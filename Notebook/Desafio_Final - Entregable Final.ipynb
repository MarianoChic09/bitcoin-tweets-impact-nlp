{"cells":[{"cell_type":"markdown","id":"af0f3375","metadata":{"id":"af0f3375"},"source":["# **Desafío Final**\n","\n","## Data Science \n","\n","### Digital House \n","\n","#### Comisión 14"]},{"cell_type":"markdown","id":"5caf4a1e","metadata":{"id":"5caf4a1e"},"source":["El objetivo del presente trabajo es predecir el comportamiento a corto plazo del precio de Bitcoin, tomando como base la reacción observada en el pasado del precio de dicha cryptomoneda a los posteos realizados en Twitter.\n","\n","La forma en que se trabajó, consistió en agrupar tweets relacionados a Bitcoin en función a la hora y el día en que fueron publicados y clasificarlos según el comportamiento del valor de Bitcoin una determinada cantidad de horas después de la emisión de los tweets (esta ventana se probó con 2, 6, 12 y 24hs)."]},{"cell_type":"markdown","id":"19715f2c","metadata":{"id":"19715f2c"},"source":["Para el el presente análisis, se obtuvieron dos bases de datos de Kaggle.com.\n","\n","Una Base de Datos con el precio por minuto de Bitcoin (https://www.kaggle.com/datasets/tencars/392-crypto-currency-pairs-at-minute-resolution), y otra con Tweets relacionados con Bitcoin (https://www.kaggle.com/datasets/kaushiksuresh147/bitcoin-tweets)"]},{"cell_type":"markdown","id":"obbous9wD7ED","metadata":{"id":"obbous9wD7ED"},"source":["### Pre-processing"]},{"cell_type":"code","execution_count":6,"id":"9613bd6f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3502,"status":"ok","timestamp":1650000165899,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"9613bd6f","outputId":"b3e5ca8c-dc7c-41fe-b179-2b1f8e9d3441"},"outputs":[{"data":{"text/plain":["'C:\\\\Users\\\\Mariano desktop\\\\OneDrive\\\\Desktop\\\\Curso Data Science Digital House\\\\Trabajo Final/'"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import datetime as dt\n","import numpy as np\n","#from google.colab import drive\n","#drive.mount('/content/gdrive/')\n","root_path_Colab = 'gdrive/MyDrive/Colab Notebooks/' \n","root_path = str(r'C:\\Users\\Mariano desktop\\OneDrive\\Desktop\\Curso Data Science Digital House\\Trabajo Final/')\n","root_path"]},{"cell_type":"markdown","id":"298beaa1","metadata":{"id":"298beaa1"},"source":["Importamos el Dataset con información relacionada al valor de Bitcoin"]},{"cell_type":"code","execution_count":10,"id":"072f2f75","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":5506,"status":"ok","timestamp":1649988670805,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"072f2f75","outputId":"11caed69-4d08-4e8f-a321-b70929008b71"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>time</th>\n","      <th>open</th>\n","      <th>close</th>\n","      <th>high</th>\n","      <th>low</th>\n","      <th>volume</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1364774820000</td>\n","      <td>93.25</td>\n","      <td>93.30</td>\n","      <td>93.30</td>\n","      <td>93.25</td>\n","      <td>93.300000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1364774880000</td>\n","      <td>100.00</td>\n","      <td>100.00</td>\n","      <td>100.00</td>\n","      <td>100.00</td>\n","      <td>93.300000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1364774940000</td>\n","      <td>93.30</td>\n","      <td>93.30</td>\n","      <td>93.30</td>\n","      <td>93.30</td>\n","      <td>33.676862</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1364775060000</td>\n","      <td>93.35</td>\n","      <td>93.47</td>\n","      <td>93.47</td>\n","      <td>93.35</td>\n","      <td>20.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1364775120000</td>\n","      <td>93.47</td>\n","      <td>93.47</td>\n","      <td>93.47</td>\n","      <td>93.47</td>\n","      <td>2.021627</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            time    open   close    high     low     volume\n","0  1364774820000   93.25   93.30   93.30   93.25  93.300000\n","1  1364774880000  100.00  100.00  100.00  100.00  93.300000\n","2  1364774940000   93.30   93.30   93.30   93.30  33.676862\n","3  1364775060000   93.35   93.47   93.47   93.35  20.000000\n","4  1364775120000   93.47   93.47   93.47   93.47   2.021627"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["data_btcusd=pd.read_csv(root_path+'Data/btcusd.csv')\n","\n","data_btcusd.head()"]},{"cell_type":"markdown","id":"30c8c0df","metadata":{"id":"30c8c0df"},"source":["Convertimos el formato de la fecha"]},{"cell_type":"code","execution_count":11,"id":"7860050b","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":6361,"status":"ok","timestamp":1649988677162,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"7860050b","outputId":"d349b358-8299-44a8-cd9e-9e8811abf00d"},"outputs":[{"name":"stdout","output_type":"stream","text":["The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>time</th>\n","      <th>open</th>\n","      <th>close</th>\n","      <th>high</th>\n","      <th>low</th>\n","      <th>volume</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2013-03-31 21:07:00</td>\n","      <td>93.25</td>\n","      <td>93.30</td>\n","      <td>93.30</td>\n","      <td>93.25</td>\n","      <td>93.300000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2013-03-31 21:08:00</td>\n","      <td>100.00</td>\n","      <td>100.00</td>\n","      <td>100.00</td>\n","      <td>100.00</td>\n","      <td>93.300000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2013-03-31 21:09:00</td>\n","      <td>93.30</td>\n","      <td>93.30</td>\n","      <td>93.30</td>\n","      <td>93.30</td>\n","      <td>33.676862</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2013-03-31 21:11:00</td>\n","      <td>93.35</td>\n","      <td>93.47</td>\n","      <td>93.47</td>\n","      <td>93.35</td>\n","      <td>20.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2013-03-31 21:12:00</td>\n","      <td>93.47</td>\n","      <td>93.47</td>\n","      <td>93.47</td>\n","      <td>93.47</td>\n","      <td>2.021627</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 time    open   close    high     low     volume\n","0 2013-03-31 21:07:00   93.25   93.30   93.30   93.25  93.300000\n","1 2013-03-31 21:08:00  100.00  100.00  100.00  100.00  93.300000\n","2 2013-03-31 21:09:00   93.30   93.30   93.30   93.30  33.676862\n","3 2013-03-31 21:11:00   93.35   93.47   93.47   93.35  20.000000\n","4 2013-03-31 21:12:00   93.47   93.47   93.47   93.47   2.021627"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["data_btcusd['time']=data_btcusd['time'].apply(lambda x: dt.datetime.fromtimestamp(x/1000)) #.strftime('%Y-%m-%d %H:%M:%S'))\n","data_btcusd.head()"]},{"cell_type":"markdown","id":"V1QTQCQBGlX8","metadata":{"id":"V1QTQCQBGlX8"},"source":["Analizamos las características del dataset"]},{"cell_type":"code","execution_count":12,"id":"2db5c280","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1649988677163,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"2db5c280","outputId":"80458f6b-cd08-4033-dd4d-edfcf7421212"},"outputs":[{"data":{"text/plain":["time      datetime64[ns]\n","open             float64\n","close            float64\n","high             float64\n","low              float64\n","volume           float64\n","dtype: object"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["data_btcusd.dtypes"]},{"cell_type":"code","execution_count":13,"id":"fccc41c3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1649988677163,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"fccc41c3","outputId":"0008f3c4-7d45-41b8-ed89-ee806e71c027"},"outputs":[{"data":{"text/plain":["(3750538, 6)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["data_btcusd.shape"]},{"cell_type":"code","execution_count":14,"id":"5ac84618","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1649988677164,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"5ac84618","outputId":"50f59174-13f8-4bb2-f669-75ab67622f5a"},"outputs":[{"data":{"text/plain":["3750533   2022-02-26 07:48:00\n","3750534   2022-02-26 07:49:00\n","3750535   2022-02-26 07:50:00\n","3750536   2022-02-26 07:51:00\n","3750537   2022-02-26 07:52:00\n","Name: time, dtype: datetime64[ns]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["data_btcusd.time.tail()"]},{"cell_type":"markdown","id":"8715e3e7","metadata":{"id":"8715e3e7"},"source":["Importamos el Dataset de los Tweets relacionados con Bitcoin"]},{"cell_type":"code","execution_count":15,"id":"413448b5","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":468},"executionInfo":{"elapsed":47985,"status":"ok","timestamp":1649988725143,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"413448b5","outputId":"cdced2ed-50ff-4289-9467-c1f0566528a9"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\ProgramData\\Anaconda3\\envs\\dhdsblend2021\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3169: DtypeWarning: Columns (5,6,7,12) have mixed types.Specify dtype option on import or set low_memory=False.\n","  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_name</th>\n","      <th>user_location</th>\n","      <th>user_description</th>\n","      <th>user_created</th>\n","      <th>user_followers</th>\n","      <th>user_friends</th>\n","      <th>user_favourites</th>\n","      <th>user_verified</th>\n","      <th>date</th>\n","      <th>text</th>\n","      <th>hashtags</th>\n","      <th>source</th>\n","      <th>is_retweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>DeSota Wilson</td>\n","      <td>Atlanta, GA</td>\n","      <td>Biz Consultant, real estate, fintech, startups...</td>\n","      <td>2009-04-26 20:05:09</td>\n","      <td>8534.0</td>\n","      <td>7605</td>\n","      <td>4838</td>\n","      <td>False</td>\n","      <td>2021-02-10 23:59:04</td>\n","      <td>Blue Ridge Bank shares halted by NYSE after #b...</td>\n","      <td>['bitcoin']</td>\n","      <td>Twitter Web App</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>CryptoND</td>\n","      <td>NaN</td>\n","      <td>😎 BITCOINLIVE is a Dutch platform aimed at inf...</td>\n","      <td>2019-10-17 20:12:10</td>\n","      <td>6769.0</td>\n","      <td>1532</td>\n","      <td>25483</td>\n","      <td>False</td>\n","      <td>2021-02-10 23:58:48</td>\n","      <td>😎 Today, that's this #Thursday, we will do a \"...</td>\n","      <td>['Thursday', 'Btc', 'wallet', 'security']</td>\n","      <td>Twitter for Android</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Tdlmatias</td>\n","      <td>London, England</td>\n","      <td>IM Academy : The best #forex, #SelfEducation, ...</td>\n","      <td>2014-11-10 10:50:37</td>\n","      <td>128.0</td>\n","      <td>332</td>\n","      <td>924</td>\n","      <td>False</td>\n","      <td>2021-02-10 23:54:48</td>\n","      <td>Guys evening, I have read this article about B...</td>\n","      <td>NaN</td>\n","      <td>Twitter Web App</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       user_name    user_location  \\\n","0  DeSota Wilson      Atlanta, GA   \n","1       CryptoND              NaN   \n","2      Tdlmatias  London, England   \n","\n","                                    user_description         user_created  \\\n","0  Biz Consultant, real estate, fintech, startups...  2009-04-26 20:05:09   \n","1  😎 BITCOINLIVE is a Dutch platform aimed at inf...  2019-10-17 20:12:10   \n","2  IM Academy : The best #forex, #SelfEducation, ...  2014-11-10 10:50:37   \n","\n","   user_followers user_friends user_favourites user_verified  \\\n","0          8534.0         7605            4838         False   \n","1          6769.0         1532           25483         False   \n","2           128.0          332             924         False   \n","\n","                  date                                               text  \\\n","0  2021-02-10 23:59:04  Blue Ridge Bank shares halted by NYSE after #b...   \n","1  2021-02-10 23:58:48  😎 Today, that's this #Thursday, we will do a \"...   \n","2  2021-02-10 23:54:48  Guys evening, I have read this article about B...   \n","\n","                                    hashtags               source is_retweet  \n","0                                ['bitcoin']      Twitter Web App      False  \n","1  ['Thursday', 'Btc', 'wallet', 'security']  Twitter for Android      False  \n","2                                        NaN      Twitter Web App      False  "]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["data_tweets=pd.read_csv(root_path+'Data/Bitcoin_tweets.csv');\n","\n","data_tweets.head(3)"]},{"cell_type":"markdown","id":"199623de","metadata":{"id":"199623de"},"source":["Nos quedamos con las features que consideramos importantes para nuestro análisis"]},{"cell_type":"code","execution_count":16,"id":"38a7b02c","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1649988725144,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"38a7b02c","outputId":"bc3a45b3-f90d-4b88-9738-b868527b5e08"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_followers</th>\n","      <th>date</th>\n","      <th>text</th>\n","      <th>is_retweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8534.0</td>\n","      <td>2021-02-10 23:59:04</td>\n","      <td>Blue Ridge Bank shares halted by NYSE after #b...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>6769.0</td>\n","      <td>2021-02-10 23:58:48</td>\n","      <td>😎 Today, that's this #Thursday, we will do a \"...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>128.0</td>\n","      <td>2021-02-10 23:54:48</td>\n","      <td>Guys evening, I have read this article about B...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>625.0</td>\n","      <td>2021-02-10 23:54:33</td>\n","      <td>$BTC A big chance in a billion! Price: \\487264...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1249.0</td>\n","      <td>2021-02-10 23:54:06</td>\n","      <td>This network is secured by 9 508 nodes as of t...</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   user_followers                 date  \\\n","0          8534.0  2021-02-10 23:59:04   \n","1          6769.0  2021-02-10 23:58:48   \n","2           128.0  2021-02-10 23:54:48   \n","3           625.0  2021-02-10 23:54:33   \n","4          1249.0  2021-02-10 23:54:06   \n","\n","                                                text is_retweet  \n","0  Blue Ridge Bank shares halted by NYSE after #b...      False  \n","1  😎 Today, that's this #Thursday, we will do a \"...      False  \n","2  Guys evening, I have read this article about B...      False  \n","3  $BTC A big chance in a billion! Price: \\487264...      False  \n","4  This network is secured by 9 508 nodes as of t...      False  "]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["data_tweets=data_tweets.loc[:,['user_followers', 'date', 'text', 'is_retweet']]\n","data_tweets.head()"]},{"cell_type":"markdown","id":"ERhz2zvOGzrX","metadata":{"id":"ERhz2zvOGzrX"},"source":["Analizamos las características del dataset"]},{"cell_type":"code","execution_count":17,"id":"fc177158","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1649988725145,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"fc177158","outputId":"a5ae5fac-498b-494c-9d4c-cce82ebceaf6"},"outputs":[{"data":{"text/plain":["(2434037, 4)"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["data_tweets.shape"]},{"cell_type":"markdown","id":"82ebf143","metadata":{"id":"82ebf143"},"source":["Eliminamos los campos que tienen datos incorrectos en el Feature \"date\" y los nulos"]},{"cell_type":"code","execution_count":18,"id":"607cb605","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2514,"status":"ok","timestamp":1649988727653,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"607cb605","outputId":"9222f826-6d75-4283-9446-f44dc9281804"},"outputs":[{"data":{"text/plain":["1393938    ['cryptotrading', 'crypto', 'tradingbots', 'bi...\n","137068     ['cryptocurrency', 'BSC', 'Bitcoin', 'Ethereum...\n","693194                                               ['btc']\n","697397                                               ['btc']\n","1611481                                          ['bitcoin']\n","1067665    ['YieldFarming', 'Airdrop', 'PancakeSwap', 'Gi...\n","180575     ['YieldFarming', 'Airdrop', 'Binance', 'Bitcoi...\n","1513850    ['PW', 'pythonwealth', 'Presale', 'token', 'ic...\n","64943                              ['ETH', 'BTC', 'Bitcoin']\n","1347699                                          ['Bitcoin']\n","1811149    ['Airdrop', 'Airdrops', 'Airdropinspector', 'B...\n","2354296                                  2022-03-10 23:59:55\n","2354297                                  2022-03-10 23:59:52\n","2354298                                  2022-03-10 23:59:41\n","2354299                                  2022-03-10 23:59:32\n","Name: date, dtype: object"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["data_tweets.date.sort_values(ascending=False).head(15)"]},{"cell_type":"code","execution_count":19,"id":"10d0e732","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2499,"status":"ok","timestamp":1649988730149,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"10d0e732","outputId":"363f2a11-c1ec-4d02-a683-7969def9c797"},"outputs":[{"data":{"text/plain":["Int64Index([1393938,  137068,  693194,  697397, 1611481, 1067665,  180575,\n","            1513850,   64943, 1347699, 1811149],\n","           dtype='int64')"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["lista_drop = data_tweets.date.sort_values(ascending=False).index[:11]\n","lista_drop"]},{"cell_type":"code","execution_count":20,"id":"6fce134d","metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1649988730150,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"6fce134d"},"outputs":[],"source":["data_tweets.drop(lista_drop, inplace=True, axis=0)"]},{"cell_type":"code","execution_count":21,"id":"2a5d0a3f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1649988730150,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"2a5d0a3f","outputId":"c668a9c3-7e60-4ec0-e512-adb2555bd8ad"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 2434026 entries, 0 to 2434036\n","Data columns (total 4 columns):\n"," #   Column          Dtype  \n","---  ------          -----  \n"," 0   user_followers  float64\n"," 1   date            object \n"," 2   text            object \n"," 3   is_retweet      object \n","dtypes: float64(1), object(3)\n","memory usage: 92.9+ MB\n"]}],"source":["data_tweets.info()"]},{"cell_type":"code","execution_count":22,"id":"a70abca9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":472,"status":"ok","timestamp":1649988730618,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"a70abca9","outputId":"48b769af-942a-45a0-ccbb-dee4a7174e9d"},"outputs":[{"data":{"text/plain":["user_followers    101\n","date              101\n","text              101\n","is_retweet        370\n","dtype: int64"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["data_tweets.isna().sum()"]},{"cell_type":"code","execution_count":23,"id":"c4253009","metadata":{"executionInfo":{"elapsed":1017,"status":"ok","timestamp":1649988731633,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"c4253009"},"outputs":[],"source":["data_tweets.dropna(inplace=True)"]},{"cell_type":"markdown","id":"5424ac7d","metadata":{"id":"5424ac7d"},"source":["Modificamos el formato de la fecha"]},{"cell_type":"code","execution_count":24,"id":"3f3a1023","metadata":{"executionInfo":{"elapsed":30720,"status":"ok","timestamp":1649988762351,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"3f3a1023"},"outputs":[],"source":["date_series_str=data_tweets.date\n","# lista_errores=['ETH', 'BTC', 'Bitcoin']\n","# date_series_str.drop(lista_errores,axis=0)\n","date=[dt.datetime.strptime(x,'%Y-%m-%d %H:%M:%S') for x in date_series_str]"]},{"cell_type":"code","execution_count":25,"id":"78be6934","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3939,"status":"ok","timestamp":1649988766287,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"78be6934","outputId":"06d4ab9c-4455-4dc6-a743-0868b2b99d5b"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 2433656 entries, 0 to 2434036\n","Data columns (total 4 columns):\n"," #   Column          Dtype         \n","---  ------          -----         \n"," 0   user_followers  float64       \n"," 1   date            datetime64[ns]\n"," 2   text            object        \n"," 3   is_retweet      object        \n","dtypes: datetime64[ns](1), float64(1), object(2)\n","memory usage: 92.8+ MB\n"]}],"source":["data_tweets['date'] = date\n","data_tweets.info()"]},{"cell_type":"code","execution_count":26,"id":"9e496633","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1649988766287,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"9e496633","outputId":"1df77d11-8dc1-4e78-e14e-a13e7bf7190b"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_followers</th>\n","      <th>date</th>\n","      <th>text</th>\n","      <th>is_retweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8534.0</td>\n","      <td>2021-02-10 23:59:04</td>\n","      <td>Blue Ridge Bank shares halted by NYSE after #b...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>6769.0</td>\n","      <td>2021-02-10 23:58:48</td>\n","      <td>😎 Today, that's this #Thursday, we will do a \"...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>128.0</td>\n","      <td>2021-02-10 23:54:48</td>\n","      <td>Guys evening, I have read this article about B...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>625.0</td>\n","      <td>2021-02-10 23:54:33</td>\n","      <td>$BTC A big chance in a billion! Price: \\487264...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1249.0</td>\n","      <td>2021-02-10 23:54:06</td>\n","      <td>This network is secured by 9 508 nodes as of t...</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   user_followers                date  \\\n","0          8534.0 2021-02-10 23:59:04   \n","1          6769.0 2021-02-10 23:58:48   \n","2           128.0 2021-02-10 23:54:48   \n","3           625.0 2021-02-10 23:54:33   \n","4          1249.0 2021-02-10 23:54:06   \n","\n","                                                text is_retweet  \n","0  Blue Ridge Bank shares halted by NYSE after #b...      False  \n","1  😎 Today, that's this #Thursday, we will do a \"...      False  \n","2  Guys evening, I have read this article about B...      False  \n","3  $BTC A big chance in a billion! Price: \\487264...      False  \n","4  This network is secured by 9 508 nodes as of t...      False  "]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["data_tweets.head()"]},{"cell_type":"markdown","id":"e207edb1","metadata":{"id":"e207edb1"},"source":["Verificamos que el Dataset no contiene retweets y dropeamos esa feature"]},{"cell_type":"code","execution_count":27,"id":"9d8e8d25","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1649988766288,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"9d8e8d25","outputId":"db05a4c3-5798-4ca0-cd21-8d6491c33f61"},"outputs":[{"data":{"text/plain":["array([False], dtype=object)"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["data_tweets.is_retweet.unique()"]},{"cell_type":"code","execution_count":28,"id":"06f841da","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1649988766288,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"06f841da","outputId":"4021a974-e925-466b-9d6d-a8c6030b574d"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_followers</th>\n","      <th>date</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8534.0</td>\n","      <td>2021-02-10 23:59:04</td>\n","      <td>Blue Ridge Bank shares halted by NYSE after #b...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>6769.0</td>\n","      <td>2021-02-10 23:58:48</td>\n","      <td>😎 Today, that's this #Thursday, we will do a \"...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>128.0</td>\n","      <td>2021-02-10 23:54:48</td>\n","      <td>Guys evening, I have read this article about B...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>625.0</td>\n","      <td>2021-02-10 23:54:33</td>\n","      <td>$BTC A big chance in a billion! Price: \\487264...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1249.0</td>\n","      <td>2021-02-10 23:54:06</td>\n","      <td>This network is secured by 9 508 nodes as of t...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   user_followers                date  \\\n","0          8534.0 2021-02-10 23:59:04   \n","1          6769.0 2021-02-10 23:58:48   \n","2           128.0 2021-02-10 23:54:48   \n","3           625.0 2021-02-10 23:54:33   \n","4          1249.0 2021-02-10 23:54:06   \n","\n","                                                text  \n","0  Blue Ridge Bank shares halted by NYSE after #b...  \n","1  😎 Today, that's this #Thursday, we will do a \"...  \n","2  Guys evening, I have read this article about B...  \n","3  $BTC A big chance in a billion! Price: \\487264...  \n","4  This network is secured by 9 508 nodes as of t...  "]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["data_tweets.drop('is_retweet', axis=1, inplace=True)\n","data_tweets.head()"]},{"cell_type":"markdown","id":"iqQEf3GoHQEe","metadata":{"id":"iqQEf3GoHQEe"},"source":["Observanos las fechas sobre las cuales el dataset obtenido tiene información"]},{"cell_type":"code","execution_count":29,"id":"MQvl8_NM2S5T","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1649988766288,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"MQvl8_NM2S5T","outputId":"0d1de688-b5bb-4b65-c74a-4398d91bfecb"},"outputs":[{"data":{"text/plain":["0      2021-02-10 23:59:04\n","100    2021-02-10 23:07:09\n","200    2021-02-10 22:25:24\n","300    2021-02-10 21:46:51\n","400    2021-02-10 21:00:02\n","500    2021-02-10 20:15:18\n","600    2021-02-10 19:41:15\n","700    2021-02-10 18:57:27\n","800    2021-02-10 18:29:25\n","900    2021-02-10 17:59:23\n","1000   2021-02-10 17:26:28\n","1100   2021-02-10 16:45:01\n","1200   2021-02-10 16:17:37\n","1300   2021-02-10 15:52:20\n","1400   2021-02-10 15:27:59\n","Name: date, dtype: datetime64[ns]"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["data_tweets.date[0:1500:100]"]},{"cell_type":"code","execution_count":30,"id":"ca704dd1","metadata":{"executionInfo":{"elapsed":553,"status":"ok","timestamp":1649988766834,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"ca704dd1"},"outputs":[],"source":["data_tweets_ordered=data_tweets.sort_values(by='date')"]},{"cell_type":"code","execution_count":31,"id":"MOjidVum48mn","metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1649988766834,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"MOjidVum48mn"},"outputs":[],"source":["dif_date = data_tweets_ordered.date.shift(-1)-data_tweets_ordered.date"]},{"cell_type":"code","execution_count":32,"id":"KrTyGl9y9NRT","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1649988766835,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"KrTyGl9y9NRT","outputId":"1773aff0-9a66-479f-b9c4-b77bdcbaef92"},"outputs":[{"data":{"text/plain":["Timedelta('300 days 23:03:16')"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["dif_date[dif_date>'0 days 01:00:00'].sum()"]},{"cell_type":"code","execution_count":33,"id":"fQFo_qKQ-oUJ","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1649988766835,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"fQFo_qKQ-oUJ","outputId":"ad91e60e-d7b2-4c31-9aa4-c79879cc2860"},"outputs":[{"data":{"text/plain":["Timedelta('398 days 13:07:51')"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["data_tweets_ordered.date.iloc[-1]-data_tweets_ordered.date.iloc[0]"]},{"cell_type":"code","execution_count":34,"id":"Yz9PGgya7ag8","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293},"executionInfo":{"elapsed":9569,"status":"ok","timestamp":1649988776400,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"Yz9PGgya7ag8","outputId":"e7b0b418-7201-45cd-9364-96c8528f3a71"},"outputs":[{"data":{"text/plain":["[<matplotlib.lines.Line2D at 0x247ac1db820>]"]},"execution_count":34,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# Import Library\n","\n","import matplotlib.pyplot as plt\n","\n","# Plot\n","\n","plt.plot(data_tweets_ordered['date'][:-3],dif_date[:-3],marker='o')"]},{"cell_type":"markdown","id":"7e85a2ac","metadata":{"id":"7e85a2ac"},"source":["Eliminamos los tweets de usuarios con menos de 150 seguidores, por considerarlos poco relevantes y posibles bots "]},{"cell_type":"code","execution_count":35,"id":"20f2d8eb","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1649988776401,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"20f2d8eb","outputId":"59bfad87-95fe-4c3c-8571-03fb133fce3e"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_followers</th>\n","      <th>date</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8534.0</td>\n","      <td>2021-02-10 23:59:04</td>\n","      <td>Blue Ridge Bank shares halted by NYSE after #b...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>6769.0</td>\n","      <td>2021-02-10 23:58:48</td>\n","      <td>😎 Today, that's this #Thursday, we will do a \"...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>625.0</td>\n","      <td>2021-02-10 23:54:33</td>\n","      <td>$BTC A big chance in a billion! Price: \\487264...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1249.0</td>\n","      <td>2021-02-10 23:54:06</td>\n","      <td>This network is secured by 9 508 nodes as of t...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>742.0</td>\n","      <td>2021-02-10 23:53:30</td>\n","      <td>💹 Trade #Crypto on #Binance \\n\\n📌 Enjoy #Cashb...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   user_followers                date  \\\n","0          8534.0 2021-02-10 23:59:04   \n","1          6769.0 2021-02-10 23:58:48   \n","3           625.0 2021-02-10 23:54:33   \n","4          1249.0 2021-02-10 23:54:06   \n","5           742.0 2021-02-10 23:53:30   \n","\n","                                                text  \n","0  Blue Ridge Bank shares halted by NYSE after #b...  \n","1  😎 Today, that's this #Thursday, we will do a \"...  \n","3  $BTC A big chance in a billion! Price: \\487264...  \n","4  This network is secured by 9 508 nodes as of t...  \n","5  💹 Trade #Crypto on #Binance \\n\\n📌 Enjoy #Cashb...  "]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["min_followers_mask = data_tweets.user_followers >= 150 #definir el número mínimo\n","\n","data_tweets_2 = data_tweets.loc[min_followers_mask,:]\n","data_tweets_2.head()"]},{"cell_type":"code","execution_count":null,"id":"er2HC47P8Uki","metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1649988776401,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"er2HC47P8Uki"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":36,"id":"8bc9a0a8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1649988776401,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"8bc9a0a8","outputId":"fc498385-6691-48c7-eb31-3bca1efedb0c"},"outputs":[{"data":{"text/plain":["(1341958, 3)"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["data_tweets_2.shape"]},{"cell_type":"markdown","id":"39cda734","metadata":{"id":"39cda734"},"source":["### Analizamos las fechas de ambos datasets para que coincidan"]},{"cell_type":"markdown","id":"d29134bf","metadata":{"id":"d29134bf"},"source":["Ordenamos el dataset de tweets por fecha"]},{"cell_type":"code","execution_count":37,"id":"43d8ab9e","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1649988776401,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"43d8ab9e","outputId":"51d431f3-592e-4e49-a898-ab2375d93091"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_followers</th>\n","      <th>date</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>301.0</td>\n","      <td>2021-02-05 10:52:04</td>\n","      <td>2⃣   Debunking 9 #Bitcoin Myths by @Patrick_Lo...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>301.0</td>\n","      <td>2021-02-05 10:52:04</td>\n","      <td>📖  Weekend Read 📖\\n\\nKeen to learn about #cryp...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>301.0</td>\n","      <td>2021-02-05 10:52:06</td>\n","      <td>4⃣  🎙️ Bloomberg LP #CryptoOutlook 2021 with @...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>301.0</td>\n","      <td>2021-02-05 10:52:07</td>\n","      <td>5⃣   #Blockchain 50 2021 by @DelRayMan, @Forbe...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>163.0</td>\n","      <td>2021-02-05 10:57:05</td>\n","      <td>#Amazing 😍\\n#Monopoly #Crypto #cryptocurrency ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1341953</th>\n","      <td>327.0</td>\n","      <td>2022-03-10 23:59:03</td>\n","      <td>@CryptoNostra $FWT @FreewayFi and their superc...</td>\n","    </tr>\n","    <tr>\n","      <th>1341954</th>\n","      <td>286.0</td>\n","      <td>2022-03-10 23:59:05</td>\n","      <td>4 hour top movers report #blockchain #crypto #...</td>\n","    </tr>\n","    <tr>\n","      <th>1341955</th>\n","      <td>2579.0</td>\n","      <td>2022-03-10 23:59:09</td>\n","      <td>Top 5 #crypto prices with 24h change:\\n\\n#BTC ...</td>\n","    </tr>\n","    <tr>\n","      <th>1341956</th>\n","      <td>9931.0</td>\n","      <td>2022-03-10 23:59:11</td>\n","      <td>It’s painful seeing my TINY #BTC buys in 2016\\...</td>\n","    </tr>\n","    <tr>\n","      <th>1341957</th>\n","      <td>319.0</td>\n","      <td>2022-03-10 23:59:31</td>\n","      <td>Playing with some lines...\\n\\n#BTC #Bitcoin #C...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1341958 rows × 3 columns</p>\n","</div>"],"text/plain":["         user_followers                date  \\\n","0                 301.0 2021-02-05 10:52:04   \n","1                 301.0 2021-02-05 10:52:04   \n","2                 301.0 2021-02-05 10:52:06   \n","3                 301.0 2021-02-05 10:52:07   \n","4                 163.0 2021-02-05 10:57:05   \n","...                 ...                 ...   \n","1341953           327.0 2022-03-10 23:59:03   \n","1341954           286.0 2022-03-10 23:59:05   \n","1341955          2579.0 2022-03-10 23:59:09   \n","1341956          9931.0 2022-03-10 23:59:11   \n","1341957           319.0 2022-03-10 23:59:31   \n","\n","                                                      text  \n","0        2⃣   Debunking 9 #Bitcoin Myths by @Patrick_Lo...  \n","1        📖  Weekend Read 📖\\n\\nKeen to learn about #cryp...  \n","2        4⃣  🎙️ Bloomberg LP #CryptoOutlook 2021 with @...  \n","3        5⃣   #Blockchain 50 2021 by @DelRayMan, @Forbe...  \n","4        #Amazing 😍\\n#Monopoly #Crypto #cryptocurrency ...  \n","...                                                    ...  \n","1341953  @CryptoNostra $FWT @FreewayFi and their superc...  \n","1341954  4 hour top movers report #blockchain #crypto #...  \n","1341955  Top 5 #crypto prices with 24h change:\\n\\n#BTC ...  \n","1341956  It’s painful seeing my TINY #BTC buys in 2016\\...  \n","1341957  Playing with some lines...\\n\\n#BTC #Bitcoin #C...  \n","\n","[1341958 rows x 3 columns]"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["data_tweets_3 = data_tweets_2.sort_values(by='date')\n","data_tweets_3.reset_index(inplace=True, drop=True)\n","data_tweets_3"]},{"cell_type":"markdown","id":"82081bb5","metadata":{"id":"82081bb5"},"source":["Vemos rango de fechas de dataset de tweets"]},{"cell_type":"code","execution_count":38,"id":"5d6206f2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1649988776402,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"5d6206f2","outputId":"f235804b-3f3b-44f2-ad77-ee09b1149f84"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tiempo inicio tweets: 2021-02-05 10:52:04\n","Tiempo final tweets: 2022-03-10 23:59:31\n"]}],"source":["tiempo_inicio_tweets = data_tweets_3.loc[0,'date']\n","print('Tiempo inicio tweets:',tiempo_inicio_tweets)\n","tiempo_final_tweets = data_tweets_3.iloc[-1,1]\n","print('Tiempo final tweets:',tiempo_final_tweets)"]},{"cell_type":"markdown","id":"1568c6fc","metadata":{"id":"1568c6fc"},"source":["Vemos rango de fechas de dataset de Bitcoin"]},{"cell_type":"code","execution_count":39,"id":"b40a1cc6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":569,"status":"ok","timestamp":1649988776961,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"b40a1cc6","outputId":"e5a92059-53b2-441b-f395-c5725f183a90"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tiempo inicio btc: 2013-03-31 21:07:00\n","Tiempo final btc: 2022-02-26 07:52:00\n"]}],"source":["tiempo_inicio_btc = data_btcusd.loc[0,'time']\n","print('Tiempo inicio btc:',tiempo_inicio_btc)\n","tiempo_final_btc = data_btcusd.iloc[-1,0]\n","print('Tiempo final btc:',tiempo_final_btc)"]},{"cell_type":"markdown","id":"c53c8088","metadata":{"id":"c53c8088"},"source":["Nos quedamos con el rango de fechas en que ambos coinciden"]},{"cell_type":"code","execution_count":40,"id":"8ed51a19","metadata":{"executionInfo":{"elapsed":46,"status":"ok","timestamp":1649988776962,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"8ed51a19"},"outputs":[],"source":["if tiempo_inicio_tweets > tiempo_inicio_btc:\n","    tiempo_data_inicio = tiempo_inicio_tweets\n","else:\n","    tiempo_data_inicio = tiempo_inicio_btc"]},{"cell_type":"code","execution_count":41,"id":"96666571","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45,"status":"ok","timestamp":1649988776962,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"96666571","outputId":"daa47579-2cd7-4bbb-e2ac-2f163ccf5ddf"},"outputs":[{"data":{"text/plain":["Timestamp('2021-02-05 10:52:04')"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["tiempo_data_inicio"]},{"cell_type":"code","execution_count":42,"id":"61cf8ab4","metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1649988776962,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"61cf8ab4"},"outputs":[],"source":["if tiempo_final_tweets < tiempo_final_btc:\n","    tiempo_data_final = tiempo_final_tweets\n","else:\n","    tiempo_data_final = tiempo_final_btc"]},{"cell_type":"code","execution_count":43,"id":"2d6f0f17","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1649988776962,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"2d6f0f17","outputId":"5cf3fd4b-327c-41b3-942a-57679007f205"},"outputs":[{"data":{"text/plain":["Timestamp('2022-02-26 07:52:00')"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["tiempo_data_final"]},{"cell_type":"code","execution_count":44,"id":"51e3c93a","metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1649988776963,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"51e3c93a"},"outputs":[],"source":["data_btc_mask = (data_btcusd.time >= tiempo_data_inicio) & (data_btcusd.time <= tiempo_data_final)\n","data_tweet_mask = (data_tweets_3.date >= tiempo_data_inicio) & (data_tweets_3.date <= tiempo_data_final)"]},{"cell_type":"markdown","id":"cpIvSYtQIPvM","metadata":{"id":"cpIvSYtQIPvM"},"source":["Dataset con valores de Bitcoin para la fecha coincidente"]},{"cell_type":"code","execution_count":45,"id":"c195eb09","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1649988776963,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"c195eb09","outputId":"9f8954cf-ae28-4496-f50c-d594d53c231b"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>time</th>\n","      <th>open</th>\n","      <th>close</th>\n","      <th>high</th>\n","      <th>low</th>\n","      <th>volume</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3198003</th>\n","      <td>2021-02-05 10:53:00</td>\n","      <td>38236.000000</td>\n","      <td>38226.721195</td>\n","      <td>38243.000000</td>\n","      <td>38175.000000</td>\n","      <td>4.782804</td>\n","    </tr>\n","    <tr>\n","      <th>3198004</th>\n","      <td>2021-02-05 10:54:00</td>\n","      <td>38231.000000</td>\n","      <td>38336.000000</td>\n","      <td>38336.047343</td>\n","      <td>38211.064618</td>\n","      <td>37.722672</td>\n","    </tr>\n","    <tr>\n","      <th>3198005</th>\n","      <td>2021-02-05 10:55:00</td>\n","      <td>38322.828016</td>\n","      <td>38317.138180</td>\n","      <td>38366.000000</td>\n","      <td>38287.977064</td>\n","      <td>10.637205</td>\n","    </tr>\n","    <tr>\n","      <th>3198006</th>\n","      <td>2021-02-05 10:56:00</td>\n","      <td>38331.000000</td>\n","      <td>38318.000000</td>\n","      <td>38331.000000</td>\n","      <td>38268.000000</td>\n","      <td>9.602213</td>\n","    </tr>\n","    <tr>\n","      <th>3198007</th>\n","      <td>2021-02-05 10:57:00</td>\n","      <td>38316.819231</td>\n","      <td>38304.000000</td>\n","      <td>38332.000000</td>\n","      <td>38303.000000</td>\n","      <td>11.947110</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                       time          open         close          high  \\\n","3198003 2021-02-05 10:53:00  38236.000000  38226.721195  38243.000000   \n","3198004 2021-02-05 10:54:00  38231.000000  38336.000000  38336.047343   \n","3198005 2021-02-05 10:55:00  38322.828016  38317.138180  38366.000000   \n","3198006 2021-02-05 10:56:00  38331.000000  38318.000000  38331.000000   \n","3198007 2021-02-05 10:57:00  38316.819231  38304.000000  38332.000000   \n","\n","                  low     volume  \n","3198003  38175.000000   4.782804  \n","3198004  38211.064618  37.722672  \n","3198005  38287.977064  10.637205  \n","3198006  38268.000000   9.602213  \n","3198007  38303.000000  11.947110  "]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["data_btcusd = data_btcusd.loc[data_btc_mask,:]\n","data_btcusd.head()"]},{"cell_type":"code","execution_count":46,"id":"e1291ede","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1649988776963,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"e1291ede","outputId":"ff223b6e-82e5-4887-9caa-64fe42171530"},"outputs":[{"data":{"text/plain":["(552535, 6)"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["data_btcusd.shape"]},{"cell_type":"markdown","id":"gtCCjbH5IVjB","metadata":{"id":"gtCCjbH5IVjB"},"source":["Dataset con tweets de Bitcoin para la fecha coincidente"]},{"cell_type":"code","execution_count":47,"id":"91a2c3ec","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1649988776963,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"91a2c3ec","outputId":"b6aec3bf-0590-4bfd-a36d-2e2101379a0d"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_followers</th>\n","      <th>date</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>301.0</td>\n","      <td>2021-02-05 10:52:04</td>\n","      <td>2⃣   Debunking 9 #Bitcoin Myths by @Patrick_Lo...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>301.0</td>\n","      <td>2021-02-05 10:52:04</td>\n","      <td>📖  Weekend Read 📖\\n\\nKeen to learn about #cryp...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>301.0</td>\n","      <td>2021-02-05 10:52:06</td>\n","      <td>4⃣  🎙️ Bloomberg LP #CryptoOutlook 2021 with @...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>301.0</td>\n","      <td>2021-02-05 10:52:07</td>\n","      <td>5⃣   #Blockchain 50 2021 by @DelRayMan, @Forbe...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>163.0</td>\n","      <td>2021-02-05 10:57:05</td>\n","      <td>#Amazing 😍\\n#Monopoly #Crypto #cryptocurrency ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   user_followers                date  \\\n","0           301.0 2021-02-05 10:52:04   \n","1           301.0 2021-02-05 10:52:04   \n","2           301.0 2021-02-05 10:52:06   \n","3           301.0 2021-02-05 10:52:07   \n","4           163.0 2021-02-05 10:57:05   \n","\n","                                                text  \n","0  2⃣   Debunking 9 #Bitcoin Myths by @Patrick_Lo...  \n","1  📖  Weekend Read 📖\\n\\nKeen to learn about #cryp...  \n","2  4⃣  🎙️ Bloomberg LP #CryptoOutlook 2021 with @...  \n","3  5⃣   #Blockchain 50 2021 by @DelRayMan, @Forbe...  \n","4  #Amazing 😍\\n#Monopoly #Crypto #cryptocurrency ...  "]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["data_tweets_3 = data_tweets_3.loc[data_tweet_mask,:]\n","data_tweets_3.head()"]},{"cell_type":"code","execution_count":48,"id":"650f90a4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1649988776963,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"650f90a4","outputId":"99ad7661-98e3-4976-cc53-78abd7a19525"},"outputs":[{"data":{"text/plain":["(1290445, 3)"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["data_tweets_3.shape"]},{"cell_type":"code","execution_count":49,"id":"b4eb1ee7","metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1649988776964,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"b4eb1ee7"},"outputs":[],"source":["data_btcusd.index = data_btcusd.time"]},{"cell_type":"markdown","id":"0FR6-S4RId6b","metadata":{"id":"0FR6-S4RId6b"},"source":["Nos quedamos con los vlaores de Bitcoin de los cierres de cada hora (para todo el período analizado)"]},{"cell_type":"code","execution_count":50,"id":"b569728d","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1649988776964,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"b569728d","outputId":"90e2835a-645c-46f2-97c0-0e1abe9974a4"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>open</th>\n","    </tr>\n","    <tr>\n","      <th>time</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>38236.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 11:00:00</th>\n","      <td>38354.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 12:00:00</th>\n","      <td>38126.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 13:00:00</th>\n","      <td>37962.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 14:00:00</th>\n","      <td>37811.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                        open\n","time                        \n","2021-02-05 10:00:00  38236.0\n","2021-02-05 11:00:00  38354.0\n","2021-02-05 12:00:00  38126.0\n","2021-02-05 13:00:00  37962.0\n","2021-02-05 14:00:00  37811.0"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["data_btc_resample = pd.DataFrame(data_btcusd.open.resample('H').first())\n","data_btc_resample.head()"]},{"cell_type":"code","execution_count":51,"id":"5702723f","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"elapsed":502,"status":"ok","timestamp":1649988777458,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"5702723f","outputId":"ba53a873-b99a-40b2-f6b6-ae20e98b6c44"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>open</th>\n","      <th>close</th>\n","    </tr>\n","    <tr>\n","      <th>time</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>38236.0</td>\n","      <td>38355.00000</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 11:00:00</th>\n","      <td>38354.0</td>\n","      <td>38128.00000</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 12:00:00</th>\n","      <td>38126.0</td>\n","      <td>37947.00000</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 13:00:00</th>\n","      <td>37962.0</td>\n","      <td>37810.93318</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 14:00:00</th>\n","      <td>37811.0</td>\n","      <td>37872.00000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                        open        close\n","time                                     \n","2021-02-05 10:00:00  38236.0  38355.00000\n","2021-02-05 11:00:00  38354.0  38128.00000\n","2021-02-05 12:00:00  38126.0  37947.00000\n","2021-02-05 13:00:00  37962.0  37810.93318\n","2021-02-05 14:00:00  37811.0  37872.00000"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["data_btc_resample['close'] = data_btcusd.close.resample('H').last()\n","data_btc_resample.head()"]},{"cell_type":"code","execution_count":52,"id":"990d2dff","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1649988777459,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"990d2dff","outputId":"fa8aa1a9-82d3-4b5a-ddc3-b73cba4b4b92"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>open</th>\n","      <th>close</th>\n","      <th>high</th>\n","    </tr>\n","    <tr>\n","      <th>time</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>38236.0</td>\n","      <td>38355.00000</td>\n","      <td>38366.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 11:00:00</th>\n","      <td>38354.0</td>\n","      <td>38128.00000</td>\n","      <td>38366.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 12:00:00</th>\n","      <td>38126.0</td>\n","      <td>37947.00000</td>\n","      <td>38309.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 13:00:00</th>\n","      <td>37962.0</td>\n","      <td>37810.93318</td>\n","      <td>38183.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 14:00:00</th>\n","      <td>37811.0</td>\n","      <td>37872.00000</td>\n","      <td>37941.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                        open        close     high\n","time                                              \n","2021-02-05 10:00:00  38236.0  38355.00000  38366.0\n","2021-02-05 11:00:00  38354.0  38128.00000  38366.0\n","2021-02-05 12:00:00  38126.0  37947.00000  38309.0\n","2021-02-05 13:00:00  37962.0  37810.93318  38183.0\n","2021-02-05 14:00:00  37811.0  37872.00000  37941.0"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["data_btc_resample['high'] = data_btcusd.high.resample('H').max()\n","data_btc_resample.head()"]},{"cell_type":"code","execution_count":53,"id":"4fb777eb","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1649988777459,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"4fb777eb","outputId":"f3996bc6-266f-4d7d-928a-1db92f683ae2"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>open</th>\n","      <th>close</th>\n","      <th>high</th>\n","      <th>low</th>\n","    </tr>\n","    <tr>\n","      <th>time</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>38236.0</td>\n","      <td>38355.00000</td>\n","      <td>38366.0</td>\n","      <td>38175.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 11:00:00</th>\n","      <td>38354.0</td>\n","      <td>38128.00000</td>\n","      <td>38366.0</td>\n","      <td>38022.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 12:00:00</th>\n","      <td>38126.0</td>\n","      <td>37947.00000</td>\n","      <td>38309.0</td>\n","      <td>37918.654556</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 13:00:00</th>\n","      <td>37962.0</td>\n","      <td>37810.93318</td>\n","      <td>38183.0</td>\n","      <td>37701.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 14:00:00</th>\n","      <td>37811.0</td>\n","      <td>37872.00000</td>\n","      <td>37941.0</td>\n","      <td>37756.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                        open        close     high           low\n","time                                                            \n","2021-02-05 10:00:00  38236.0  38355.00000  38366.0  38175.000000\n","2021-02-05 11:00:00  38354.0  38128.00000  38366.0  38022.000000\n","2021-02-05 12:00:00  38126.0  37947.00000  38309.0  37918.654556\n","2021-02-05 13:00:00  37962.0  37810.93318  38183.0  37701.000000\n","2021-02-05 14:00:00  37811.0  37872.00000  37941.0  37756.000000"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["data_btc_resample['low'] = data_btcusd.low.resample('H').min()\n","data_btc_resample.head()"]},{"cell_type":"code","execution_count":54,"id":"48e4e491","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1649988777460,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"48e4e491","outputId":"150ec370-3a18-4282-cb60-2713653e5517"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>open</th>\n","      <th>close</th>\n","      <th>high</th>\n","      <th>low</th>\n","      <th>volume</th>\n","    </tr>\n","    <tr>\n","      <th>time</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>38236.0</td>\n","      <td>38355.00000</td>\n","      <td>38366.0</td>\n","      <td>38175.000000</td>\n","      <td>78.510053</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 11:00:00</th>\n","      <td>38354.0</td>\n","      <td>38128.00000</td>\n","      <td>38366.0</td>\n","      <td>38022.000000</td>\n","      <td>157.987029</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 12:00:00</th>\n","      <td>38126.0</td>\n","      <td>37947.00000</td>\n","      <td>38309.0</td>\n","      <td>37918.654556</td>\n","      <td>197.929364</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 13:00:00</th>\n","      <td>37962.0</td>\n","      <td>37810.93318</td>\n","      <td>38183.0</td>\n","      <td>37701.000000</td>\n","      <td>414.629575</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 14:00:00</th>\n","      <td>37811.0</td>\n","      <td>37872.00000</td>\n","      <td>37941.0</td>\n","      <td>37756.000000</td>\n","      <td>90.369899</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                        open        close     high           low      volume\n","time                                                                        \n","2021-02-05 10:00:00  38236.0  38355.00000  38366.0  38175.000000   78.510053\n","2021-02-05 11:00:00  38354.0  38128.00000  38366.0  38022.000000  157.987029\n","2021-02-05 12:00:00  38126.0  37947.00000  38309.0  37918.654556  197.929364\n","2021-02-05 13:00:00  37962.0  37810.93318  38183.0  37701.000000  414.629575\n","2021-02-05 14:00:00  37811.0  37872.00000  37941.0  37756.000000   90.369899"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["data_btc_resample['volume'] = data_btcusd.volume.resample('H').sum()\n","data_btc_resample.head() "]},{"cell_type":"code","execution_count":55,"id":"7899c1d2","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1649988777460,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"7899c1d2","outputId":"6cb9aef1-743c-4853-ac8d-2b4da081e007"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>open</th>\n","      <th>close</th>\n","      <th>high</th>\n","      <th>low</th>\n","      <th>volume</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>9257.000000</td>\n","      <td>9257.000000</td>\n","      <td>9257.000000</td>\n","      <td>9257.000000</td>\n","      <td>9262.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>47612.783557</td>\n","      <td>47613.085106</td>\n","      <td>47878.873927</td>\n","      <td>47330.043473</td>\n","      <td>326.231542</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>9104.971332</td>\n","      <td>9104.860057</td>\n","      <td>9120.726412</td>\n","      <td>9085.465610</td>\n","      <td>489.720237</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>29446.000000</td>\n","      <td>29447.000000</td>\n","      <td>29718.000000</td>\n","      <td>29247.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>39975.000000</td>\n","      <td>39975.000000</td>\n","      <td>40221.000000</td>\n","      <td>39681.000000</td>\n","      <td>102.685142</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>47484.000000</td>\n","      <td>47484.000000</td>\n","      <td>47739.000000</td>\n","      <td>47200.000000</td>\n","      <td>188.982775</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>55763.000000</td>\n","      <td>55768.234837</td>\n","      <td>56130.000000</td>\n","      <td>55368.000000</td>\n","      <td>359.018477</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>68601.000000</td>\n","      <td>68601.000000</td>\n","      <td>68958.000000</td>\n","      <td>68450.000000</td>\n","      <td>11111.599499</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               open         close          high           low        volume\n","count   9257.000000   9257.000000   9257.000000   9257.000000   9262.000000\n","mean   47612.783557  47613.085106  47878.873927  47330.043473    326.231542\n","std     9104.971332   9104.860057   9120.726412   9085.465610    489.720237\n","min    29446.000000  29447.000000  29718.000000  29247.000000      0.000000\n","25%    39975.000000  39975.000000  40221.000000  39681.000000    102.685142\n","50%    47484.000000  47484.000000  47739.000000  47200.000000    188.982775\n","75%    55763.000000  55768.234837  56130.000000  55368.000000    359.018477\n","max    68601.000000  68601.000000  68958.000000  68450.000000  11111.599499"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["data_btc_resample.describe()"]},{"cell_type":"markdown","id":"vFJHyQDgItV8","metadata":{"id":"vFJHyQDgItV8"},"source":["Para generar el campo en el que observaremos si el Bitcoin subió o bajó de valor respecto de la hora anterior, desplazamos el precio de cierre y luego calculamos la diferencia con el de la hora de cada fila "]},{"cell_type":"code","execution_count":56,"id":"f1b6bcdf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1649988777460,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"f1b6bcdf","outputId":"47f2edce-0dfb-4aa3-9473-d06cb5533e6d"},"outputs":[{"data":{"text/plain":["time\n","2021-02-05 10:00:00    38128.000000\n","2021-02-05 11:00:00    37947.000000\n","2021-02-05 12:00:00    37810.933180\n","2021-02-05 13:00:00    37872.000000\n","2021-02-05 14:00:00    37371.000000\n","                           ...     \n","2022-02-26 03:00:00    39230.000000\n","2022-02-26 04:00:00    38795.739269\n","2022-02-26 05:00:00    38836.000000\n","2022-02-26 06:00:00    39069.000000\n","2022-02-26 07:00:00             NaN\n","Freq: H, Name: close, Length: 9262, dtype: float64"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["n = 1\n","close_hora_siguiente = data_btc_resample.close.shift(-n) \n","close_hora_siguiente"]},{"cell_type":"code","execution_count":57,"id":"a29dab13","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1649988777461,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"a29dab13","outputId":"fd9b08bd-afa3-4177-9b91-e1555c78ccee"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>open</th>\n","      <th>close</th>\n","      <th>high</th>\n","      <th>low</th>\n","      <th>volume</th>\n","      <th>evolucion_close</th>\n","    </tr>\n","    <tr>\n","      <th>time</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>38236.0</td>\n","      <td>38355.00000</td>\n","      <td>38366.0</td>\n","      <td>38175.000000</td>\n","      <td>78.510053</td>\n","      <td>227.00000</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 11:00:00</th>\n","      <td>38354.0</td>\n","      <td>38128.00000</td>\n","      <td>38366.0</td>\n","      <td>38022.000000</td>\n","      <td>157.987029</td>\n","      <td>181.00000</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 12:00:00</th>\n","      <td>38126.0</td>\n","      <td>37947.00000</td>\n","      <td>38309.0</td>\n","      <td>37918.654556</td>\n","      <td>197.929364</td>\n","      <td>136.06682</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 13:00:00</th>\n","      <td>37962.0</td>\n","      <td>37810.93318</td>\n","      <td>38183.0</td>\n","      <td>37701.000000</td>\n","      <td>414.629575</td>\n","      <td>-61.06682</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 14:00:00</th>\n","      <td>37811.0</td>\n","      <td>37872.00000</td>\n","      <td>37941.0</td>\n","      <td>37756.000000</td>\n","      <td>90.369899</td>\n","      <td>501.00000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                        open        close     high           low      volume  \\\n","time                                                                           \n","2021-02-05 10:00:00  38236.0  38355.00000  38366.0  38175.000000   78.510053   \n","2021-02-05 11:00:00  38354.0  38128.00000  38366.0  38022.000000  157.987029   \n","2021-02-05 12:00:00  38126.0  37947.00000  38309.0  37918.654556  197.929364   \n","2021-02-05 13:00:00  37962.0  37810.93318  38183.0  37701.000000  414.629575   \n","2021-02-05 14:00:00  37811.0  37872.00000  37941.0  37756.000000   90.369899   \n","\n","                     evolucion_close  \n","time                                  \n","2021-02-05 10:00:00        227.00000  \n","2021-02-05 11:00:00        181.00000  \n","2021-02-05 12:00:00        136.06682  \n","2021-02-05 13:00:00        -61.06682  \n","2021-02-05 14:00:00        501.00000  "]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["data_btc_resample['evolucion_close'] = data_btc_resample.close - close_hora_siguiente\n","data_btc_resample.head() "]},{"cell_type":"code","execution_count":58,"id":"f56dde91","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1649988777461,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"f56dde91","outputId":"358608ba-f136-41f8-fac4-6bcca632c0a2"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>open</th>\n","      <th>close</th>\n","      <th>high</th>\n","      <th>low</th>\n","      <th>volume</th>\n","      <th>evolucion_close</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>9257.000000</td>\n","      <td>9257.000000</td>\n","      <td>9257.000000</td>\n","      <td>9257.000000</td>\n","      <td>9262.000000</td>\n","      <td>9254.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>47612.783557</td>\n","      <td>47613.085106</td>\n","      <td>47878.873927</td>\n","      <td>47330.043473</td>\n","      <td>326.231542</td>\n","      <td>-0.079317</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>9104.971332</td>\n","      <td>9104.860057</td>\n","      <td>9120.726412</td>\n","      <td>9085.465610</td>\n","      <td>489.720237</td>\n","      <td>388.089231</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>29446.000000</td>\n","      <td>29447.000000</td>\n","      <td>29718.000000</td>\n","      <td>29247.000000</td>\n","      <td>0.000000</td>\n","      <td>-3878.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>39975.000000</td>\n","      <td>39975.000000</td>\n","      <td>40221.000000</td>\n","      <td>39681.000000</td>\n","      <td>102.685142</td>\n","      <td>-183.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>47484.000000</td>\n","      <td>47484.000000</td>\n","      <td>47739.000000</td>\n","      <td>47200.000000</td>\n","      <td>188.982775</td>\n","      <td>-2.914875</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>55763.000000</td>\n","      <td>55768.234837</td>\n","      <td>56130.000000</td>\n","      <td>55368.000000</td>\n","      <td>359.018477</td>\n","      <td>181.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>68601.000000</td>\n","      <td>68601.000000</td>\n","      <td>68958.000000</td>\n","      <td>68450.000000</td>\n","      <td>11111.599499</td>\n","      <td>4251.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               open         close          high           low        volume  \\\n","count   9257.000000   9257.000000   9257.000000   9257.000000   9262.000000   \n","mean   47612.783557  47613.085106  47878.873927  47330.043473    326.231542   \n","std     9104.971332   9104.860057   9120.726412   9085.465610    489.720237   \n","min    29446.000000  29447.000000  29718.000000  29247.000000      0.000000   \n","25%    39975.000000  39975.000000  40221.000000  39681.000000    102.685142   \n","50%    47484.000000  47484.000000  47739.000000  47200.000000    188.982775   \n","75%    55763.000000  55768.234837  56130.000000  55368.000000    359.018477   \n","max    68601.000000  68601.000000  68958.000000  68450.000000  11111.599499   \n","\n","       evolucion_close  \n","count      9254.000000  \n","mean         -0.079317  \n","std         388.089231  \n","min       -3878.000000  \n","25%        -183.000000  \n","50%          -2.914875  \n","75%         181.000000  \n","max        4251.000000  "]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["data_btc_resample.describe()"]},{"cell_type":"code","execution_count":59,"id":"18701e9b","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1649988777461,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"18701e9b","outputId":"cb366b21-2e68-4ce9-f27a-48f6444c7549"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>open</th>\n","      <th>close</th>\n","      <th>high</th>\n","      <th>low</th>\n","      <th>volume</th>\n","      <th>evolucion_close</th>\n","      <th>label</th>\n","    </tr>\n","    <tr>\n","      <th>time</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>38236.0</td>\n","      <td>38355.00000</td>\n","      <td>38366.0</td>\n","      <td>38175.000000</td>\n","      <td>78.510053</td>\n","      <td>227.00000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 11:00:00</th>\n","      <td>38354.0</td>\n","      <td>38128.00000</td>\n","      <td>38366.0</td>\n","      <td>38022.000000</td>\n","      <td>157.987029</td>\n","      <td>181.00000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 12:00:00</th>\n","      <td>38126.0</td>\n","      <td>37947.00000</td>\n","      <td>38309.0</td>\n","      <td>37918.654556</td>\n","      <td>197.929364</td>\n","      <td>136.06682</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 13:00:00</th>\n","      <td>37962.0</td>\n","      <td>37810.93318</td>\n","      <td>38183.0</td>\n","      <td>37701.000000</td>\n","      <td>414.629575</td>\n","      <td>-61.06682</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 14:00:00</th>\n","      <td>37811.0</td>\n","      <td>37872.00000</td>\n","      <td>37941.0</td>\n","      <td>37756.000000</td>\n","      <td>90.369899</td>\n","      <td>501.00000</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                        open        close     high           low      volume  \\\n","time                                                                           \n","2021-02-05 10:00:00  38236.0  38355.00000  38366.0  38175.000000   78.510053   \n","2021-02-05 11:00:00  38354.0  38128.00000  38366.0  38022.000000  157.987029   \n","2021-02-05 12:00:00  38126.0  37947.00000  38309.0  37918.654556  197.929364   \n","2021-02-05 13:00:00  37962.0  37810.93318  38183.0  37701.000000  414.629575   \n","2021-02-05 14:00:00  37811.0  37872.00000  37941.0  37756.000000   90.369899   \n","\n","                     evolucion_close  label  \n","time                                         \n","2021-02-05 10:00:00        227.00000      1  \n","2021-02-05 11:00:00        181.00000      1  \n","2021-02-05 12:00:00        136.06682      1  \n","2021-02-05 13:00:00        -61.06682      0  \n","2021-02-05 14:00:00        501.00000      1  "]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["data_btc_resample['label'] = (data_btc_resample.evolucion_close > 0).astype(int)\n","data_btc_resample.head()"]},{"cell_type":"markdown","id":"MW4i7eS1J28A","metadata":{"id":"MW4i7eS1J28A"},"source":["Redondeamos la hora de publicación de cada tweet para poder vincularlo con el label generado anteriormente en el dataset con los valores de Bitcoin"]},{"cell_type":"code","execution_count":null,"id":"f6af1cca","metadata":{"executionInfo":{"elapsed":13994,"status":"ok","timestamp":1649988936344,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"f6af1cca"},"outputs":[],"source":["#data_tweets_3.to_csv(root_path+'Data/data_tweets_3.csv')"]},{"cell_type":"code","execution_count":61,"id":"9bDQQKUI5TcI","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1649988936345,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"9bDQQKUI5TcI","outputId":"c331ecfc-76dc-4148-d01d-84d122ab1194"},"outputs":[{"data":{"text/plain":["0         2021-02-05 10:52:04\n","1         2021-02-05 10:52:06\n","2         2021-02-05 10:52:07\n","3         2021-02-05 10:57:05\n","4         2021-02-05 10:58:03\n","                  ...        \n","1290440   2022-02-18 23:59:27\n","1290441   2022-02-18 23:59:30\n","1290442   2022-02-18 23:59:30\n","1290443   2022-02-18 23:59:34\n","1290444                   NaT\n","Name: date, Length: 1290445, dtype: datetime64[ns]"]},"execution_count":61,"metadata":{},"output_type":"execute_result"}],"source":["data_tweets_3.date.shift(-1)"]},{"cell_type":"code","execution_count":62,"id":"21e69318","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":102845,"status":"ok","timestamp":1649989039186,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"21e69318","outputId":"85597475-497c-4627-f761-a8e9d10cd1d7"},"outputs":[{"data":{"text/plain":["[Timestamp('2021-02-05 10:00:00'),\n"," Timestamp('2021-02-05 10:00:00'),\n"," Timestamp('2021-02-05 10:00:00'),\n"," Timestamp('2021-02-05 10:00:00'),\n"," Timestamp('2021-02-05 10:00:00'),\n"," Timestamp('2021-02-05 10:00:00'),\n"," Timestamp('2021-02-05 10:00:00'),\n"," Timestamp('2021-02-05 10:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 11:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 12:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 13:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 14:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 15:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 16:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 17:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 18:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 19:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 20:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," Timestamp('2021-02-05 21:00:00'),\n"," ...]"]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["date_redondeado = [time.floor('H') for time in data_tweets_3.date]\n","date_redondeado"]},{"cell_type":"code","execution_count":63,"id":"b644b6d8","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":330},"executionInfo":{"elapsed":2305,"status":"ok","timestamp":1649989041485,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"b644b6d8","outputId":"1296ceab-5bdf-4306-a7c4-5fd95529ec03"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\MARIAN~1\\AppData\\Local\\Temp/ipykernel_27432/971523947.py:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data_tweets_3['date'] = date_redondeado\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_followers</th>\n","      <th>date</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>301.0</td>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>2⃣   Debunking 9 #Bitcoin Myths by @Patrick_Lo...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>301.0</td>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>📖  Weekend Read 📖\\n\\nKeen to learn about #cryp...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>301.0</td>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>4⃣  🎙️ Bloomberg LP #CryptoOutlook 2021 with @...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>301.0</td>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>5⃣   #Blockchain 50 2021 by @DelRayMan, @Forbe...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>163.0</td>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>#Amazing 😍\\n#Monopoly #Crypto #cryptocurrency ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   user_followers                date  \\\n","0           301.0 2021-02-05 10:00:00   \n","1           301.0 2021-02-05 10:00:00   \n","2           301.0 2021-02-05 10:00:00   \n","3           301.0 2021-02-05 10:00:00   \n","4           163.0 2021-02-05 10:00:00   \n","\n","                                                text  \n","0  2⃣   Debunking 9 #Bitcoin Myths by @Patrick_Lo...  \n","1  📖  Weekend Read 📖\\n\\nKeen to learn about #cryp...  \n","2  4⃣  🎙️ Bloomberg LP #CryptoOutlook 2021 with @...  \n","3  5⃣   #Blockchain 50 2021 by @DelRayMan, @Forbe...  \n","4  #Amazing 😍\\n#Monopoly #Crypto #cryptocurrency ...  "]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["data_tweets_3['date'] = date_redondeado\n","data_tweets_3.head()"]},{"cell_type":"code","execution_count":64,"id":"cfae999c","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":344},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1649989041486,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"cfae999c","outputId":"d2093bbd-7105-4109-ef83-dc6822d5b8c9"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\ProgramData\\Anaconda3\\envs\\dhdsblend2021\\lib\\site-packages\\pandas\\core\\frame.py:4167: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  return super().drop(\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_followers</th>\n","      <th>text</th>\n","    </tr>\n","    <tr>\n","      <th>date</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>2⃣   Debunking 9 #Bitcoin Myths by @Patrick_Lo...</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>📖  Weekend Read 📖\\n\\nKeen to learn about #cryp...</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>4⃣  🎙️ Bloomberg LP #CryptoOutlook 2021 with @...</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>5⃣   #Blockchain 50 2021 by @DelRayMan, @Forbe...</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>163.0</td>\n","      <td>#Amazing 😍\\n#Monopoly #Crypto #cryptocurrency ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     user_followers  \\\n","date                                  \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           163.0   \n","\n","                                                                  text  \n","date                                                                    \n","2021-02-05 10:00:00  2⃣   Debunking 9 #Bitcoin Myths by @Patrick_Lo...  \n","2021-02-05 10:00:00  📖  Weekend Read 📖\\n\\nKeen to learn about #cryp...  \n","2021-02-05 10:00:00  4⃣  🎙️ Bloomberg LP #CryptoOutlook 2021 with @...  \n","2021-02-05 10:00:00  5⃣   #Blockchain 50 2021 by @DelRayMan, @Forbe...  \n","2021-02-05 10:00:00  #Amazing 😍\\n#Monopoly #Crypto #cryptocurrency ...  "]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["data_tweets_3.index = data_tweets_3.date\n","data_tweets_3.drop('date', inplace=True, axis=1)\n","data_tweets_3.head()"]},{"cell_type":"code","execution_count":65,"id":"1557bcdf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1649989041487,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"1557bcdf","outputId":"9b3b098b-8bca-45e0-a8ce-288726d45791"},"outputs":[{"data":{"text/plain":["(1290445, 2)"]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["data_tweets_3.shape"]},{"cell_type":"code","execution_count":66,"id":"85e161b4","metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1649989041487,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"85e161b4"},"outputs":[],"source":["#data_tweets_3.drop_duplicates(['text'], keep='first') # dropear duplicados\n","#data_tweets_3.head()"]},{"cell_type":"code","execution_count":67,"id":"0ebe01a9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1649989041487,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"0ebe01a9","outputId":"20974a61-0bac-4c97-822b-5a9ef6bf9825"},"outputs":[{"data":{"text/plain":["(1290445, 2)"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["data_tweets_3.shape"]},{"cell_type":"code","execution_count":null,"id":"0e326432","metadata":{"executionInfo":{"elapsed":11801,"status":"ok","timestamp":1649989053279,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"0e326432"},"outputs":[],"source":["#data_tweets_3.to_csv(root_path+'Data/data_tweets.csv')"]},{"cell_type":"code","execution_count":null,"id":"742c16eb","metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1649989053280,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"742c16eb"},"outputs":[],"source":["#data_btc_resample.to_csv(root_path+'Data/data_btcusd.csv')"]},{"cell_type":"markdown","id":"jp20vyppAO1d","metadata":{"id":"jp20vyppAO1d"},"source":["### Determinación de ventana y Text Mining"]},{"cell_type":"code","execution_count":69,"id":"0ed731b5","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":502,"status":"ok","timestamp":1649989238651,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"0ed731b5","outputId":"5a1ae3dc-2403-48c3-b2f9-154926ffeaff"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>time</th>\n","      <th>open</th>\n","      <th>close</th>\n","      <th>high</th>\n","      <th>low</th>\n","      <th>volume</th>\n","      <th>evolucion_close</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>38236.0</td>\n","      <td>38355.00000</td>\n","      <td>38366.0</td>\n","      <td>38175.000000</td>\n","      <td>78.510053</td>\n","      <td>227.00000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2021-02-05 11:00:00</td>\n","      <td>38354.0</td>\n","      <td>38128.00000</td>\n","      <td>38366.0</td>\n","      <td>38022.000000</td>\n","      <td>157.987029</td>\n","      <td>181.00000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2021-02-05 12:00:00</td>\n","      <td>38126.0</td>\n","      <td>37947.00000</td>\n","      <td>38309.0</td>\n","      <td>37918.654556</td>\n","      <td>197.929364</td>\n","      <td>136.06682</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2021-02-05 13:00:00</td>\n","      <td>37962.0</td>\n","      <td>37810.93318</td>\n","      <td>38183.0</td>\n","      <td>37701.000000</td>\n","      <td>414.629575</td>\n","      <td>-61.06682</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2021-02-05 14:00:00</td>\n","      <td>37811.0</td>\n","      <td>37872.00000</td>\n","      <td>37941.0</td>\n","      <td>37756.000000</td>\n","      <td>90.369899</td>\n","      <td>501.00000</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                  time     open        close     high           low  \\\n","0  2021-02-05 10:00:00  38236.0  38355.00000  38366.0  38175.000000   \n","1  2021-02-05 11:00:00  38354.0  38128.00000  38366.0  38022.000000   \n","2  2021-02-05 12:00:00  38126.0  37947.00000  38309.0  37918.654556   \n","3  2021-02-05 13:00:00  37962.0  37810.93318  38183.0  37701.000000   \n","4  2021-02-05 14:00:00  37811.0  37872.00000  37941.0  37756.000000   \n","\n","       volume  evolucion_close  label  \n","0   78.510053        227.00000      1  \n","1  157.987029        181.00000      1  \n","2  197.929364        136.06682      1  \n","3  414.629575        -61.06682      0  \n","4   90.369899        501.00000      1  "]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["data_btcusd=pd.read_csv(root_path+'Data/data_btcusd.csv')\n","\n","data_btcusd.head()"]},{"cell_type":"code","execution_count":70,"id":"30460bf1","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"elapsed":484,"status":"ok","timestamp":1649989483692,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"30460bf1","outputId":"17cbc613-f236-4ae4-e6bc-f4ed302e6af0"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>open</th>\n","      <th>close</th>\n","      <th>high</th>\n","      <th>low</th>\n","      <th>volume</th>\n","      <th>evolucion_close</th>\n","      <th>label</th>\n","    </tr>\n","    <tr>\n","      <th>time</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>38236.0</td>\n","      <td>38355.00000</td>\n","      <td>38366.0</td>\n","      <td>38175.000000</td>\n","      <td>78.510053</td>\n","      <td>227.00000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 11:00:00</th>\n","      <td>38354.0</td>\n","      <td>38128.00000</td>\n","      <td>38366.0</td>\n","      <td>38022.000000</td>\n","      <td>157.987029</td>\n","      <td>181.00000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 12:00:00</th>\n","      <td>38126.0</td>\n","      <td>37947.00000</td>\n","      <td>38309.0</td>\n","      <td>37918.654556</td>\n","      <td>197.929364</td>\n","      <td>136.06682</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 13:00:00</th>\n","      <td>37962.0</td>\n","      <td>37810.93318</td>\n","      <td>38183.0</td>\n","      <td>37701.000000</td>\n","      <td>414.629575</td>\n","      <td>-61.06682</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 14:00:00</th>\n","      <td>37811.0</td>\n","      <td>37872.00000</td>\n","      <td>37941.0</td>\n","      <td>37756.000000</td>\n","      <td>90.369899</td>\n","      <td>501.00000</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                        open        close     high           low      volume  \\\n","time                                                                           \n","2021-02-05 10:00:00  38236.0  38355.00000  38366.0  38175.000000   78.510053   \n","2021-02-05 11:00:00  38354.0  38128.00000  38366.0  38022.000000  157.987029   \n","2021-02-05 12:00:00  38126.0  37947.00000  38309.0  37918.654556  197.929364   \n","2021-02-05 13:00:00  37962.0  37810.93318  38183.0  37701.000000  414.629575   \n","2021-02-05 14:00:00  37811.0  37872.00000  37941.0  37756.000000   90.369899   \n","\n","                     evolucion_close  label  \n","time                                         \n","2021-02-05 10:00:00        227.00000      1  \n","2021-02-05 11:00:00        181.00000      1  \n","2021-02-05 12:00:00        136.06682      1  \n","2021-02-05 13:00:00        -61.06682      0  \n","2021-02-05 14:00:00        501.00000      1  "]},"execution_count":70,"metadata":{},"output_type":"execute_result"}],"source":["data_btcusd.set_index('time', drop=True, inplace=True)\n","data_btcusd.head()"]},{"cell_type":"code","execution_count":71,"id":"3982393a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":483,"status":"ok","timestamp":1649989498010,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"3982393a","outputId":"0cf74258-4525-4d8a-e605-c2c6dda26bee"},"outputs":[{"data":{"text/plain":["(9262, 7)"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["data_btcusd.shape"]},{"cell_type":"code","execution_count":72,"id":"54364f85","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":7104,"status":"ok","timestamp":1649990384795,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"54364f85","outputId":"d41a51b6-5594-4760-9fa3-f168185f7937"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>user_followers</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>301.0</td>\n","      <td>2⃣   Debunking 9 #Bitcoin Myths by @Patrick_Lo...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>301.0</td>\n","      <td>📖  Weekend Read 📖\\n\\nKeen to learn about #cryp...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>301.0</td>\n","      <td>4⃣  🎙️ Bloomberg LP #CryptoOutlook 2021 with @...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>301.0</td>\n","      <td>5⃣   #Blockchain 50 2021 by @DelRayMan, @Forbe...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>163.0</td>\n","      <td>#Amazing 😍\\n#Monopoly #Crypto #cryptocurrency ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                  date  user_followers  \\\n","0  2021-02-05 10:00:00           301.0   \n","1  2021-02-05 10:00:00           301.0   \n","2  2021-02-05 10:00:00           301.0   \n","3  2021-02-05 10:00:00           301.0   \n","4  2021-02-05 10:00:00           163.0   \n","\n","                                                text  \n","0  2⃣   Debunking 9 #Bitcoin Myths by @Patrick_Lo...  \n","1  📖  Weekend Read 📖\\n\\nKeen to learn about #cryp...  \n","2  4⃣  🎙️ Bloomberg LP #CryptoOutlook 2021 with @...  \n","3  5⃣   #Blockchain 50 2021 by @DelRayMan, @Forbe...  \n","4  #Amazing 😍\\n#Monopoly #Crypto #cryptocurrency ...  "]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["data_tweets=pd.read_csv(root_path+'Data/data_tweets.csv')\n","\n","data_tweets.head()"]},{"cell_type":"code","execution_count":73,"id":"39219601","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"elapsed":434,"status":"ok","timestamp":1649990388763,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"39219601","outputId":"075b4eb3-6336-41f7-9a9e-d6048ec80f56"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_followers</th>\n","      <th>text</th>\n","    </tr>\n","    <tr>\n","      <th>date</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>2⃣   Debunking 9 #Bitcoin Myths by @Patrick_Lo...</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>📖  Weekend Read 📖\\n\\nKeen to learn about #cryp...</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>4⃣  🎙️ Bloomberg LP #CryptoOutlook 2021 with @...</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>5⃣   #Blockchain 50 2021 by @DelRayMan, @Forbe...</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>163.0</td>\n","      <td>#Amazing 😍\\n#Monopoly #Crypto #cryptocurrency ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     user_followers  \\\n","date                                  \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           163.0   \n","\n","                                                                  text  \n","date                                                                    \n","2021-02-05 10:00:00  2⃣   Debunking 9 #Bitcoin Myths by @Patrick_Lo...  \n","2021-02-05 10:00:00  📖  Weekend Read 📖\\n\\nKeen to learn about #cryp...  \n","2021-02-05 10:00:00  4⃣  🎙️ Bloomberg LP #CryptoOutlook 2021 with @...  \n","2021-02-05 10:00:00  5⃣   #Blockchain 50 2021 by @DelRayMan, @Forbe...  \n","2021-02-05 10:00:00  #Amazing 😍\\n#Monopoly #Crypto #cryptocurrency ...  "]},"execution_count":73,"metadata":{},"output_type":"execute_result"}],"source":["data_tweets.set_index('date', drop=True, inplace=True)\n","data_tweets.head()"]},{"cell_type":"code","execution_count":null,"id":"9367b2e1","metadata":{"executionInfo":{"elapsed":443,"status":"ok","timestamp":1649990393642,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"9367b2e1"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"e753cad2","metadata":{"id":"e753cad2"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":74,"id":"711a14c5","metadata":{"id":"711a14c5"},"outputs":[],"source":["# ver Nans del final\n","# generar n para ventana de tiempo entre tweet y comportamiento de mercado"]},{"cell_type":"markdown","id":"qc57tpmJKdkY","metadata":{"id":"qc57tpmJKdkY"},"source":["Desplazamos el label generado en el dataset con valores de Bitcoin para poder hacer un join con el dataset de tweets y vincular los tweets con el comportamiento de la cryptomoneda en un plazo determinado de horas"]},{"cell_type":"code","execution_count":75,"id":"69b3e5a9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":605,"status":"ok","timestamp":1649991507737,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"69b3e5a9","outputId":"b3ebbe51-0e0f-41c4-8155-3489859f3c17"},"outputs":[{"data":{"text/plain":["time\n","2021-02-05 10:00:00    0.0\n","2021-02-05 11:00:00    0.0\n","2021-02-05 12:00:00    1.0\n","2021-02-05 13:00:00    1.0\n","2021-02-05 14:00:00    0.0\n","                      ... \n","2022-02-26 03:00:00    NaN\n","2022-02-26 04:00:00    NaN\n","2022-02-26 05:00:00    NaN\n","2022-02-26 06:00:00    NaN\n","2022-02-26 07:00:00    NaN\n","Name: label, Length: 9262, dtype: float64"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["n_label = 24\n","ventana_label = data_btcusd.label.shift(-n_label) #se puede cambiar n\n","ventana_label"]},{"cell_type":"markdown","id":"9APqbfd1Kzwa","metadata":{"id":"9APqbfd1Kzwa"},"source":["Llamamos 'Target' al label luego de haberlo desfazado n cantidad de horas"]},{"cell_type":"code","execution_count":76,"id":"e009d55c","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"elapsed":86,"status":"ok","timestamp":1649991508500,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"e009d55c","outputId":"0caab184-1bb1-4788-f653-6eebe44be63e"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>open</th>\n","      <th>close</th>\n","      <th>high</th>\n","      <th>low</th>\n","      <th>volume</th>\n","      <th>evolucion_close</th>\n","      <th>label</th>\n","      <th>target</th>\n","    </tr>\n","    <tr>\n","      <th>time</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>38236.0</td>\n","      <td>38355.00000</td>\n","      <td>38366.0</td>\n","      <td>38175.000000</td>\n","      <td>78.510053</td>\n","      <td>227.00000</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 11:00:00</th>\n","      <td>38354.0</td>\n","      <td>38128.00000</td>\n","      <td>38366.0</td>\n","      <td>38022.000000</td>\n","      <td>157.987029</td>\n","      <td>181.00000</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 12:00:00</th>\n","      <td>38126.0</td>\n","      <td>37947.00000</td>\n","      <td>38309.0</td>\n","      <td>37918.654556</td>\n","      <td>197.929364</td>\n","      <td>136.06682</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 13:00:00</th>\n","      <td>37962.0</td>\n","      <td>37810.93318</td>\n","      <td>38183.0</td>\n","      <td>37701.000000</td>\n","      <td>414.629575</td>\n","      <td>-61.06682</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 14:00:00</th>\n","      <td>37811.0</td>\n","      <td>37872.00000</td>\n","      <td>37941.0</td>\n","      <td>37756.000000</td>\n","      <td>90.369899</td>\n","      <td>501.00000</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                        open        close     high           low      volume  \\\n","time                                                                           \n","2021-02-05 10:00:00  38236.0  38355.00000  38366.0  38175.000000   78.510053   \n","2021-02-05 11:00:00  38354.0  38128.00000  38366.0  38022.000000  157.987029   \n","2021-02-05 12:00:00  38126.0  37947.00000  38309.0  37918.654556  197.929364   \n","2021-02-05 13:00:00  37962.0  37810.93318  38183.0  37701.000000  414.629575   \n","2021-02-05 14:00:00  37811.0  37872.00000  37941.0  37756.000000   90.369899   \n","\n","                     evolucion_close  label  target  \n","time                                                 \n","2021-02-05 10:00:00        227.00000      1     0.0  \n","2021-02-05 11:00:00        181.00000      1     0.0  \n","2021-02-05 12:00:00        136.06682      1     1.0  \n","2021-02-05 13:00:00        -61.06682      0     1.0  \n","2021-02-05 14:00:00        501.00000      1     0.0  "]},"execution_count":76,"metadata":{},"output_type":"execute_result"}],"source":["data_btcusd['target'] = ventana_label\n","data_btcusd.head()"]},{"cell_type":"code","execution_count":77,"id":"8ndmOygTIndZ","metadata":{"executionInfo":{"elapsed":86,"status":"ok","timestamp":1649991508501,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"8ndmOygTIndZ"},"outputs":[],"source":["data_btcusd.dropna(axis=0, inplace=True)"]},{"cell_type":"code","execution_count":78,"id":"9730329e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":86,"status":"ok","timestamp":1649991508501,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"9730329e","outputId":"3e4d6f00-e469-468a-e795-39e49684882c"},"outputs":[{"data":{"text/plain":["0"]},"execution_count":78,"metadata":{},"output_type":"execute_result"}],"source":["data_btcusd['target'].isna().sum()"]},{"cell_type":"markdown","id":"6-7gv710LA8_","metadata":{"id":"6-7gv710LA8_"},"source":["Hacemos el join de la variable target con el dataset de tweets"]},{"cell_type":"code","execution_count":79,"id":"c8bca4f6","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":861,"status":"ok","timestamp":1649991509357,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"c8bca4f6","outputId":"5defa6e2-58be-44e1-f9b4-cdc1da99936f"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_followers</th>\n","      <th>text</th>\n","      <th>volume</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>2⃣   Debunking 9 #Bitcoin Myths by @Patrick_Lo...</td>\n","      <td>78.510053</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>📖  Weekend Read 📖\\n\\nKeen to learn about #cryp...</td>\n","      <td>78.510053</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>4⃣  🎙️ Bloomberg LP #CryptoOutlook 2021 with @...</td>\n","      <td>78.510053</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>5⃣   #Blockchain 50 2021 by @DelRayMan, @Forbe...</td>\n","      <td>78.510053</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>163.0</td>\n","      <td>#Amazing 😍\\n#Monopoly #Crypto #cryptocurrency ...</td>\n","      <td>78.510053</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2022-01-13 15:00:00</th>\n","      <td>221770.0</td>\n","      <td>Ugly LTF rejection on #Bitcoin hopefully we ar...</td>\n","      <td>80.718062</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2022-01-13 15:00:00</th>\n","      <td>8241.0</td>\n","      <td>Polynesian nation of #Tonga announced its plan...</td>\n","      <td>80.718062</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2022-01-13 15:00:00</th>\n","      <td>4609.0</td>\n","      <td>#Bitcoin now = 130M users\\nInternet in 1997 = ...</td>\n","      <td>80.718062</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2022-01-13 15:00:00</th>\n","      <td>14520.0</td>\n","      <td>#Bitcoin Miner Rhodium’s Planned IPO Values It...</td>\n","      <td>80.718062</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2022-01-13 15:00:00</th>\n","      <td>1450.0</td>\n","      <td>Nobody paid attention to the publication date ...</td>\n","      <td>80.718062</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1150000 rows × 4 columns</p>\n","</div>"],"text/plain":["                     user_followers  \\\n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           163.0   \n","...                             ...   \n","2022-01-13 15:00:00        221770.0   \n","2022-01-13 15:00:00          8241.0   \n","2022-01-13 15:00:00          4609.0   \n","2022-01-13 15:00:00         14520.0   \n","2022-01-13 15:00:00          1450.0   \n","\n","                                                                  text  \\\n","2021-02-05 10:00:00  2⃣   Debunking 9 #Bitcoin Myths by @Patrick_Lo...   \n","2021-02-05 10:00:00  📖  Weekend Read 📖\\n\\nKeen to learn about #cryp...   \n","2021-02-05 10:00:00  4⃣  🎙️ Bloomberg LP #CryptoOutlook 2021 with @...   \n","2021-02-05 10:00:00  5⃣   #Blockchain 50 2021 by @DelRayMan, @Forbe...   \n","2021-02-05 10:00:00  #Amazing 😍\\n#Monopoly #Crypto #cryptocurrency ...   \n","...                                                                ...   \n","2022-01-13 15:00:00  Ugly LTF rejection on #Bitcoin hopefully we ar...   \n","2022-01-13 15:00:00  Polynesian nation of #Tonga announced its plan...   \n","2022-01-13 15:00:00  #Bitcoin now = 130M users\\nInternet in 1997 = ...   \n","2022-01-13 15:00:00  #Bitcoin Miner Rhodium’s Planned IPO Values It...   \n","2022-01-13 15:00:00  Nobody paid attention to the publication date ...   \n","\n","                        volume  target  \n","2021-02-05 10:00:00  78.510053     0.0  \n","2021-02-05 10:00:00  78.510053     0.0  \n","2021-02-05 10:00:00  78.510053     0.0  \n","2021-02-05 10:00:00  78.510053     0.0  \n","2021-02-05 10:00:00  78.510053     0.0  \n","...                        ...     ...  \n","2022-01-13 15:00:00  80.718062     0.0  \n","2022-01-13 15:00:00  80.718062     0.0  \n","2022-01-13 15:00:00  80.718062     0.0  \n","2022-01-13 15:00:00  80.718062     0.0  \n","2022-01-13 15:00:00  80.718062     0.0  \n","\n","[1150000 rows x 4 columns]"]},"execution_count":79,"metadata":{},"output_type":"execute_result"}],"source":["data = data_tweets.join(data_btcusd[['volume', 'target']], how='left')\n","data"]},{"cell_type":"code","execution_count":80,"id":"gTjbuTt0-7UC","metadata":{"executionInfo":{"elapsed":2529,"status":"ok","timestamp":1649991511883,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"gTjbuTt0-7UC"},"outputs":[],"source":["# convertimos todo a minúscula\n","data.text = [x.lower() for x in data.text]"]},{"cell_type":"code","execution_count":81,"id":"k274-6XZ-7UD","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1649991511884,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"k274-6XZ-7UD","outputId":"53cf1ce3-04d8-4e32-fd45-253c53de13c4"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_followers</th>\n","      <th>text</th>\n","      <th>volume</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>2⃣   debunking 9 #bitcoin myths by @patrick_lo...</td>\n","      <td>78.510053</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>📖  weekend read 📖\\n\\nkeen to learn about #cryp...</td>\n","      <td>78.510053</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>4⃣  🎙️ bloomberg lp #cryptooutlook 2021 with @...</td>\n","      <td>78.510053</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>5⃣   #blockchain 50 2021 by @delrayman, @forbe...</td>\n","      <td>78.510053</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>163.0</td>\n","      <td>#amazing 😍\\n#monopoly #crypto #cryptocurrency ...</td>\n","      <td>78.510053</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     user_followers  \\\n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           163.0   \n","\n","                                                                  text  \\\n","2021-02-05 10:00:00  2⃣   debunking 9 #bitcoin myths by @patrick_lo...   \n","2021-02-05 10:00:00  📖  weekend read 📖\\n\\nkeen to learn about #cryp...   \n","2021-02-05 10:00:00  4⃣  🎙️ bloomberg lp #cryptooutlook 2021 with @...   \n","2021-02-05 10:00:00  5⃣   #blockchain 50 2021 by @delrayman, @forbe...   \n","2021-02-05 10:00:00  #amazing 😍\\n#monopoly #crypto #cryptocurrency ...   \n","\n","                        volume  target  \n","2021-02-05 10:00:00  78.510053     0.0  \n","2021-02-05 10:00:00  78.510053     0.0  \n","2021-02-05 10:00:00  78.510053     0.0  \n","2021-02-05 10:00:00  78.510053     0.0  \n","2021-02-05 10:00:00  78.510053     0.0  "]},"execution_count":81,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"code","execution_count":82,"id":"fHPjAbTT-7UD","metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1649991511884,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"fHPjAbTT-7UD"},"outputs":[],"source":["# eliminamos menciones, hashtags, etc\n","import re\n","import string\n","\n","mencion = re.compile(\"@\\S+\")\n","links = re.compile(\"https*\\S+\")\n","hashtags = re.compile(\"#\\S+\")\n","apostrofes = re.compile(\"\\'\\w+\")\n","puntuaciones = re.compile('[%s]' % re.escape(string.punctuation))\n","numeros = re.compile(r'\\w*\\d+\\w*')\n","espacios = re.compile('\\s{2,}')#(' +')\n","html = re.compile('<.*?>') \n","alfanumericos = re.compile(\"[^a-z0-9]\")\n","aa = re.compile(\"aa\\S+\")\n","def eliminar(x):\n","    clean_mencion = re.sub(mencion, \" \", x)\n","    clean_links = re.sub(links, \" \", clean_mencion)\n","    clean_hashtags = re.sub(hashtags, \" \", clean_links)\n","    clean_apostrofes = re.sub(apostrofes, '', clean_hashtags)\n","    clean_puntuaciones = re.sub(puntuaciones, '', clean_apostrofes)\n","    clean_numeros = re.sub(numeros, '', clean_puntuaciones)\n","    clean_text = re.sub(html, '', clean_numeros)\n","    clean_alfanumericos = re.sub(alfanumericos,\" \", clean_text)\n","    clean_aa = re.sub(aa,\" \", clean_alfanumericos)\n","    clean_espacios = re.sub(espacios,' ', clean_aa)\n","    return clean_espacios\n"]},{"cell_type":"code","execution_count":83,"id":"Meuza3QV-7UD","metadata":{"executionInfo":{"elapsed":65323,"status":"ok","timestamp":1649991577202,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"Meuza3QV-7UD"},"outputs":[],"source":["limpieza_2 = [eliminar(x) for x in data.text]"]},{"cell_type":"code","execution_count":84,"id":"j8Y0c975-7UE","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1649991577203,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"j8Y0c975-7UE","outputId":"5d90e71f-4227-4011-ac15-eecace163a4c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tweet original: \n"," 2⃣   debunking 9 #bitcoin myths by @patrick_lowry_  ⬇️  \n","\n","#cryptocurrency #bitcoin #crypto #blockchain #btc… https://t.co/2cm83fub2n\n","\n","Tweet cleaned: \n","  debunking myths by \n","Tweet original: \n"," 📖  weekend read 📖\n","\n","keen to learn about #crypto assets? check out our reading list! \n","1⃣   2021 cryptomarket outlook… https://t.co/opiev94qzl\n","\n","Tweet cleaned: \n","  weekend read keen to learn about assets check out our reading list cryptomarket outlook \n","Tweet original: \n"," 4⃣  🎙️ bloomberg lp #cryptooutlook 2021 with @mikemcglone11 ⬇️\n","\n","#cryptocurrency #bitcoin #crypto #blockchain #btc… https://t.co/gc3vngap6v\n","\n","Tweet cleaned: \n","  bloomberg lp with \n","Tweet original: \n"," 5⃣   #blockchain 50 2021 by @delrayman, @forbes , @forbescrypto  ⬇️\n","\n","#cryptocurrency #bitcoin #crypto #blockchain… https://t.co/l3xj7j49fx\n","\n","Tweet cleaned: \n","  by \n","Tweet original: \n"," #amazing 😍\n","#monopoly #crypto #cryptocurrency #cryptocurrencies #cryptonews #cryptotrading #ripple #xrp… https://t.co/4dqtzsemup\n","\n","Tweet cleaned: \n","  \n","Tweet original: \n"," @julswap $juld $bnb #binance #bsc #binancesmartchain #btc #bitcoin $btc $eth $uni $sushi $cake #1inch $link  $xrp… https://t.co/yxsqclje2j\n","\n","Tweet cleaned: \n","  juld bnb btc eth uni sushi cake link xrp \n","Tweet original: \n"," amazoncoin = 100% love\n","\n","💚 👉👉 https://t.co/gydszxkino\n","\n","$ama #amazoncoin #crypto #defi #cryptocurrency… https://t.co/ri88dgetwg\n","\n","Tweet cleaned: \n"," amazoncoin love ama \n","Tweet original: \n"," #bitcoin braces for $48,000 as inverse head-and-shoulders favor #btc bulls\n","$btc/usd fades bounce off $36,192 while… https://t.co/8uu0a1rn2w\n","\n","Tweet cleaned: \n","  braces for as inverse headandshoulders favor bulls btcusd fades bounce off while \n","Tweet original: \n"," bitcoin: $37,412.78\n"," -0.46% (-$174.48)\n","high: $37,916.21\n","low: $36,200.10\n","volume: 400\n","\n","$btc #btc #bitcoin\n","\n","Tweet cleaned: \n"," bitcoin high low volume btc \n","Tweet original: \n"," bitcoin - btc\n","price: $37,399.74\n","change in 1h: -0.64178052%\n","market cap: $696,383,439,242.75\n","ranking: 1\n","#bitcoin #btc\n","\n","Tweet cleaned: \n"," bitcoin btc price change in market cap ranking \n"]}],"source":["for i in range(10):\n","  print(f\"Tweet original: \\n {data.text[i]}\",)\n","  print(f\"\\nTweet cleaned: \\n {limpieza_2[i]}\",)\n"]},{"cell_type":"code","execution_count":85,"id":"4BOfVFlo-7UE","metadata":{"executionInfo":{"elapsed":566,"status":"ok","timestamp":1649991577765,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"4BOfVFlo-7UE"},"outputs":[],"source":["data.text = limpieza_2"]},{"cell_type":"code","execution_count":86,"id":"W1BAhuTr-7UE","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1649991577766,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"W1BAhuTr-7UE","outputId":"23227275-5b5c-4521-b0f9-0a8e8255e6f0"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_followers</th>\n","      <th>text</th>\n","      <th>volume</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>debunking myths by</td>\n","      <td>78.510053</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>weekend read keen to learn about assets check...</td>\n","      <td>78.510053</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>bloomberg lp with</td>\n","      <td>78.510053</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>by</td>\n","      <td>78.510053</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>163.0</td>\n","      <td></td>\n","      <td>78.510053</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     user_followers  \\\n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           163.0   \n","\n","                                                                  text  \\\n","2021-02-05 10:00:00                                debunking myths by    \n","2021-02-05 10:00:00   weekend read keen to learn about assets check...   \n","2021-02-05 10:00:00                                 bloomberg lp with    \n","2021-02-05 10:00:00                                                by    \n","2021-02-05 10:00:00                                                      \n","\n","                        volume  target  \n","2021-02-05 10:00:00  78.510053     0.0  \n","2021-02-05 10:00:00  78.510053     0.0  \n","2021-02-05 10:00:00  78.510053     0.0  \n","2021-02-05 10:00:00  78.510053     0.0  \n","2021-02-05 10:00:00  78.510053     0.0  "]},"execution_count":86,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"markdown","id":"W6hoCRcEk9wd","metadata":{"id":"W6hoCRcEk9wd"},"source":["Para facilitar el procesamiento, exportamos el dataset generado con cada una de las ventanas de tiempo."]},{"cell_type":"code","execution_count":87,"id":"237ab50e","metadata":{"executionInfo":{"elapsed":7945,"status":"ok","timestamp":1649991598654,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"237ab50e"},"outputs":[],"source":["#data.to_csv(root_path+'Data/data_24h_prep.csv')"]},{"cell_type":"markdown","id":"Y7pdPRNpDD8Z","metadata":{"id":"Y7pdPRNpDD8Z"},"source":["### Modelling Vectorizer"]},{"cell_type":"code","execution_count":94,"id":"f5e1a040","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["^C\n","Note: you may need to restart the kernel to use updated packages.\n","Collecting xgboost\n","  Downloading xgboost-1.5.2-py3-none-win_amd64.whl (106.6 MB)\n","Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\envs\\dhdsblend2021\\lib\\site-packages (from xgboost) (1.19.2)\n","Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\envs\\dhdsblend2021\\lib\\site-packages (from xgboost) (1.5.2)\n","Installing collected packages: xgboost\n","Successfully installed xgboost-1.5.2\n","Collecting xgboost\n","  Downloading xgboost-1.5.2-py3-none-win_amd64.whl (106.6 MB)\n","Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\envs\\dhdsblend2021\\lib\\site-packages (from xgboost) (1.5.2)\n","Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\envs\\dhdsblend2021\\lib\\site-packages (from xgboost) (1.19.2)\n","Installing collected packages: xgboost\n","Successfully installed xgboost-1.5.2\n"]}],"source":["pip install xgboost"]},{"cell_type":"code","execution_count":95,"id":"0eb7cc21","metadata":{"id":"0eb7cc21"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix, recall_score, precision_score, precision_recall_curve,auc,mean_squared_error\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.model_selection import KFold\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.model_selection import GridSearchCV,StratifiedKFold,train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","from sklearn import tree\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.pipeline import Pipeline\n","import xgboost as xgb\n","\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import GridSearchCV\n"]},{"cell_type":"code","execution_count":96,"id":"de976b7b","metadata":{"executionInfo":{"elapsed":850,"status":"ok","timestamp":1649982425818,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"de976b7b"},"outputs":[],"source":["import pandas as pd\n","import datetime as dt\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":23,"id":"d342f7c0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":504,"status":"ok","timestamp":1649983541217,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"d342f7c0","outputId":"776b2615-160c-47f4-be45-3573818e984d"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to C:\\Users\\Mariano\n","[nltk_data]     desktop\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to C:\\Users\\Mariano\n","[nltk_data]     desktop\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to C:\\Users\\Mariano\n","[nltk_data]     desktop\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.model_selection import GridSearchCV,StratifiedKFold,train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","import nltk\n","nltk.download('punkt')   \n","nltk.download('stopwords')\n","nltk.download('wordnet')   \n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from nltk.corpus import stopwords \n","from nltk.stem import PorterStemmer\n","from nltk.stem import LancasterStemmer\n","from nltk.stem import WordNetLemmatizer\n","from nltk.stem.snowball import SnowballStemmer\n","from sklearn.feature_extraction.text import CountVectorizer\n","#from google.colab import drive"]},{"cell_type":"code","execution_count":null,"id":"dlbqGy5bDVDx","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26073,"status":"ok","timestamp":1649982455667,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"dlbqGy5bDVDx","outputId":"3510c973-c947-4054-f20e-99327822ae63"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive/\n"]}],"source":["#from google.colab import drive\n","#drive.mount('/content/gdrive/')\n","#root_path = 'gdrive/MyDrive/Colab Notebooks/'  "]},{"cell_type":"code","execution_count":100,"id":"c969cabb","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":3970,"status":"ok","timestamp":1649993743975,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"c969cabb","outputId":"d99e7876-bee7-4399-cef1-72ae7a9e2386"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_followers</th>\n","      <th>text</th>\n","      <th>volume</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>debunking myths by</td>\n","      <td>78.510053</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>weekend read keen to learn about assets check...</td>\n","      <td>78.510053</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>bloomberg lp with</td>\n","      <td>78.510053</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>by</td>\n","      <td>78.510053</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>163.0</td>\n","      <td></td>\n","      <td>78.510053</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     user_followers  \\\n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           163.0   \n","\n","                                                                  text  \\\n","2021-02-05 10:00:00                                debunking myths by    \n","2021-02-05 10:00:00   weekend read keen to learn about assets check...   \n","2021-02-05 10:00:00                                 bloomberg lp with    \n","2021-02-05 10:00:00                                                by    \n","2021-02-05 10:00:00                                                      \n","\n","                        volume  target  \n","2021-02-05 10:00:00  78.510053     0.0  \n","2021-02-05 10:00:00  78.510053     0.0  \n","2021-02-05 10:00:00  78.510053     0.0  \n","2021-02-05 10:00:00  78.510053     0.0  \n","2021-02-05 10:00:00  78.510053     0.0  "]},"execution_count":100,"metadata":{},"output_type":"execute_result"}],"source":["data_12 = pd.read_csv(root_path+'Data/data_24h_prep.csv')\n","#largo = data.shape[0]\n","data.head()"]},{"cell_type":"code","execution_count":102,"id":"0e7bf973","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1649993744685,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"0e7bf973","outputId":"e3fba67b-3209-4bc2-f29c-5009b9de3faa"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Fecha_hora</th>\n","      <th>user_followers</th>\n","      <th>text</th>\n","      <th>volume</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>301.0</td>\n","      <td>debunking myths by</td>\n","      <td>78.510053</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>301.0</td>\n","      <td>weekend read keen to learn about assets check...</td>\n","      <td>78.510053</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>301.0</td>\n","      <td>bloomberg lp with</td>\n","      <td>78.510053</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>301.0</td>\n","      <td>by</td>\n","      <td>78.510053</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>163.0</td>\n","      <td></td>\n","      <td>78.510053</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            Fecha_hora  user_followers  \\\n","0  2021-02-05 10:00:00           301.0   \n","1  2021-02-05 10:00:00           301.0   \n","2  2021-02-05 10:00:00           301.0   \n","3  2021-02-05 10:00:00           301.0   \n","4  2021-02-05 10:00:00           163.0   \n","\n","                                                text     volume  target  \n","0                                debunking myths by   78.510053     0.0  \n","1   weekend read keen to learn about assets check...  78.510053     0.0  \n","2                                 bloomberg lp with   78.510053     0.0  \n","3                                                by   78.510053     0.0  \n","4                                                     78.510053     0.0  "]},"execution_count":102,"metadata":{},"output_type":"execute_result"}],"source":["columnas = ['Fecha_hora', 'user_followers', 'text', 'volume', 'target']\n","data_12.columns = columnas\n","data_12.head()"]},{"cell_type":"code","execution_count":111,"id":"aef271ce","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20070,"status":"ok","timestamp":1649993768211,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"aef271ce","outputId":"3deecbc1-d5c3-471e-c6a4-3c654cbe0a15"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"," Clase  Bull\n","['buy' 'last' 'like' 'good' 'day' 'join' 'great' 'today' 'trading' 'free'\n"," 'top' 'money' 'current' 'high' 'bullish' 'long' 'people' 'future' 'low'\n"," 'going']\n","\n"," Clase  Bear\n","['buy' 'last' 'like' 'good' 'day' 'trading' 'great' 'today' 'free' 'join'\n"," 'top' 'current' 'money' 'long' 'high' 'bullish' 'people' 'future' 'next'\n"," 'low']\n"]}],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","from nltk.corpus import stopwords\n","import numpy as np\n","stopwords_en=stopwords.words('english');\n","palabras_a_sacar = ['btc', 'bitcoin', 'crypto', 'price', 'amp', 'get', 'market', 'time', 'one', 'see', 'us', 'eth', 'project', 'new', 'usd']\n","stopwords_en.extend(palabras_a_sacar)\n","\n","vectorizer=CountVectorizer(stop_words=stopwords_en);\n","\n","clases=['Bear', 'Bull'];\n","\n","for clase in range(0,2):\n","    X=vectorizer.fit_transform(data_12[data_12['target']==clase]['text']);\n","    counts=X.sum(axis=0);\n","    counts=np.array(counts);\n","    \n","    indices=np.argsort(counts);\n","    valores=np.sort(counts);\n","    indices=indices[0][::-1];\n","    valores=valores[0][::-1];\n","    terms=np.array(vectorizer.get_feature_names());\n","\n","    print('\\n Clase ',clases[clase-1])\n","    print(terms[indices[:20]])"]},{"cell_type":"code","execution_count":106,"id":"03d2db59","metadata":{"executionInfo":{"elapsed":24242,"status":"ok","timestamp":1649993825743,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"03d2db59"},"outputs":[],"source":["# Train Test Split\n","train,test=train_test_split(data_12,stratify=data_12['target'],random_state=3);\n","\n","vectorizer=TfidfVectorizer();\n","X_train=vectorizer.fit_transform(train['text']);\n","y_train=train['target'];\n","\n","X_test=vectorizer.transform(test['text']);\n","y_test=test['target'];"]},{"cell_type":"code","execution_count":107,"id":"d8_YwuUZ-F0A","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1649993825744,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"d8_YwuUZ-F0A","outputId":"9f282fa9-6365-4102-82d1-dda70d48549f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.5356939130434782\n"]}],"source":["# Naive Bayes Multinomial\n","nbc=MultinomialNB();\n","\n","nbc.fit(X_train,y_train);\n","y_pred=nbc.predict(X_test);\n","\n","print('Accuracy:',accuracy_score(y_test,y_pred))"]},{"cell_type":"code","execution_count":108,"id":"7c2da30c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":62963,"status":"ok","timestamp":1649983943082,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"7c2da30c","outputId":"da581c9f-0b07-4664-94b3-ac4e2cb202b1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n","[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:   25.3s\n","[Parallel(n_jobs=3)]: Done  60 out of  60 | elapsed:   31.5s finished\n"]},{"name":"stdout","output_type":"stream","text":["best score: 0.5354478262805827\n","best params: {'alpha': 0.91}\n"]}],"source":["vectorizer=TfidfVectorizer();\n","\n","X=vectorizer.fit_transform(data_12['text']);\n","y=data_12['target'];\n","\n","skf=StratifiedKFold(n_splits=3,random_state=3,shuffle=True);\n","\n","params={'alpha':np.arange(0.01,1,0.05)};\n","GS_CV=GridSearchCV(MultinomialNB(),params,cv=skf,verbose=1,n_jobs=3);\n","GS_CV.fit(X,y);\n","print('best score:',GS_CV.best_score_)\n","print('best params:',GS_CV.best_params_)"]},{"cell_type":"code","execution_count":1,"id":"rOpc-VWFtlBD","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1649984047569,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"rOpc-VWFtlBD"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix, recall_score, precision_score, precision_recall_curve,auc,mean_squared_error\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.model_selection import KFold\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","\n","from sklearn import tree\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.pipeline import Pipeline\n","import xgboost as xgb\n","\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import GridSearchCV"]},{"cell_type":"code","execution_count":112,"id":"f731cdcb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3573962,"status":"ok","timestamp":1649987622082,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"f731cdcb","outputId":"ea3d2a49-3cf4-4abf-db86-9244e4096b76"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 13 candidates, totalling 65 fits\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"]},{"name":"stdout","output_type":"stream","text":["[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.521, total= 1.6min\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.6min remaining:    0.0s\n"]},{"name":"stdout","output_type":"stream","text":["[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.522, total= 1.4min\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.0min remaining:    0.0s\n"]},{"name":"stdout","output_type":"stream","text":["[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.522, total= 1.3min\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  4.2min remaining:    0.0s\n"]},{"name":"stdout","output_type":"stream","text":["[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.524, total= 1.2min\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.523, total= 1.3min\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.521, total= 1.4min\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.522, total= 1.4min\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.523, total= 1.4min\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.524, total= 1.4min\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.523, total= 1.4min\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=6 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=6, score=0.521, total= 1.5min\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=6 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=6, score=0.523, total= 1.4min\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=6 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=6, score=0.523, total= 1.5min\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=6 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=6, score=0.524, total= 1.5min\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=6 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=6, score=0.524, total= 1.5min\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1, score=0.532, total=  15.4s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1, score=0.532, total=  24.4s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1, score=0.531, total=  38.5s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1, score=0.533, total=  16.8s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1, score=0.532, total=  17.2s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2, score=0.534, total=  20.2s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2, score=0.534, total=  19.4s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2, score=0.532, total=  19.7s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2, score=0.533, total=  17.5s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2, score=0.532, total=  21.0s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50, score=0.521, total=  10.5s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50, score=0.522, total=   8.0s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50, score=0.522, total=   9.2s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50, score=0.524, total=   9.8s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50, score=0.523, total=   9.2s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100, score=0.521, total=  17.8s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100, score=0.522, total=  18.2s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100, score=0.522, total=  17.8s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100, score=0.523, total=  18.9s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100, score=0.523, total=  19.0s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50, score=0.522, total=  17.6s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50, score=0.522, total=  17.3s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50, score=0.523, total=  17.4s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50, score=0.524, total=  16.3s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50, score=0.524, total=  16.5s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100, score=0.522, total=  32.2s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100, score=0.523, total=  24.7s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100, score=0.523, total=  29.0s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100, score=0.524, total=  26.9s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100, score=0.523, total=  27.6s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50 \n"]},{"name":"stderr","output_type":"stream","text":["C:\\ProgramData\\Anaconda3\\envs\\dhdsblend2021\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"name":"stdout","output_type":"stream","text":["[03:36:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50, score=0.525, total=  14.3s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50 \n","[03:36:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50, score=0.526, total=  13.3s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50 \n","[03:36:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50, score=0.526, total=  13.4s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50 \n","[03:36:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50, score=0.527, total=  13.6s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50 \n","[03:37:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50, score=0.526, total=  13.4s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100 \n","[03:37:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100, score=0.526, total=  26.9s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100 \n","[03:37:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100, score=0.527, total=  27.4s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100 \n","[03:38:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100, score=0.527, total=  26.6s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100 \n","[03:38:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100, score=0.528, total=  26.1s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100 \n","[03:39:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100, score=0.528, total=  25.0s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50 \n","[03:39:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50, score=0.527, total=  22.8s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50 \n","[03:39:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50, score=0.528, total=  23.0s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50 \n","[03:40:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50, score=0.528, total=  19.9s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50 \n","[03:40:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50, score=0.528, total=  24.3s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50 \n","[03:40:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50, score=0.528, total=  24.7s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100 \n","[03:41:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100, score=0.529, total=  48.4s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100 \n","[03:42:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100, score=0.530, total=  48.0s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100 \n","[03:42:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100, score=0.530, total=  51.2s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100 \n","[03:43:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100, score=0.531, total=  50.2s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100 \n","[03:44:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100, score=0.530, total=  47.9s\n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Done  65 out of  65 | elapsed: 40.0min finished\n"]},{"data":{"text/plain":["GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n","             estimator=Pipeline(steps=[('scaler', None),\n","                                       ('model',\n","                                        LogisticRegression(random_state=127,\n","                                                           solver='liblinear'))]),\n","             param_grid=[{'model': [DecisionTreeClassifier(random_state=40)],\n","                          'model__max_depth': [2, 4, 6]},\n","                         {'model': [LogisticRegression(random_state=127,\n","                                                       solver='liblinear')],\n","                          'model__penalty'...\n","                                                  max_depth=None,\n","                                                  min_child_weight=None,\n","                                                  missing=nan,\n","                                                  monotone_constraints=None,\n","                                                  n_estimators=100, n_jobs=-1,\n","                                                  num_parallel_tree=None,\n","                                                  predictor=None,\n","                                                  random_state=None,\n","                                                  reg_alpha=None,\n","                                                  reg_lambda=None,\n","                                                  scale_pos_weight=None,\n","                                                  subsample=None,\n","                                                  tree_method=None,\n","                                                  validate_parameters=None,\n","                                                  verbosity=None)],\n","                          'model__max_depth': [1, 2],\n","                          'model__n_estimators': [50, 100]}],\n","             verbose=4)"]},"execution_count":112,"metadata":{},"output_type":"execute_result"}],"source":["# Pipeline + Grid Search\n","pasos = [('scaler', None), ('model', LogisticRegression(random_state = 127,solver='liblinear'))]\n","pipe_grid = Pipeline(pasos)\n","param_grid = [{'model' : [tree.DecisionTreeClassifier(random_state=40)], 'model__max_depth':[2,4,6]},\n","              {'model' : [LogisticRegression(random_state = 127,solver='liblinear')], 'model__penalty':['l1','l2']},\n","              {'model' : [RandomForestClassifier(n_jobs=-1,bootstrap=True,random_state = 127)], 'model__n_estimators':[50,100], 'model__max_depth':[2,4]},\n","              {'model' : [xgb.XGBClassifier(n_jobs=-1)], 'model__n_estimators':[50,100], 'model__max_depth':[1,2]}]\n","cv = KFold(n_splits=5) #random_state=123)\n","gsearch = GridSearchCV(estimator=pipe_grid, cv=cv,\n","                        param_grid=param_grid, verbose=4)\n","gsearch.fit(X_train, y_train)\n"]},{"cell_type":"markdown","id":"vE45VSRePdpl","metadata":{"id":"vE45VSRePdpl"},"source":["### Vader Sentiment Analysis"]},{"cell_type":"code","execution_count":2,"id":"Fd4R2G3CPylm","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6551,"status":"ok","timestamp":1649993613851,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"Fd4R2G3CPylm","outputId":"c7d60e82-a828-4c34-84bf-6b4cf3fbd068"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: vaderSentiment in c:\\programdata\\anaconda3\\envs\\dhdsblend2021\\lib\\site-packages (3.3.2)\n","Requirement already satisfied: requests in c:\\programdata\\anaconda3\\envs\\dhdsblend2021\\lib\\site-packages (from vaderSentiment) (2.27.1)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\envs\\dhdsblend2021\\lib\\site-packages (from requests->vaderSentiment) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\dhdsblend2021\\lib\\site-packages (from requests->vaderSentiment) (3.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\dhdsblend2021\\lib\\site-packages (from requests->vaderSentiment) (1.26.6)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\dhdsblend2021\\lib\\site-packages (from requests->vaderSentiment) (2021.10.8)\n"]}],"source":["!pip install vaderSentiment"]},{"cell_type":"code","execution_count":3,"id":"uFsdzKEcPa8j","metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1650000215733,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"uFsdzKEcPa8j"},"outputs":[],"source":["from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n","analyser = SentimentIntensityAnalyzer()\n","def senti_score_udf(sentence):\n","    snt = analyser.polarity_scores(sentence)\n","    return ([snt['neg'], snt['neu'], snt['pos'], snt['compound']])"]},{"cell_type":"code","execution_count":4,"id":"KUs1O5swcLYD","metadata":{"executionInfo":{"elapsed":2038,"status":"ok","timestamp":1650000218605,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"KUs1O5swcLYD"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix, recall_score, precision_score, precision_recall_curve,auc,mean_squared_error\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.model_selection import KFold\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","\n","from sklearn import tree\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.pipeline import Pipeline\n","import xgboost as xgb\n","\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import GridSearchCV"]},{"cell_type":"markdown","id":"bqTTovbGhalT","metadata":{"id":"bqTTovbGhalT"},"source":["#### Ventana de 2 horas"]},{"cell_type":"code","execution_count":9,"id":"v7qP5ug6cLYA","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":3217,"status":"ok","timestamp":1650000236689,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"v7qP5ug6cLYA","outputId":"0b3539cb-114d-4d31-a492-b357a8f1bbe3"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Fecha_hora</th>\n","      <th>user_followers</th>\n","      <th>text</th>\n","      <th>volume</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>301.0</td>\n","      <td>debunking myths by</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>301.0</td>\n","      <td>weekend read keen to learn about assets check...</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>301.0</td>\n","      <td>bloomberg lp with</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>301.0</td>\n","      <td>by</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>163.0</td>\n","      <td></td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            Fecha_hora  user_followers  \\\n","0  2021-02-05 10:00:00           301.0   \n","1  2021-02-05 10:00:00           301.0   \n","2  2021-02-05 10:00:00           301.0   \n","3  2021-02-05 10:00:00           301.0   \n","4  2021-02-05 10:00:00           163.0   \n","\n","                                                text    volume  target  \n","0                                debunking myths by   4.846474     0.0  \n","1   weekend read keen to learn about assets check...  4.846474     0.0  \n","2                                 bloomberg lp with   4.846474     0.0  \n","3                                                by   4.846474     0.0  \n","4                                                     4.846474     0.0  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["data_2 = pd.read_csv(root_path+'Data/data_2h_prep.csv')\n","columnas = ['Fecha_hora', 'user_followers', 'text', 'volume', 'target']\n","data_2.columns = columnas\n","data_2.head()"]},{"cell_type":"code","execution_count":10,"id":"0UPjJMlkcLYA","metadata":{"id":"0UPjJMlkcLYA"},"outputs":[{"data":{"text/plain":["[[0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.741, 0.259, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.323, 0.677, 0.6369],\n"," [0.0, 0.803, 0.197, 0.4019],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.756, 0.244, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.168, 0.16, 0.672, 0.743],\n"," [0.0, 0.615, 0.385, 0.3612],\n"," [0.0, 0.843, 0.157, 0.4215],\n"," [0.0, 0.82, 0.18, 0.0258],\n"," [0.0, 0.784, 0.216, 0.0258],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.859, 0.141, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.466, 0.534, 0.0, -0.7269],\n"," [0.0, 0.759, 0.241, 0.6597],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.0, 0.844, 0.156, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.091, 0.753, 0.156, 0.2196],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.286, 0.714, 0.0, -0.5574],\n"," [0.0, 0.683, 0.317, 0.6249],\n"," [0.0, 0.791, 0.209, 0.4404],\n"," [0.0, 0.504, 0.496, 0.7096],\n"," [0.0, 0.656, 0.344, 0.2732],\n"," [0.0, 0.876, 0.124, 0.34],\n"," [0.087, 0.913, 0.0, -0.2023],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.887, 0.113, 0.3182],\n"," [0.0, 0.843, 0.157, 0.3818],\n"," [0.0, 0.73, 0.27, 0.5719],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.203, 0.58, 0.217, 0.0258],\n"," [0.11, 0.756, 0.134, 0.1027],\n"," [0.0, 0.683, 0.317, 0.6249],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.749, 0.251, 0.5719],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.783, 0.217, 0.3818],\n"," [0.0, 0.8, 0.2, 0.3612],\n"," [0.107, 0.773, 0.12, 0.0772],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.203, 0.797, 0.0, -0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.809, 0.191, 0.5106],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.079, 0.785, 0.136, 0.2196],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.756, 0.244, 0.6697],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.815, 0.185, 0.5106],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.855, 0.145, 0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.855, 0.145, 0.296],\n"," [0.0, 0.769, 0.231, 0.5994],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.753, 0.247, 0.3818],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.824, 0.176, 0.296],\n"," [0.0, 0.792, 0.208, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.826, 0.174, 0.2263],\n"," [0.0, 0.529, 0.471, 0.7906],\n"," [0.0, 0.664, 0.336, 0.8225],\n"," [0.0, 0.78, 0.22, 0.4767],\n"," [0.0, 0.769, 0.231, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.866, 0.134, 0.1779],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.111, 0.758, 0.131, 0.1027],\n"," [0.0, 0.855, 0.145, 0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.852, 0.148, 0.3818],\n"," [0.0, 0.732, 0.268, 0.5106],\n"," [0.423, 0.577, 0.0, -0.6597],\n"," [0.0, 0.786, 0.214, 0.5994],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.425, 0.575, 0.0, -0.5719],\n"," [0.213, 0.787, 0.0, -0.2263],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.277, 0.723, 0.0, -0.5583],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.694, 0.306, 0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.662, 0.338, 0.5542],\n"," [0.0, 0.575, 0.425, 0.5719],\n"," [0.0, 0.345, 0.655, 0.2263],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.818, 0.182, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.123, 0.877, 0.0, -0.1027],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.577, 0.423, 0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.114, 0.702, 0.184, 0.3818],\n"," [0.0, 0.508, 0.492, 0.7003],\n"," [0.0, 0.508, 0.492, 0.7003],\n"," [0.0, 0.508, 0.492, 0.7003],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.273, 0.727, 0.0, -0.4588],\n"," [0.0, 0.806, 0.194, 0.34],\n"," [0.091, 0.579, 0.331, 0.7003],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.517, 0.483, 0.4215],\n"," [0.106, 0.894, 0.0, -0.2263],\n"," [0.0, 0.738, 0.262, 0.5994],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.84, 0.16, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.17, 0.721, 0.109, -0.2344],\n"," [0.0, 0.792, 0.208, 0.4939],\n"," [0.0, 0.75, 0.25, 0.7184],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.863, 0.137, 0.4019],\n"," [0.0, 0.813, 0.187, 0.3182],\n"," [0.079, 0.826, 0.095, 0.1027],\n"," [0.0, 0.435, 0.565, 0.5994],\n"," [0.0, 0.886, 0.114, 0.2648],\n"," [0.237, 0.763, 0.0, -0.4215],\n"," [0.0, 0.838, 0.162, 0.4404],\n"," [0.0, 0.791, 0.209, 0.4404],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.145, 0.855, 0.0, -0.296],\n"," [0.0, 0.508, 0.492, 0.7003],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.412, 0.588, 0.6908],\n"," [0.0, 0.508, 0.492, 0.7003],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.814, 0.186, 0.6249],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.585, 0.415, 0.7964],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.069, 0.931, 0.0, -0.1027],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.905, 0.095, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.769, 0.231, 0.4588],\n"," [0.0, 0.9, 0.1, 0.25],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.813, 0.187, 0.3182],\n"," [0.0, 0.884, 0.116, 0.3612],\n"," [0.0, 0.833, 0.167, 0.5574],\n"," [0.0, 0.274, 0.726, 0.6486],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.856, 0.144, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.821, 0.179, 0.34],\n"," [0.2, 0.8, 0.0, -0.4588],\n"," [0.0, 0.802, 0.198, 0.4939],\n"," [0.231, 0.769, 0.0, -0.5574],\n"," [0.0, 0.778, 0.222, 0.25],\n"," [0.0, 0.82, 0.18, 0.0258],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.119, 0.811, 0.07, -0.2263],\n"," [0.0, 0.66, 0.34, 0.5574],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.776, 0.224, 0.3818],\n"," [0.138, 0.566, 0.296, 0.3612],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.905, 0.095, 0.3182],\n"," [0.0, 0.822, 0.178, 0.3818],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.328, 0.672, 0.0, -0.5994],\n"," [0.0, 0.8, 0.2, 0.3612],\n"," [0.0, 0.795, 0.205, 0.2023],\n"," [0.0, 0.787, 0.213, 0.4019],\n"," [0.0, 0.746, 0.254, 0.7003],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.316, 0.684, 0.0, -0.5719],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.219, 0.781, 0.0, -0.2023],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.8, 0.2, 0.3612],\n"," [0.0, 0.588, 0.412, 0.8126],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.204, 0.796, 0.0, -0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.221, 0.779, 0.0, -0.6597],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.755, 0.245, 0.5994],\n"," [0.0, 0.769, 0.231, 0.2023],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.784, 0.216, 0.5106],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.604, 0.396, 0.7351],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.097, 0.903, 0.0, -0.128],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.09, 0.802, 0.108, 0.1027],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.341, 0.659, 0.0, -0.4767],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.408, 0.592, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.897, 0.103, 0.128],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.793, 0.207, 0.5267],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.82, 0.18, 0.0258],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.736, 0.264, 0.7269],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.909, 0.091, 0.1027],\n"," [0.314, 0.686, 0.0, -0.6705],\n"," [0.0, 0.508, 0.492, 0.5859],\n"," [0.0, 0.843, 0.157, 0.0772],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.821, 0.179, 0.34],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.882, 0.118, 0.34],\n"," [0.0, 0.787, 0.213, 0.5859],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.769, 0.231, 0.2023],\n"," [0.0, 0.802, 0.198, 0.6369],\n"," [0.0, 0.599, 0.401, 0.7717],\n"," [0.0, 0.773, 0.227, 0.6124],\n"," [0.268, 0.732, 0.0, -0.296],\n"," [0.0, 0.674, 0.326, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.882, 0.118, 0.2846],\n"," [0.0, 0.748, 0.252, 0.4019],\n"," [0.0, 0.8, 0.2, 0.4588],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.348, 0.652, 0.0, -0.1531],\n"," [0.0, 0.887, 0.113, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.8, 0.2, 0.4588],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.756, 0.244, 0.6369],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.694, 0.306, 0.296],\n"," [0.0, 0.694, 0.306, 0.296],\n"," [0.0, 0.884, 0.116, 0.3612],\n"," [0.0, 0.778, 0.222, 0.25],\n"," [0.0, 0.86, 0.14, 0.0772],\n"," [0.185, 0.815, 0.0, -0.3612],\n"," [0.0, 0.82, 0.18, 0.5106],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.204, 0.796, 0.0, -0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.694, 0.306, 0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.089, 0.691, 0.22, 0.4939],\n"," [0.0, 0.86, 0.14, 0.3818],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.734, 0.266, 0.4404],\n"," [0.286, 0.714, 0.0, -0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.849, 0.151, 0.4939],\n"," [0.133, 0.867, 0.0, -0.3818],\n"," [0.231, 0.769, 0.0, -0.34],\n"," [0.0, 0.64, 0.36, 0.5434],\n"," [0.075, 0.75, 0.175, 0.3818],\n"," [0.0, 0.827, 0.173, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.131, 0.763, 0.106, -0.1531],\n"," [0.0, 0.664, 0.336, 0.7248],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.776, 0.224, 0.6696],\n"," [0.0, 0.488, 0.512, 0.6369],\n"," [0.0, 0.911, 0.089, 0.1901],\n"," [0.0, 0.69, 0.31, 0.743],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.778, 0.222, 0.25],\n"," [0.0, 0.83, 0.17, 0.6249],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.816, 0.184, 0.4019],\n"," [0.316, 0.684, 0.0, -0.5719],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.588, 0.412, 0.5423],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.859, 0.141, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.341, 0.659, 0.0, -0.6367],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.765, 0.235, 0.4588],\n"," [0.167, 0.833, 0.0, -0.296],\n"," [0.0, 0.847, 0.153, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.728, 0.272, 0.6395],\n"," [0.0, 0.861, 0.139, 0.3089],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.3, 0.7, 0.0, -0.5945],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.821, 0.179, 0.34],\n"," [0.0, 0.673, 0.327, 0.743],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.398, 0.602, 0.0, -0.6486],\n"," [0.215, 0.785, 0.0, -0.6249],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.131, 0.765, 0.104, -0.1901],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.678, 0.322, 0.6908],\n"," [0.05, 0.561, 0.389, 0.8979],\n"," [0.0, 0.682, 0.318, 0.6369],\n"," [0.198, 0.802, 0.0, -0.5719],\n"," [0.0, 0.847, 0.153, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.535, 0.465, 0.7264],\n"," [0.0, 0.921, 0.079, 0.2263],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.751, 0.249, 0.5106],\n"," [0.0, 0.909, 0.091, 0.0258],\n"," [0.444, 0.556, 0.0, -0.9153],\n"," [0.0, 0.899, 0.101, 0.2023],\n"," [0.083, 0.632, 0.285, 0.7269],\n"," [0.109, 0.746, 0.144, 0.1779],\n"," [0.159, 0.841, 0.0, -0.5574],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.07, 0.873, 0.057, -0.0772],\n"," [0.112, 0.888, 0.0, -0.2263],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.115, 0.885, 0.0, -0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.809, 0.191, 0.3818],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.341, 0.659, 0.0, -0.4767],\n"," [0.0, 0.8, 0.2, 0.3612],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.739, 0.261, 0.6488],\n"," [0.225, 0.775, 0.0, -0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.702, 0.298, 0.6249],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.663, 0.337, 0.765],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.87, 0.13, 0.2023],\n"," [0.295, 0.705, 0.0, -0.7883],\n"," [0.1, 0.9, 0.0, -0.2732],\n"," [0.0, 0.698, 0.302, 0.4404],\n"," [0.202, 0.798, 0.0, -0.6486],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.8, 0.2, 0.4588],\n"," [0.057, 0.67, 0.273, 0.6705],\n"," [0.109, 0.891, 0.0, -0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.896, 0.104, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.904, 0.096, 0.177],\n"," [0.076, 0.811, 0.114, 0.1779],\n"," [0.0, 0.698, 0.302, 0.6369],\n"," [0.0, 0.802, 0.198, 0.6369],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.169, 0.756, 0.076, -0.3818],\n"," [0.405, 0.595, 0.0, -0.9225],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.371, 0.584, 0.045, -0.8885],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.864, 0.136, 0.296],\n"," [0.0, 0.769, 0.231, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.252, 0.748, 0.0, -0.5719],\n"," [0.323, 0.677, 0.0, -0.6486],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.161, 0.674, 0.166, 0.0258],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.899, 0.101, 0.2263],\n"," [0.0, 0.787, 0.213, 0.5574],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.714, 0.286, 0.6808],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.227, 0.773, 0.5267],\n"," [0.0, 0.588, 0.412, 0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.774, 0.226, 0.4215],\n"," [0.265, 0.735, 0.0, -0.6597],\n"," [0.121, 0.794, 0.084, -0.2023],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.504, 0.496, 0.7096],\n"," [0.0, 0.775, 0.225, 0.5859],\n"," [0.114, 0.761, 0.125, 0.0516],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.098, 0.813, 0.089, -0.0258],\n"," [0.0, 0.698, 0.302, 0.6369],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.72, 0.28, 0.5423],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.609, 0.391, 0.8828],\n"," [0.0, 0.544, 0.456, 0.7717],\n"," [0.0, 0.737, 0.263, 0.6908],\n"," [0.0, 0.852, 0.148, 0.3818],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.828, 0.172, 0.3612],\n"," [0.093, 0.814, 0.093, -0.0018],\n"," [0.11, 0.65, 0.24, 0.3818],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.316, 0.684, 0.0, -0.5588],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.72, 0.28, 0.765],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.753, 0.247, 0.3818],\n"," [0.0, 0.794, 0.206, 0.5994],\n"," [0.0, 0.865, 0.135, 0.3612],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.336, 0.49, 0.175, -0.3182],\n"," [0.73, 0.27, 0.0, -0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.133, 0.665, 0.202, 0.2228],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.498, 0.502, 0.9202],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.823, 0.177, 0.6249],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.266, 0.546, 0.188, -0.5106],\n"," [0.0, 0.69, 0.31, 0.6705],\n"," [0.22, 0.78, 0.0, -0.4767],\n"," [0.0, 0.713, 0.287, 0.7537],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.69, 0.31, 0.4019],\n"," [0.0, 0.637, 0.363, 0.6908],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.815, 0.185, 0.3612],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.605, 0.395, 0.5542],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.691, 0.309, 0.6682],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.596, 0.404, 0.8316],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.232, 0.768, 0.0, -0.6177],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.683, 0.317, 0.6705],\n"," [0.135, 0.71, 0.155, 0.0772],\n"," [0.0, 0.738, 0.262, 0.4927],\n"," [0.0, 0.758, 0.242, 0.3724],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.735, 0.265, 0.2023],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.818, 0.182, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.783, 0.217, 0.3612],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.418, 0.582, 0.0, -0.3804],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.821, 0.179, 0.34],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.8, 0.2, 0.3612],\n"," [0.076, 0.707, 0.217, 0.4215],\n"," [0.0, 0.682, 0.318, 0.6369],\n"," [0.072, 0.821, 0.108, 0.1779],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.072, 0.821, 0.108, 0.1779],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.0, 0.875, 0.125, 0.4588],\n"," [0.083, 0.784, 0.132, 0.25],\n"," [0.0, 0.508, 0.492, 0.7003],\n"," [0.132, 0.789, 0.079, -0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.305, 0.695, 0.8442],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.246, 0.629, 0.126, -0.4767],\n"," [0.0, 0.714, 0.286, 0.7003],\n"," [0.273, 0.727, 0.0, -0.4588],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.122, 0.612, 0.266, 0.4667],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.811, 0.189, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.797, 0.203, 0.552],\n"," [0.403, 0.597, 0.0, -0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.818, 0.182, 0.4404],\n"," [0.31, 0.69, 0.0, -0.5574],\n"," [0.0, 0.779, 0.221, 0.1779],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.833, 0.167, 0.2023],\n"," [0.0, 0.588, 0.412, 0.6369],\n"," [0.0, 0.213, 0.787, 0.5719],\n"," [0.126, 0.686, 0.189, 0.2732],\n"," [0.0, 0.633, 0.367, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.4, 0.6, 0.0, -0.25],\n"," [0.164, 0.672, 0.164, 0.0],\n"," [0.164, 0.672, 0.164, 0.0],\n"," [0.0, 0.522, 0.478, 0.6705],\n"," [0.0, 0.549, 0.451, 0.7506],\n"," [0.0, 0.659, 0.341, 0.7351],\n"," [0.0, 0.784, 0.216, 0.5106],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.56, 0.44, 0.6705],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.333, 0.667, 0.4588],\n"," [0.0, 0.863, 0.137, 0.2263],\n"," [0.097, 0.903, 0.0, -0.0191],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.672, 0.328, 0.4404],\n"," [0.167, 0.833, 0.0, -0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.741, 0.259, 0.4215],\n"," [0.0, 0.822, 0.178, 0.0772],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.787, 0.213, 0.4019],\n"," [0.132, 0.868, 0.0, -0.4404],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.128, 0.642, 0.229, 0.296],\n"," [0.172, 0.698, 0.13, 0.0258],\n"," [0.299, 0.597, 0.104, -0.4939],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.0, 0.823, 0.177, 0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.122, 0.732, 0.146, 0.0935],\n"," [0.0, 0.828, 0.172, 0.4404],\n"," [0.0, 0.844, 0.156, 0.5719],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.0, 0.842, 0.158, 0.128],\n"," [0.092, 0.908, 0.0, -0.2584],\n"," [0.0, 0.404, 0.596, 0.7096],\n"," [0.0, 0.469, 0.531, 0.5267],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.13, 0.87, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.694, 0.306, 0.296],\n"," [0.0, 0.829, 0.171, 0.4391],\n"," [0.18, 0.667, 0.153, -0.1027],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.147, 0.67, 0.184, -0.4299],\n"," [0.127, 0.597, 0.276, 0.4588],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.837, 0.163, 0.5994],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.553, 0.447, 0.836],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.872, 0.128, 0.3612],\n"," [0.0, 0.816, 0.184, 0.4019],\n"," [0.353, 0.321, 0.326, -0.0423],\n"," [0.0, 0.568, 0.432, 0.8225],\n"," [0.286, 0.714, 0.0, -0.3412],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.719, 0.281, 0.8316],\n"," [0.127, 0.769, 0.104, -0.1531],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.142, 0.645, 0.213, 0.2732],\n"," [0.0, 0.718, 0.282, 0.6705],\n"," [0.158, 0.842, 0.0, -0.4588],\n"," [0.0, 0.61, 0.39, 0.4939],\n"," [0.0, 0.691, 0.309, 0.7717],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.602, 0.398, 0.765],\n"," [0.417, 0.583, 0.0, -0.5106],\n"," [0.0, 0.427, 0.573, 0.9022],\n"," [0.0, 0.721, 0.279, 0.7351],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.115, 0.885, 0.0, -0.0772],\n"," [0.0, 0.714, 0.286, 0.5859],\n"," [0.0, 0.764, 0.236, 0.5719],\n"," [0.0, 0.796, 0.204, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.856, 0.144, 0.4019],\n"," [0.0, 0.742, 0.258, 0.7096],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.772, 0.228, 0.5477],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.258, 0.656, 0.086, -0.608],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.734, 0.266, 0.5719],\n"," [0.174, 0.826, 0.0, -0.2732],\n"," [0.187, 0.719, 0.094, -0.3182],\n"," [0.0, 0.815, 0.185, 0.3612],\n"," [0.643, 0.357, 0.0, -0.5574],\n"," [0.341, 0.659, 0.0, -0.4767],\n"," [0.0, 0.699, 0.301, 0.7096],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.106, 0.894, 0.0, -0.0772],\n"," [0.109, 0.891, 0.0, -0.296],\n"," [0.0, 0.68, 0.32, 0.5106],\n"," [0.0, 0.76, 0.24, 0.6249],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.86, 0.14, 0.5023],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.775, 0.225, 0.4404],\n"," [0.0, 0.414, 0.586, 0.795],\n"," [0.0, 0.708, 0.292, 0.4391],\n"," [0.0, 0.699, 0.301, 0.6808],\n"," [0.0, 0.714, 0.286, 0.6808],\n"," [0.0, 0.829, 0.171, 0.5106],\n"," [0.216, 0.784, 0.0, -0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.2, 0.8, 0.0, -0.5423],\n"," [0.0, 0.549, 0.451, 0.6249],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.732, 0.268, 0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.763, 0.237, 0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.823, 0.177, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.662, 0.338, 0.7321],\n"," [0.0, 0.8, 0.2, 0.3612],\n"," [0.245, 0.598, 0.158, -0.1531],\n"," [0.237, 0.763, 0.0, -0.4767],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.854, 0.146, 0.34],\n"," [0.145, 0.751, 0.104, -0.1779],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.199, 0.801, 0.0, -0.4973],\n"," [0.0, 0.763, 0.237, 0.6808],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.756, 0.244, 0.7003],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.256, 0.625, 0.119, -0.296],\n"," [0.0, 0.884, 0.116, 0.3612],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.783, 0.217, 0.3612],\n"," [0.0, 0.73, 0.27, 0.743],\n"," [0.0, 0.833, 0.167, 0.2023],\n"," [0.263, 0.737, 0.0, -0.5719],\n"," [0.0, 0.874, 0.126, 0.0772],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.727, 0.273, 0.7184],\n"," [0.0, 0.895, 0.105, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.551, 0.449, 0.6908],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.109, 0.891, 0.0, -0.296],\n"," [0.0, 0.328, 0.672, 0.6249],\n"," [0.193, 0.459, 0.349, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.858, 0.142, 0.5106],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.654, 0.346, 0.5719],\n"," [0.0, 0.828, 0.172, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.882, 0.118, 0.34],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.237, 0.678, 0.085, -0.6705],\n"," [0.062, 0.752, 0.186, 0.5859],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.178, 0.822, 0.0, -0.5709],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.145, 0.855, 0.0, -0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.429, 0.571, 0.0, -0.9001],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.098, 0.667, 0.235, 0.3612],\n"," [0.0, 0.741, 0.259, 0.4215],\n"," [0.161, 0.737, 0.101, -0.3182],\n"," [0.09, 0.66, 0.25, 0.5267],\n"," [0.196, 0.506, 0.297, 0.1531],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.541, 0.459, 0.8176],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.722, 0.278, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.784, 0.216, 0.5106],\n"," [0.101, 0.78, 0.119, 0.1027],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 1.0, 0.5994],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.078, 0.782, 0.14, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.756, 0.244, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.465, 0.535, 0.5574],\n"," [0.0, 0.741, 0.259, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.881, 0.119, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.792, 0.208, 0.2732],\n"," [0.191, 0.619, 0.191, 0.0],\n"," [0.0, 0.805, 0.195, 0.4404],\n"," [0.109, 0.891, 0.0, -0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.566, 0.434, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.847, 0.153, 0.4019],\n"," [0.0, 0.764, 0.236, 0.5719],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.157, 0.843, 0.0, -0.3818],\n"," [0.152, 0.848, 0.0, -0.5267],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.834, 0.166, 0.5849],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.773, 0.227, 0.6249],\n"," [0.188, 0.676, 0.136, -0.1744],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.513, 0.487, 0.6908],\n"," [0.0, 0.513, 0.487, 0.6908],\n"," [0.0, 0.513, 0.487, 0.6908],\n"," [0.0, 0.513, 0.487, 0.6908],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.597, 0.403, 0.0, -0.8126],\n"," [0.162, 0.838, 0.0, -0.4404],\n"," [0.0, 0.916, 0.084, 0.0258],\n"," [0.0, 0.828, 0.172, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.495, 0.434, 0.071, -0.868],\n"," [0.0, 1.0, 0.0, 0.0],\n"," ...]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["sentiment=[senti_score_udf(x) for x in data_2['text']]\n","sentiment"]},{"cell_type":"code","execution_count":11,"id":"AzbW0bUDcLYB","metadata":{"id":"AzbW0bUDcLYB"},"outputs":[],"source":["df_sentimiento = pd.DataFrame(sentiment)\n","df_sentimiento.columns=['Negativo','Neutro','Positivo','Compound']\n","df_sentimiento.index=data_2.Fecha_hora"]},{"cell_type":"code","execution_count":12,"id":"BMObvYLHcLYB","metadata":{"id":"BMObvYLHcLYB"},"outputs":[],"source":["data_2.set_index('Fecha_hora',drop=True,inplace=True)"]},{"cell_type":"code","execution_count":13,"id":"oOLumJJbcLYB","metadata":{"id":"oOLumJJbcLYB"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_followers</th>\n","      <th>text</th>\n","      <th>volume</th>\n","      <th>target</th>\n","    </tr>\n","    <tr>\n","      <th>Fecha_hora</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>debunking myths by</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>weekend read keen to learn about assets check...</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>bloomberg lp with</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>by</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>163.0</td>\n","      <td></td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     user_followers  \\\n","Fecha_hora                            \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           163.0   \n","\n","                                                                  text  \\\n","Fecha_hora                                                               \n","2021-02-05 10:00:00                                debunking myths by    \n","2021-02-05 10:00:00   weekend read keen to learn about assets check...   \n","2021-02-05 10:00:00                                 bloomberg lp with    \n","2021-02-05 10:00:00                                                by    \n","2021-02-05 10:00:00                                                      \n","\n","                       volume  target  \n","Fecha_hora                             \n","2021-02-05 10:00:00  4.846474     0.0  \n","2021-02-05 10:00:00  4.846474     0.0  \n","2021-02-05 10:00:00  4.846474     0.0  \n","2021-02-05 10:00:00  4.846474     0.0  \n","2021-02-05 10:00:00  4.846474     0.0  "]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["data_2.head()"]},{"cell_type":"code","execution_count":14,"id":"5LSR2ZDKcLYB","metadata":{"id":"5LSR2ZDKcLYB"},"outputs":[],"source":["data_final_2= pd.concat([data_2,df_sentimiento],axis=1)\n","data_final_2.drop(['text','user_followers','volume'],inplace=True,axis=1)"]},{"cell_type":"code","execution_count":15,"id":"5WFJYbiHcLYB","metadata":{"id":"5WFJYbiHcLYB"},"outputs":[{"data":{"text/plain":["0.0    661425\n","1.0    629020\n","Name: target, dtype: int64"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["data_final_2.target.value_counts()"]},{"cell_type":"code","execution_count":16,"id":"pUTd_MKwcLYB","metadata":{"id":"pUTd_MKwcLYB"},"outputs":[{"data":{"text/plain":["target      0\n","Negativo    0\n","Neutro      0\n","Positivo    0\n","Compound    0\n","dtype: int64"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["data_final_2.isna().sum()"]},{"cell_type":"code","execution_count":17,"id":"s4_usGmDcLYB","metadata":{"id":"s4_usGmDcLYB"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>target</th>\n","      <th>Negativo</th>\n","      <th>Neutro</th>\n","      <th>Positivo</th>\n","      <th>Compound</th>\n","    </tr>\n","    <tr>\n","      <th>Fecha_hora</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.733375</td>\n","      <td>0.141625</td>\n","      <td>0.191587</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 11:00:00</th>\n","      <td>1.0</td>\n","      <td>0.036789</td>\n","      <td>0.858634</td>\n","      <td>0.104577</td>\n","      <td>0.136373</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 12:00:00</th>\n","      <td>1.0</td>\n","      <td>0.034255</td>\n","      <td>0.843436</td>\n","      <td>0.122319</td>\n","      <td>0.154889</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 13:00:00</th>\n","      <td>1.0</td>\n","      <td>0.029848</td>\n","      <td>0.847051</td>\n","      <td>0.092798</td>\n","      <td>0.116370</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 14:00:00</th>\n","      <td>0.0</td>\n","      <td>0.027440</td>\n","      <td>0.878612</td>\n","      <td>0.093948</td>\n","      <td>0.135504</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2022-02-18 14:00:00</th>\n","      <td>0.0</td>\n","      <td>0.043031</td>\n","      <td>0.840680</td>\n","      <td>0.116299</td>\n","      <td>0.162116</td>\n","    </tr>\n","    <tr>\n","      <th>2022-02-18 20:00:00</th>\n","      <td>0.0</td>\n","      <td>0.047657</td>\n","      <td>0.797960</td>\n","      <td>0.154389</td>\n","      <td>0.204873</td>\n","    </tr>\n","    <tr>\n","      <th>2022-02-18 21:00:00</th>\n","      <td>0.0</td>\n","      <td>0.047296</td>\n","      <td>0.836479</td>\n","      <td>0.116251</td>\n","      <td>0.163007</td>\n","    </tr>\n","    <tr>\n","      <th>2022-02-18 22:00:00</th>\n","      <td>1.0</td>\n","      <td>0.049515</td>\n","      <td>0.830021</td>\n","      <td>0.120461</td>\n","      <td>0.160952</td>\n","    </tr>\n","    <tr>\n","      <th>2022-02-18 23:00:00</th>\n","      <td>0.0</td>\n","      <td>0.072190</td>\n","      <td>0.820000</td>\n","      <td>0.107809</td>\n","      <td>0.085002</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2280 rows × 5 columns</p>\n","</div>"],"text/plain":["                     target  Negativo    Neutro  Positivo  Compound\n","Fecha_hora                                                         \n","2021-02-05 10:00:00     0.0  0.000000  0.733375  0.141625  0.191587\n","2021-02-05 11:00:00     1.0  0.036789  0.858634  0.104577  0.136373\n","2021-02-05 12:00:00     1.0  0.034255  0.843436  0.122319  0.154889\n","2021-02-05 13:00:00     1.0  0.029848  0.847051  0.092798  0.116370\n","2021-02-05 14:00:00     0.0  0.027440  0.878612  0.093948  0.135504\n","...                     ...       ...       ...       ...       ...\n","2022-02-18 14:00:00     0.0  0.043031  0.840680  0.116299  0.162116\n","2022-02-18 20:00:00     0.0  0.047657  0.797960  0.154389  0.204873\n","2022-02-18 21:00:00     0.0  0.047296  0.836479  0.116251  0.163007\n","2022-02-18 22:00:00     1.0  0.049515  0.830021  0.120461  0.160952\n","2022-02-18 23:00:00     0.0  0.072190  0.820000  0.107809  0.085002\n","\n","[2280 rows x 5 columns]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["data_final_2.groupby(by=data_final_2.index,axis=0).mean()"]},{"cell_type":"code","execution_count":18,"id":"vn1onNsmcLYB","metadata":{"id":"vn1onNsmcLYB"},"outputs":[],"source":["date=[dt.datetime.strptime(x,'%Y-%m-%d %H:%M:%S') for x in data_final_2.index]"]},{"cell_type":"code","execution_count":19,"id":"WePuH4pMcLYB","metadata":{"id":"WePuH4pMcLYB"},"outputs":[],"source":["data_final_2.index=date"]},{"cell_type":"code","execution_count":20,"id":"MXo-Rq4ncLYC","metadata":{"id":"MXo-Rq4ncLYC"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>target</th>\n","      <th>Negativo</th>\n","      <th>Neutro</th>\n","      <th>Positivo</th>\n","      <th>Compound</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.000</td>\n","      <td>0.000</td>\n","      <td>0.0000</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.741</td>\n","      <td>0.259</td>\n","      <td>0.4939</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.000</td>\n","      <td>0.000</td>\n","      <td>0.0000</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.000</td>\n","      <td>0.000</td>\n","      <td>0.0000</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     target  Negativo  Neutro  Positivo  Compound\n","2021-02-05 10:00:00     0.0       0.0   1.000     0.000    0.0000\n","2021-02-05 10:00:00     0.0       0.0   0.741     0.259    0.4939\n","2021-02-05 10:00:00     0.0       0.0   1.000     0.000    0.0000\n","2021-02-05 10:00:00     0.0       0.0   1.000     0.000    0.0000\n","2021-02-05 10:00:00     0.0       0.0   0.000     0.000    0.0000"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["data_final_2.head()"]},{"cell_type":"code","execution_count":21,"id":"gXv5fCk-cLYC","metadata":{"id":"gXv5fCk-cLYC"},"outputs":[{"data":{"text/plain":["target      0.0000\n","Negativo    0.0000\n","Neutro      0.0000\n","Positivo    0.0000\n","Compound   -0.9918\n","dtype: float64"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["data_final_2.min()"]},{"cell_type":"code","execution_count":25,"id":"KFz37AehcLYC","metadata":{"id":"KFz37AehcLYC"},"outputs":[],"source":["# Train Test Split\n","train,test=train_test_split(data_final_2,stratify=data_final_2['target'],random_state=3);\n","\n","#vectorizer=TfidfVectorizer();\n","X_train_2=train.drop(['target', 'Compound'], axis=1)\n","y_train_2=train['target'];\n","\n","X_test_2=test.drop(['target', 'Compound'], axis=1);\n","y_test_2=test['target'];"]},{"cell_type":"code","execution_count":27,"id":"oHeXRadLcLYC","metadata":{"id":"oHeXRadLcLYC"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.5125568794713153\n"]}],"source":["# Naive Bayes Multinomial\n","nbc=MultinomialNB();\n","\n","nbc.fit(X_train_2,y_train_2);\n","y_pred=nbc.predict(X_test_2);\n","\n","print('Accuracy:',accuracy_score(y_test_2,y_pred))"]},{"cell_type":"code","execution_count":29,"id":"ac_RHPXHcLYC","metadata":{"id":"ac_RHPXHcLYC"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n","[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:   10.9s\n","[Parallel(n_jobs=3)]: Done  60 out of  60 | elapsed:   13.6s finished\n"]},{"name":"stdout","output_type":"stream","text":["best score: 0.512555746274188\n","best params: {'alpha': 1e-05}\n"]}],"source":["X_2=data_final_2.drop(['target', 'Compound'], axis=1);\n","y_2=data_final_2['target'];\n","\n","skf=StratifiedKFold(n_splits=3,random_state=3,shuffle=True);\n","\n","params={'alpha':np.arange(0.00001,1,0.05)};\n","GS_CV=GridSearchCV(MultinomialNB(),params,cv=skf,verbose=1,n_jobs=3);\n","GS_CV.fit(X_2,y_2);\n","print('best score:',GS_CV.best_score_)\n","print('best params:',GS_CV.best_params_)"]},{"cell_type":"code","execution_count":31,"id":"G5OIl3BgcLYE","metadata":{"id":"G5OIl3BgcLYE"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 13 candidates, totalling 65 fits\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"]},{"name":"stdout","output_type":"stream","text":["[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.512, total=   0.5s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"]},{"name":"stdout","output_type":"stream","text":["[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.513, total=   0.4s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.8s remaining:    0.0s\n"]},{"name":"stdout","output_type":"stream","text":["[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.511, total=   0.5s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.4s remaining:    0.0s\n"]},{"name":"stdout","output_type":"stream","text":["[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.515, total=   0.5s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.512, total=   0.4s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.513, total=   0.5s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.513, total=   0.8s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.511, total=   0.6s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.516, total=   0.6s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.513, total=   0.5s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=6 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=6, score=0.513, total=   0.7s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=6 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=6, score=0.514, total=   0.8s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=6 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=6, score=0.512, total=   0.8s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=6 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=6, score=0.516, total=   0.8s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=6 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=6, score=0.513, total=   0.9s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1, score=0.512, total=   5.7s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1, score=0.512, total=  40.1s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1, score=0.511, total=  14.4s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1, score=0.515, total=  19.6s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1, score=0.512, total=  28.3s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2, score=0.512, total=   0.7s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2, score=0.512, total=   0.9s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2, score=0.511, total=   1.0s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2, score=0.515, total=   1.3s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2, score=0.512, total=   1.2s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50, score=0.512, total=   7.7s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50, score=0.512, total=   4.7s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50, score=0.511, total=   4.7s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50, score=0.515, total=   5.0s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50, score=0.512, total=   5.1s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100, score=0.512, total=   9.4s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100, score=0.512, total=   8.7s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100, score=0.511, total=   8.1s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100, score=0.515, total=   9.1s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100, score=0.512, total=   9.0s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50, score=0.513, total=   9.1s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50, score=0.513, total=  10.9s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50, score=0.512, total=   7.9s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50, score=0.516, total=   7.7s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50, score=0.513, total=  11.3s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100, score=0.513, total=  20.4s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100, score=0.513, total=  18.5s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100, score=0.512, total=  18.6s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100, score=0.516, total=  31.7s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100, score=0.513, total=  18.2s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50 \n"]},{"name":"stderr","output_type":"stream","text":["C:\\ProgramData\\Anaconda3\\envs\\dhdsblend2021\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"name":"stdout","output_type":"stream","text":["[12:10:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50, score=0.512, total=   2.8s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50 \n","[12:10:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50, score=0.512, total=   2.2s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50 \n","[12:10:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50, score=0.512, total=   2.5s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50 \n","[12:10:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50, score=0.515, total=   2.6s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50 \n","[12:10:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50, score=0.512, total=   2.3s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100 \n","[12:10:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100, score=0.513, total=   5.1s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100 \n","[12:10:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100, score=0.513, total=   3.8s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100 \n","[12:10:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100, score=0.512, total=   3.6s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100 \n","[12:10:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100, score=0.515, total=   4.4s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100 \n","[12:10:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100, score=0.513, total=   4.9s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50 \n","[12:11:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50, score=0.514, total=   4.5s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50 \n","[12:11:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50, score=0.514, total=   3.5s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50 \n","[12:11:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50, score=0.513, total=  25.7s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50 \n","[12:11:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50, score=0.516, total=   4.6s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50 \n","[12:11:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50, score=0.514, total=   8.9s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100 \n","[12:11:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100, score=0.514, total=   7.6s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100 \n","[12:11:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100, score=0.513, total=   7.5s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100 \n","[12:12:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100, score=0.514, total=   6.7s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100 \n","[12:12:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100, score=0.517, total=  10.0s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100 \n","[12:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100, score=0.514, total=   7.3s\n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Done  65 out of  65 | elapsed:  7.8min finished\n"]},{"name":"stdout","output_type":"stream","text":["[12:12:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","-----------------------------------\n","Mejores hiperparámetros encontrados\n","-----------------------------------\n","{'model': XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=2,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), 'model__max_depth': 2, 'model__n_estimators': 100} : 0.5144451597891087 None\n"]}],"source":["# Pipeline + Grid Search\n","pasos = [('scaler', None), ('model', LogisticRegression(random_state = 127,solver='liblinear'))]\n","pipe_grid = Pipeline(pasos)\n","param_grid = [{'model' : [tree.DecisionTreeClassifier(random_state=40)], 'model__max_depth':[2,4,6]},\n","              {'model' : [LogisticRegression(random_state = 127,solver='liblinear')], 'model__penalty':['l1','l2']},\n","              {'model' : [RandomForestClassifier(n_jobs=-1,bootstrap=True,random_state = 127)], 'model__n_estimators':[50,100], 'model__max_depth':[2,4]},\n","              {'model' : [xgb.XGBClassifier(n_jobs=-1)], 'model__n_estimators':[50,100], 'model__max_depth':[1,2]}]\n","cv = KFold(n_splits=5) #random_state=123)\n","gsearch = GridSearchCV(estimator=pipe_grid, cv=cv,\n","                        param_grid=param_grid, verbose=4)\n","gsearch.fit(X_train_2, y_train_2)\n","\n","print(\"-----------------------------------\")\n","print(\"Mejores hiperparámetros encontrados\")\n","print(\"-----------------------------------\")\n","print(gsearch.best_params_, \":\", gsearch.best_score_, gsearch.scoring)\n"]},{"cell_type":"markdown","id":"sn_BkFAchoS2","metadata":{"id":"sn_BkFAchoS2"},"source":["#### Ventana de 6 horas"]},{"cell_type":"code","execution_count":32,"id":"edG_8Un9eRQf","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":3011,"status":"ok","timestamp":1649998868136,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"edG_8Un9eRQf","outputId":"b5235290-5dcf-48e0-872c-6f36d18e6a21"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Fecha_hora</th>\n","      <th>user_followers</th>\n","      <th>text</th>\n","      <th>volume</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>301.0</td>\n","      <td>debunking myths by</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>301.0</td>\n","      <td>weekend read keen to learn about assets check...</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>301.0</td>\n","      <td>bloomberg lp with</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>301.0</td>\n","      <td>by</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>163.0</td>\n","      <td></td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            Fecha_hora  user_followers  \\\n","0  2021-02-05 10:00:00           301.0   \n","1  2021-02-05 10:00:00           301.0   \n","2  2021-02-05 10:00:00           301.0   \n","3  2021-02-05 10:00:00           301.0   \n","4  2021-02-05 10:00:00           163.0   \n","\n","                                                text    volume  target  \n","0                                debunking myths by   4.846474     0.0  \n","1   weekend read keen to learn about assets check...  4.846474     0.0  \n","2                                 bloomberg lp with   4.846474     0.0  \n","3                                                by   4.846474     0.0  \n","4                                                     4.846474     0.0  "]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["data_6 = pd.read_csv(root_path+'Data/data_6h_prep.csv')\n","columnas = ['Fecha_hora', 'user_followers', 'text', 'volume', 'target']\n","data_6.columns = columnas\n","data_6.head()"]},{"cell_type":"code","execution_count":33,"id":"En37y_WYeRQf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":162945,"status":"ok","timestamp":1649999031078,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"En37y_WYeRQf","outputId":"953274d4-a1ae-4622-ef04-a463a2d97ef4"},"outputs":[{"data":{"text/plain":["[[0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.741, 0.259, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.323, 0.677, 0.6369],\n"," [0.0, 0.803, 0.197, 0.4019],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.756, 0.244, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.168, 0.16, 0.672, 0.743],\n"," [0.0, 0.615, 0.385, 0.3612],\n"," [0.0, 0.843, 0.157, 0.4215],\n"," [0.0, 0.82, 0.18, 0.0258],\n"," [0.0, 0.784, 0.216, 0.0258],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.859, 0.141, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.466, 0.534, 0.0, -0.7269],\n"," [0.0, 0.759, 0.241, 0.6597],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.0, 0.844, 0.156, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.091, 0.753, 0.156, 0.2196],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.286, 0.714, 0.0, -0.5574],\n"," [0.0, 0.683, 0.317, 0.6249],\n"," [0.0, 0.791, 0.209, 0.4404],\n"," [0.0, 0.504, 0.496, 0.7096],\n"," [0.0, 0.656, 0.344, 0.2732],\n"," [0.0, 0.876, 0.124, 0.34],\n"," [0.087, 0.913, 0.0, -0.2023],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.887, 0.113, 0.3182],\n"," [0.0, 0.843, 0.157, 0.3818],\n"," [0.0, 0.73, 0.27, 0.5719],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.203, 0.58, 0.217, 0.0258],\n"," [0.11, 0.756, 0.134, 0.1027],\n"," [0.0, 0.683, 0.317, 0.6249],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.749, 0.251, 0.5719],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.783, 0.217, 0.3818],\n"," [0.0, 0.8, 0.2, 0.3612],\n"," [0.107, 0.773, 0.12, 0.0772],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.203, 0.797, 0.0, -0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.809, 0.191, 0.5106],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.079, 0.785, 0.136, 0.2196],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.756, 0.244, 0.6697],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.815, 0.185, 0.5106],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.855, 0.145, 0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.855, 0.145, 0.296],\n"," [0.0, 0.769, 0.231, 0.5994],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.753, 0.247, 0.3818],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.824, 0.176, 0.296],\n"," [0.0, 0.792, 0.208, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.826, 0.174, 0.2263],\n"," [0.0, 0.529, 0.471, 0.7906],\n"," [0.0, 0.664, 0.336, 0.8225],\n"," [0.0, 0.78, 0.22, 0.4767],\n"," [0.0, 0.769, 0.231, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.866, 0.134, 0.1779],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.111, 0.758, 0.131, 0.1027],\n"," [0.0, 0.855, 0.145, 0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.852, 0.148, 0.3818],\n"," [0.0, 0.732, 0.268, 0.5106],\n"," [0.423, 0.577, 0.0, -0.6597],\n"," [0.0, 0.786, 0.214, 0.5994],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.425, 0.575, 0.0, -0.5719],\n"," [0.213, 0.787, 0.0, -0.2263],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.277, 0.723, 0.0, -0.5583],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.694, 0.306, 0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.662, 0.338, 0.5542],\n"," [0.0, 0.575, 0.425, 0.5719],\n"," [0.0, 0.345, 0.655, 0.2263],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.818, 0.182, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.123, 0.877, 0.0, -0.1027],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.577, 0.423, 0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.114, 0.702, 0.184, 0.3818],\n"," [0.0, 0.508, 0.492, 0.7003],\n"," [0.0, 0.508, 0.492, 0.7003],\n"," [0.0, 0.508, 0.492, 0.7003],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.273, 0.727, 0.0, -0.4588],\n"," [0.0, 0.806, 0.194, 0.34],\n"," [0.091, 0.579, 0.331, 0.7003],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.517, 0.483, 0.4215],\n"," [0.106, 0.894, 0.0, -0.2263],\n"," [0.0, 0.738, 0.262, 0.5994],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.84, 0.16, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.17, 0.721, 0.109, -0.2344],\n"," [0.0, 0.792, 0.208, 0.4939],\n"," [0.0, 0.75, 0.25, 0.7184],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.863, 0.137, 0.4019],\n"," [0.0, 0.813, 0.187, 0.3182],\n"," [0.079, 0.826, 0.095, 0.1027],\n"," [0.0, 0.435, 0.565, 0.5994],\n"," [0.0, 0.886, 0.114, 0.2648],\n"," [0.237, 0.763, 0.0, -0.4215],\n"," [0.0, 0.838, 0.162, 0.4404],\n"," [0.0, 0.791, 0.209, 0.4404],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.145, 0.855, 0.0, -0.296],\n"," [0.0, 0.508, 0.492, 0.7003],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.412, 0.588, 0.6908],\n"," [0.0, 0.508, 0.492, 0.7003],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.814, 0.186, 0.6249],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.585, 0.415, 0.7964],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.069, 0.931, 0.0, -0.1027],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.905, 0.095, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.769, 0.231, 0.4588],\n"," [0.0, 0.9, 0.1, 0.25],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.813, 0.187, 0.3182],\n"," [0.0, 0.884, 0.116, 0.3612],\n"," [0.0, 0.833, 0.167, 0.5574],\n"," [0.0, 0.274, 0.726, 0.6486],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.856, 0.144, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.821, 0.179, 0.34],\n"," [0.2, 0.8, 0.0, -0.4588],\n"," [0.0, 0.802, 0.198, 0.4939],\n"," [0.231, 0.769, 0.0, -0.5574],\n"," [0.0, 0.778, 0.222, 0.25],\n"," [0.0, 0.82, 0.18, 0.0258],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.119, 0.811, 0.07, -0.2263],\n"," [0.0, 0.66, 0.34, 0.5574],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.776, 0.224, 0.3818],\n"," [0.138, 0.566, 0.296, 0.3612],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.905, 0.095, 0.3182],\n"," [0.0, 0.822, 0.178, 0.3818],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.328, 0.672, 0.0, -0.5994],\n"," [0.0, 0.8, 0.2, 0.3612],\n"," [0.0, 0.795, 0.205, 0.2023],\n"," [0.0, 0.787, 0.213, 0.4019],\n"," [0.0, 0.746, 0.254, 0.7003],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.316, 0.684, 0.0, -0.5719],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.219, 0.781, 0.0, -0.2023],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.8, 0.2, 0.3612],\n"," [0.0, 0.588, 0.412, 0.8126],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.204, 0.796, 0.0, -0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.221, 0.779, 0.0, -0.6597],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.755, 0.245, 0.5994],\n"," [0.0, 0.769, 0.231, 0.2023],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.784, 0.216, 0.5106],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.604, 0.396, 0.7351],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.097, 0.903, 0.0, -0.128],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.09, 0.802, 0.108, 0.1027],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.341, 0.659, 0.0, -0.4767],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.408, 0.592, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.897, 0.103, 0.128],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.793, 0.207, 0.5267],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.82, 0.18, 0.0258],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.736, 0.264, 0.7269],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.909, 0.091, 0.1027],\n"," [0.314, 0.686, 0.0, -0.6705],\n"," [0.0, 0.508, 0.492, 0.5859],\n"," [0.0, 0.843, 0.157, 0.0772],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.821, 0.179, 0.34],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.882, 0.118, 0.34],\n"," [0.0, 0.787, 0.213, 0.5859],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.769, 0.231, 0.2023],\n"," [0.0, 0.802, 0.198, 0.6369],\n"," [0.0, 0.599, 0.401, 0.7717],\n"," [0.0, 0.773, 0.227, 0.6124],\n"," [0.268, 0.732, 0.0, -0.296],\n"," [0.0, 0.674, 0.326, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.882, 0.118, 0.2846],\n"," [0.0, 0.748, 0.252, 0.4019],\n"," [0.0, 0.8, 0.2, 0.4588],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.348, 0.652, 0.0, -0.1531],\n"," [0.0, 0.887, 0.113, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.8, 0.2, 0.4588],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.756, 0.244, 0.6369],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.694, 0.306, 0.296],\n"," [0.0, 0.694, 0.306, 0.296],\n"," [0.0, 0.884, 0.116, 0.3612],\n"," [0.0, 0.778, 0.222, 0.25],\n"," [0.0, 0.86, 0.14, 0.0772],\n"," [0.185, 0.815, 0.0, -0.3612],\n"," [0.0, 0.82, 0.18, 0.5106],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.204, 0.796, 0.0, -0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.694, 0.306, 0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.089, 0.691, 0.22, 0.4939],\n"," [0.0, 0.86, 0.14, 0.3818],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.734, 0.266, 0.4404],\n"," [0.286, 0.714, 0.0, -0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.849, 0.151, 0.4939],\n"," [0.133, 0.867, 0.0, -0.3818],\n"," [0.231, 0.769, 0.0, -0.34],\n"," [0.0, 0.64, 0.36, 0.5434],\n"," [0.075, 0.75, 0.175, 0.3818],\n"," [0.0, 0.827, 0.173, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.131, 0.763, 0.106, -0.1531],\n"," [0.0, 0.664, 0.336, 0.7248],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.776, 0.224, 0.6696],\n"," [0.0, 0.488, 0.512, 0.6369],\n"," [0.0, 0.911, 0.089, 0.1901],\n"," [0.0, 0.69, 0.31, 0.743],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.778, 0.222, 0.25],\n"," [0.0, 0.83, 0.17, 0.6249],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.816, 0.184, 0.4019],\n"," [0.316, 0.684, 0.0, -0.5719],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.588, 0.412, 0.5423],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.859, 0.141, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.341, 0.659, 0.0, -0.6367],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.765, 0.235, 0.4588],\n"," [0.167, 0.833, 0.0, -0.296],\n"," [0.0, 0.847, 0.153, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.728, 0.272, 0.6395],\n"," [0.0, 0.861, 0.139, 0.3089],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.3, 0.7, 0.0, -0.5945],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.821, 0.179, 0.34],\n"," [0.0, 0.673, 0.327, 0.743],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.398, 0.602, 0.0, -0.6486],\n"," [0.215, 0.785, 0.0, -0.6249],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.131, 0.765, 0.104, -0.1901],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.678, 0.322, 0.6908],\n"," [0.05, 0.561, 0.389, 0.8979],\n"," [0.0, 0.682, 0.318, 0.6369],\n"," [0.198, 0.802, 0.0, -0.5719],\n"," [0.0, 0.847, 0.153, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.535, 0.465, 0.7264],\n"," [0.0, 0.921, 0.079, 0.2263],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.751, 0.249, 0.5106],\n"," [0.0, 0.909, 0.091, 0.0258],\n"," [0.444, 0.556, 0.0, -0.9153],\n"," [0.0, 0.899, 0.101, 0.2023],\n"," [0.083, 0.632, 0.285, 0.7269],\n"," [0.109, 0.746, 0.144, 0.1779],\n"," [0.159, 0.841, 0.0, -0.5574],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.07, 0.873, 0.057, -0.0772],\n"," [0.112, 0.888, 0.0, -0.2263],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.115, 0.885, 0.0, -0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.809, 0.191, 0.3818],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.341, 0.659, 0.0, -0.4767],\n"," [0.0, 0.8, 0.2, 0.3612],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.739, 0.261, 0.6488],\n"," [0.225, 0.775, 0.0, -0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.702, 0.298, 0.6249],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.663, 0.337, 0.765],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.87, 0.13, 0.2023],\n"," [0.295, 0.705, 0.0, -0.7883],\n"," [0.1, 0.9, 0.0, -0.2732],\n"," [0.0, 0.698, 0.302, 0.4404],\n"," [0.202, 0.798, 0.0, -0.6486],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.8, 0.2, 0.4588],\n"," [0.057, 0.67, 0.273, 0.6705],\n"," [0.109, 0.891, 0.0, -0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.896, 0.104, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.904, 0.096, 0.177],\n"," [0.076, 0.811, 0.114, 0.1779],\n"," [0.0, 0.698, 0.302, 0.6369],\n"," [0.0, 0.802, 0.198, 0.6369],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.169, 0.756, 0.076, -0.3818],\n"," [0.405, 0.595, 0.0, -0.9225],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.371, 0.584, 0.045, -0.8885],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.864, 0.136, 0.296],\n"," [0.0, 0.769, 0.231, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.252, 0.748, 0.0, -0.5719],\n"," [0.323, 0.677, 0.0, -0.6486],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.161, 0.674, 0.166, 0.0258],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.899, 0.101, 0.2263],\n"," [0.0, 0.787, 0.213, 0.5574],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.714, 0.286, 0.6808],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.227, 0.773, 0.5267],\n"," [0.0, 0.588, 0.412, 0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.774, 0.226, 0.4215],\n"," [0.265, 0.735, 0.0, -0.6597],\n"," [0.121, 0.794, 0.084, -0.2023],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.504, 0.496, 0.7096],\n"," [0.0, 0.775, 0.225, 0.5859],\n"," [0.114, 0.761, 0.125, 0.0516],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.098, 0.813, 0.089, -0.0258],\n"," [0.0, 0.698, 0.302, 0.6369],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.72, 0.28, 0.5423],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.609, 0.391, 0.8828],\n"," [0.0, 0.544, 0.456, 0.7717],\n"," [0.0, 0.737, 0.263, 0.6908],\n"," [0.0, 0.852, 0.148, 0.3818],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.828, 0.172, 0.3612],\n"," [0.093, 0.814, 0.093, -0.0018],\n"," [0.11, 0.65, 0.24, 0.3818],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.316, 0.684, 0.0, -0.5588],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.72, 0.28, 0.765],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.753, 0.247, 0.3818],\n"," [0.0, 0.794, 0.206, 0.5994],\n"," [0.0, 0.865, 0.135, 0.3612],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.336, 0.49, 0.175, -0.3182],\n"," [0.73, 0.27, 0.0, -0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.133, 0.665, 0.202, 0.2228],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.498, 0.502, 0.9202],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.823, 0.177, 0.6249],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.266, 0.546, 0.188, -0.5106],\n"," [0.0, 0.69, 0.31, 0.6705],\n"," [0.22, 0.78, 0.0, -0.4767],\n"," [0.0, 0.713, 0.287, 0.7537],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.69, 0.31, 0.4019],\n"," [0.0, 0.637, 0.363, 0.6908],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.815, 0.185, 0.3612],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.605, 0.395, 0.5542],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.691, 0.309, 0.6682],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.596, 0.404, 0.8316],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.232, 0.768, 0.0, -0.6177],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.683, 0.317, 0.6705],\n"," [0.135, 0.71, 0.155, 0.0772],\n"," [0.0, 0.738, 0.262, 0.4927],\n"," [0.0, 0.758, 0.242, 0.3724],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.735, 0.265, 0.2023],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.818, 0.182, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.783, 0.217, 0.3612],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.418, 0.582, 0.0, -0.3804],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.821, 0.179, 0.34],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.8, 0.2, 0.3612],\n"," [0.076, 0.707, 0.217, 0.4215],\n"," [0.0, 0.682, 0.318, 0.6369],\n"," [0.072, 0.821, 0.108, 0.1779],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.072, 0.821, 0.108, 0.1779],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.0, 0.875, 0.125, 0.4588],\n"," [0.083, 0.784, 0.132, 0.25],\n"," [0.0, 0.508, 0.492, 0.7003],\n"," [0.132, 0.789, 0.079, -0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.305, 0.695, 0.8442],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.246, 0.629, 0.126, -0.4767],\n"," [0.0, 0.714, 0.286, 0.7003],\n"," [0.273, 0.727, 0.0, -0.4588],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.122, 0.612, 0.266, 0.4667],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.811, 0.189, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.797, 0.203, 0.552],\n"," [0.403, 0.597, 0.0, -0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.818, 0.182, 0.4404],\n"," [0.31, 0.69, 0.0, -0.5574],\n"," [0.0, 0.779, 0.221, 0.1779],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.833, 0.167, 0.2023],\n"," [0.0, 0.588, 0.412, 0.6369],\n"," [0.0, 0.213, 0.787, 0.5719],\n"," [0.126, 0.686, 0.189, 0.2732],\n"," [0.0, 0.633, 0.367, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.4, 0.6, 0.0, -0.25],\n"," [0.164, 0.672, 0.164, 0.0],\n"," [0.164, 0.672, 0.164, 0.0],\n"," [0.0, 0.522, 0.478, 0.6705],\n"," [0.0, 0.549, 0.451, 0.7506],\n"," [0.0, 0.659, 0.341, 0.7351],\n"," [0.0, 0.784, 0.216, 0.5106],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.56, 0.44, 0.6705],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.333, 0.667, 0.4588],\n"," [0.0, 0.863, 0.137, 0.2263],\n"," [0.097, 0.903, 0.0, -0.0191],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.672, 0.328, 0.4404],\n"," [0.167, 0.833, 0.0, -0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.741, 0.259, 0.4215],\n"," [0.0, 0.822, 0.178, 0.0772],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.787, 0.213, 0.4019],\n"," [0.132, 0.868, 0.0, -0.4404],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.128, 0.642, 0.229, 0.296],\n"," [0.172, 0.698, 0.13, 0.0258],\n"," [0.299, 0.597, 0.104, -0.4939],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.0, 0.823, 0.177, 0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.122, 0.732, 0.146, 0.0935],\n"," [0.0, 0.828, 0.172, 0.4404],\n"," [0.0, 0.844, 0.156, 0.5719],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.0, 0.842, 0.158, 0.128],\n"," [0.092, 0.908, 0.0, -0.2584],\n"," [0.0, 0.404, 0.596, 0.7096],\n"," [0.0, 0.469, 0.531, 0.5267],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.13, 0.87, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.694, 0.306, 0.296],\n"," [0.0, 0.829, 0.171, 0.4391],\n"," [0.18, 0.667, 0.153, -0.1027],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.147, 0.67, 0.184, -0.4299],\n"," [0.127, 0.597, 0.276, 0.4588],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.837, 0.163, 0.5994],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.553, 0.447, 0.836],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.872, 0.128, 0.3612],\n"," [0.0, 0.816, 0.184, 0.4019],\n"," [0.353, 0.321, 0.326, -0.0423],\n"," [0.0, 0.568, 0.432, 0.8225],\n"," [0.286, 0.714, 0.0, -0.3412],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.719, 0.281, 0.8316],\n"," [0.127, 0.769, 0.104, -0.1531],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.142, 0.645, 0.213, 0.2732],\n"," [0.0, 0.718, 0.282, 0.6705],\n"," [0.158, 0.842, 0.0, -0.4588],\n"," [0.0, 0.61, 0.39, 0.4939],\n"," [0.0, 0.691, 0.309, 0.7717],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.602, 0.398, 0.765],\n"," [0.417, 0.583, 0.0, -0.5106],\n"," [0.0, 0.427, 0.573, 0.9022],\n"," [0.0, 0.721, 0.279, 0.7351],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.115, 0.885, 0.0, -0.0772],\n"," [0.0, 0.714, 0.286, 0.5859],\n"," [0.0, 0.764, 0.236, 0.5719],\n"," [0.0, 0.796, 0.204, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.856, 0.144, 0.4019],\n"," [0.0, 0.742, 0.258, 0.7096],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.772, 0.228, 0.5477],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.258, 0.656, 0.086, -0.608],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.734, 0.266, 0.5719],\n"," [0.174, 0.826, 0.0, -0.2732],\n"," [0.187, 0.719, 0.094, -0.3182],\n"," [0.0, 0.815, 0.185, 0.3612],\n"," [0.643, 0.357, 0.0, -0.5574],\n"," [0.341, 0.659, 0.0, -0.4767],\n"," [0.0, 0.699, 0.301, 0.7096],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.106, 0.894, 0.0, -0.0772],\n"," [0.109, 0.891, 0.0, -0.296],\n"," [0.0, 0.68, 0.32, 0.5106],\n"," [0.0, 0.76, 0.24, 0.6249],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.86, 0.14, 0.5023],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.775, 0.225, 0.4404],\n"," [0.0, 0.414, 0.586, 0.795],\n"," [0.0, 0.708, 0.292, 0.4391],\n"," [0.0, 0.699, 0.301, 0.6808],\n"," [0.0, 0.714, 0.286, 0.6808],\n"," [0.0, 0.829, 0.171, 0.5106],\n"," [0.216, 0.784, 0.0, -0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.2, 0.8, 0.0, -0.5423],\n"," [0.0, 0.549, 0.451, 0.6249],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.732, 0.268, 0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.763, 0.237, 0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.823, 0.177, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.662, 0.338, 0.7321],\n"," [0.0, 0.8, 0.2, 0.3612],\n"," [0.245, 0.598, 0.158, -0.1531],\n"," [0.237, 0.763, 0.0, -0.4767],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.854, 0.146, 0.34],\n"," [0.145, 0.751, 0.104, -0.1779],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.199, 0.801, 0.0, -0.4973],\n"," [0.0, 0.763, 0.237, 0.6808],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.756, 0.244, 0.7003],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.256, 0.625, 0.119, -0.296],\n"," [0.0, 0.884, 0.116, 0.3612],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.783, 0.217, 0.3612],\n"," [0.0, 0.73, 0.27, 0.743],\n"," [0.0, 0.833, 0.167, 0.2023],\n"," [0.263, 0.737, 0.0, -0.5719],\n"," [0.0, 0.874, 0.126, 0.0772],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.727, 0.273, 0.7184],\n"," [0.0, 0.895, 0.105, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.551, 0.449, 0.6908],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.109, 0.891, 0.0, -0.296],\n"," [0.0, 0.328, 0.672, 0.6249],\n"," [0.193, 0.459, 0.349, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.858, 0.142, 0.5106],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.654, 0.346, 0.5719],\n"," [0.0, 0.828, 0.172, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.882, 0.118, 0.34],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.237, 0.678, 0.085, -0.6705],\n"," [0.062, 0.752, 0.186, 0.5859],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.178, 0.822, 0.0, -0.5709],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.145, 0.855, 0.0, -0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.429, 0.571, 0.0, -0.9001],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.098, 0.667, 0.235, 0.3612],\n"," [0.0, 0.741, 0.259, 0.4215],\n"," [0.161, 0.737, 0.101, -0.3182],\n"," [0.09, 0.66, 0.25, 0.5267],\n"," [0.196, 0.506, 0.297, 0.1531],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.541, 0.459, 0.8176],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.722, 0.278, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.784, 0.216, 0.5106],\n"," [0.101, 0.78, 0.119, 0.1027],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 1.0, 0.5994],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.078, 0.782, 0.14, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.756, 0.244, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.465, 0.535, 0.5574],\n"," [0.0, 0.741, 0.259, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.881, 0.119, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.792, 0.208, 0.2732],\n"," [0.191, 0.619, 0.191, 0.0],\n"," [0.0, 0.805, 0.195, 0.4404],\n"," [0.109, 0.891, 0.0, -0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.566, 0.434, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.847, 0.153, 0.4019],\n"," [0.0, 0.764, 0.236, 0.5719],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.157, 0.843, 0.0, -0.3818],\n"," [0.152, 0.848, 0.0, -0.5267],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.834, 0.166, 0.5849],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.773, 0.227, 0.6249],\n"," [0.188, 0.676, 0.136, -0.1744],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.513, 0.487, 0.6908],\n"," [0.0, 0.513, 0.487, 0.6908],\n"," [0.0, 0.513, 0.487, 0.6908],\n"," [0.0, 0.513, 0.487, 0.6908],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.597, 0.403, 0.0, -0.8126],\n"," [0.162, 0.838, 0.0, -0.4404],\n"," [0.0, 0.916, 0.084, 0.0258],\n"," [0.0, 0.828, 0.172, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.495, 0.434, 0.071, -0.868],\n"," [0.0, 1.0, 0.0, 0.0],\n"," ...]"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["sentiment=[senti_score_udf(x) for x in data_6['text']]\n","sentiment"]},{"cell_type":"code","execution_count":34,"id":"JW9_-4oieRQg","metadata":{"executionInfo":{"elapsed":602,"status":"ok","timestamp":1649999031675,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"JW9_-4oieRQg"},"outputs":[],"source":["df_sentimiento = pd.DataFrame(sentiment)\n","df_sentimiento.columns=['Negativo','Neutro','Positivo','Compound']\n","df_sentimiento.index=data_6.Fecha_hora"]},{"cell_type":"code","execution_count":35,"id":"s3-08UJueRQg","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1649999031675,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"s3-08UJueRQg"},"outputs":[],"source":["data_6.set_index('Fecha_hora',drop=True,inplace=True)"]},{"cell_type":"code","execution_count":36,"id":"MceT2uFweRQg","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1649999031676,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"MceT2uFweRQg","outputId":"e1faa195-1c60-4a74-ff48-96a3a9e2cc2e"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_followers</th>\n","      <th>text</th>\n","      <th>volume</th>\n","      <th>target</th>\n","    </tr>\n","    <tr>\n","      <th>Fecha_hora</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>debunking myths by</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>weekend read keen to learn about assets check...</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>bloomberg lp with</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>by</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>163.0</td>\n","      <td></td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     user_followers  \\\n","Fecha_hora                            \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           163.0   \n","\n","                                                                  text  \\\n","Fecha_hora                                                               \n","2021-02-05 10:00:00                                debunking myths by    \n","2021-02-05 10:00:00   weekend read keen to learn about assets check...   \n","2021-02-05 10:00:00                                 bloomberg lp with    \n","2021-02-05 10:00:00                                                by    \n","2021-02-05 10:00:00                                                      \n","\n","                       volume  target  \n","Fecha_hora                             \n","2021-02-05 10:00:00  4.846474     0.0  \n","2021-02-05 10:00:00  4.846474     0.0  \n","2021-02-05 10:00:00  4.846474     0.0  \n","2021-02-05 10:00:00  4.846474     0.0  \n","2021-02-05 10:00:00  4.846474     0.0  "]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["data_6.head()"]},{"cell_type":"code","execution_count":37,"id":"wXrnmz-keRQg","metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1649999032142,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"wXrnmz-keRQg"},"outputs":[],"source":["data_final_6= pd.concat([data_6,df_sentimiento],axis=1)\n","data_final_6.drop(['text','user_followers','volume'],inplace=True,axis=1)"]},{"cell_type":"code","execution_count":38,"id":"7w4xYTEeeRQg","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1649999032142,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"7w4xYTEeeRQg","outputId":"4f1c8087-2cd9-46c6-d87a-420fcbe06406"},"outputs":[{"data":{"text/plain":["0.0    650060\n","1.0    640385\n","Name: target, dtype: int64"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["data_final_6.target.value_counts()"]},{"cell_type":"code","execution_count":39,"id":"UnedissReRQg","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1649999032142,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"UnedissReRQg","outputId":"14bcf471-5c07-4c12-b5b9-74f7be16072a"},"outputs":[{"data":{"text/plain":["target      0\n","Negativo    0\n","Neutro      0\n","Positivo    0\n","Compound    0\n","dtype: int64"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["data_final_6.isna().sum()"]},{"cell_type":"code","execution_count":40,"id":"U2bgyfx8eRQg","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":455},"executionInfo":{"elapsed":665,"status":"ok","timestamp":1649999032803,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"U2bgyfx8eRQg","outputId":"ad3eae4e-bee5-4b5d-a632-731670c8e5e7"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>target</th>\n","      <th>Negativo</th>\n","      <th>Neutro</th>\n","      <th>Positivo</th>\n","      <th>Compound</th>\n","    </tr>\n","    <tr>\n","      <th>Fecha_hora</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.733375</td>\n","      <td>0.141625</td>\n","      <td>0.191587</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 11:00:00</th>\n","      <td>1.0</td>\n","      <td>0.036789</td>\n","      <td>0.858634</td>\n","      <td>0.104577</td>\n","      <td>0.136373</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 12:00:00</th>\n","      <td>0.0</td>\n","      <td>0.034255</td>\n","      <td>0.843436</td>\n","      <td>0.122319</td>\n","      <td>0.154889</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 13:00:00</th>\n","      <td>0.0</td>\n","      <td>0.029848</td>\n","      <td>0.847051</td>\n","      <td>0.092798</td>\n","      <td>0.116370</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 14:00:00</th>\n","      <td>0.0</td>\n","      <td>0.027440</td>\n","      <td>0.878612</td>\n","      <td>0.093948</td>\n","      <td>0.135504</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2022-02-18 14:00:00</th>\n","      <td>1.0</td>\n","      <td>0.043031</td>\n","      <td>0.840680</td>\n","      <td>0.116299</td>\n","      <td>0.162116</td>\n","    </tr>\n","    <tr>\n","      <th>2022-02-18 20:00:00</th>\n","      <td>1.0</td>\n","      <td>0.047657</td>\n","      <td>0.797960</td>\n","      <td>0.154389</td>\n","      <td>0.204873</td>\n","    </tr>\n","    <tr>\n","      <th>2022-02-18 21:00:00</th>\n","      <td>0.0</td>\n","      <td>0.047296</td>\n","      <td>0.836479</td>\n","      <td>0.116251</td>\n","      <td>0.163007</td>\n","    </tr>\n","    <tr>\n","      <th>2022-02-18 22:00:00</th>\n","      <td>0.0</td>\n","      <td>0.049515</td>\n","      <td>0.830021</td>\n","      <td>0.120461</td>\n","      <td>0.160952</td>\n","    </tr>\n","    <tr>\n","      <th>2022-02-18 23:00:00</th>\n","      <td>0.0</td>\n","      <td>0.072190</td>\n","      <td>0.820000</td>\n","      <td>0.107809</td>\n","      <td>0.085002</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2280 rows × 5 columns</p>\n","</div>"],"text/plain":["                     target  Negativo    Neutro  Positivo  Compound\n","Fecha_hora                                                         \n","2021-02-05 10:00:00     0.0  0.000000  0.733375  0.141625  0.191587\n","2021-02-05 11:00:00     1.0  0.036789  0.858634  0.104577  0.136373\n","2021-02-05 12:00:00     0.0  0.034255  0.843436  0.122319  0.154889\n","2021-02-05 13:00:00     0.0  0.029848  0.847051  0.092798  0.116370\n","2021-02-05 14:00:00     0.0  0.027440  0.878612  0.093948  0.135504\n","...                     ...       ...       ...       ...       ...\n","2022-02-18 14:00:00     1.0  0.043031  0.840680  0.116299  0.162116\n","2022-02-18 20:00:00     1.0  0.047657  0.797960  0.154389  0.204873\n","2022-02-18 21:00:00     0.0  0.047296  0.836479  0.116251  0.163007\n","2022-02-18 22:00:00     0.0  0.049515  0.830021  0.120461  0.160952\n","2022-02-18 23:00:00     0.0  0.072190  0.820000  0.107809  0.085002\n","\n","[2280 rows x 5 columns]"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["data_final_6.groupby(by=data_final_6.index,axis=0).mean()"]},{"cell_type":"code","execution_count":41,"id":"CWdSrmcPeRQg","metadata":{"executionInfo":{"elapsed":15212,"status":"ok","timestamp":1649999048012,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"CWdSrmcPeRQg"},"outputs":[],"source":["date=[dt.datetime.strptime(x,'%Y-%m-%d %H:%M:%S') for x in data_final_6.index]"]},{"cell_type":"code","execution_count":42,"id":"VDxENT6zeRQg","metadata":{"executionInfo":{"elapsed":1319,"status":"ok","timestamp":1649999050124,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"VDxENT6zeRQg"},"outputs":[],"source":["data_final_6.index=date"]},{"cell_type":"code","execution_count":43,"id":"g3xk5Nl-eRQg","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1649999050125,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"g3xk5Nl-eRQg","outputId":"3640a75a-b70c-491a-9912-d8b00ababee3"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>target</th>\n","      <th>Negativo</th>\n","      <th>Neutro</th>\n","      <th>Positivo</th>\n","      <th>Compound</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.000</td>\n","      <td>0.000</td>\n","      <td>0.0000</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.741</td>\n","      <td>0.259</td>\n","      <td>0.4939</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.000</td>\n","      <td>0.000</td>\n","      <td>0.0000</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.000</td>\n","      <td>0.000</td>\n","      <td>0.0000</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     target  Negativo  Neutro  Positivo  Compound\n","2021-02-05 10:00:00     0.0       0.0   1.000     0.000    0.0000\n","2021-02-05 10:00:00     0.0       0.0   0.741     0.259    0.4939\n","2021-02-05 10:00:00     0.0       0.0   1.000     0.000    0.0000\n","2021-02-05 10:00:00     0.0       0.0   1.000     0.000    0.0000\n","2021-02-05 10:00:00     0.0       0.0   0.000     0.000    0.0000"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["data_final_6.head()"]},{"cell_type":"code","execution_count":44,"id":"mgsfxfx_eRQh","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1649999050125,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"mgsfxfx_eRQh","outputId":"63467d38-53c9-4714-83f9-ba99c8c13180"},"outputs":[{"data":{"text/plain":["target      0.0000\n","Negativo    0.0000\n","Neutro      0.0000\n","Positivo    0.0000\n","Compound   -0.9918\n","dtype: float64"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["data_final_6.min()"]},{"cell_type":"code","execution_count":45,"id":"cSCqsstweRQh","metadata":{"executionInfo":{"elapsed":573,"status":"ok","timestamp":1649999050693,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"cSCqsstweRQh"},"outputs":[],"source":["# Train Test Split\n","train,test=train_test_split(data_final_6,stratify=data_final_6['target'],random_state=3);\n","\n","#vectorizer=TfidfVectorizer();\n","X_train_6=train.drop(['target', 'Compound'], axis=1)\n","y_train_6=train['target'];\n","\n","X_test_6=test.drop(['target', 'Compound'], axis=1);\n","y_test_6=test['target'];"]},{"cell_type":"code","execution_count":48,"id":"r5_JKZeKeRQh","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":601,"status":"ok","timestamp":1649999051292,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"r5_JKZeKeRQh","outputId":"bd8a05bd-4765-4ce6-c4b1-01536a2249fd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.5037475357395261\n"]}],"source":["# Naive Bayes Multinomial\n","nbc=MultinomialNB();\n","\n","nbc.fit(X_train_6,y_train_6);\n","y_pred=nbc.predict(X_test_6);\n","\n","print('Accuracy:',accuracy_score(y_test_6,y_pred))"]},{"cell_type":"code","execution_count":50,"id":"lzJCZjt9eRQh","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21169,"status":"ok","timestamp":1649996121640,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"lzJCZjt9eRQh","outputId":"c9842213-3978-473d-e8ea-5d29850bc607"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n","[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:   19.6s\n","[Parallel(n_jobs=3)]: Done  60 out of  60 | elapsed:   22.9s finished\n"]},{"name":"stdout","output_type":"stream","text":["best score: 0.5037487068414429\n","best params: {'alpha': 1e-05}\n"]}],"source":["X_2=data_final_6.drop(['target', 'Compound'], axis=1);\n","y_2=data_final_6['target'];\n","\n","skf=StratifiedKFold(n_splits=3,random_state=3,shuffle=True);\n","\n","params={'alpha':np.arange(0.00001,1,0.05)};\n","GS_CV=GridSearchCV(MultinomialNB(),params,cv=skf,verbose=1,n_jobs=3);\n","GS_CV.fit(X_2,y_2);\n","print('best score:',GS_CV.best_score_)\n","print('best params:',GS_CV.best_params_)"]},{"cell_type":"code","execution_count":51,"id":"g9pxnxCdeRQh","metadata":{"id":"g9pxnxCdeRQh"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 13 candidates, totalling 65 fits\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"]},{"name":"stdout","output_type":"stream","text":["[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.504, total=   0.8s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n"]},{"name":"stdout","output_type":"stream","text":["[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.502, total=   0.5s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.2s remaining:    0.0s\n"]},{"name":"stdout","output_type":"stream","text":["[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.502, total=   0.5s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.8s remaining:    0.0s\n"]},{"name":"stdout","output_type":"stream","text":["[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.505, total=   0.4s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.503, total=   0.4s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.503, total=   0.6s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.502, total=   0.6s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.503, total=   0.6s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.507, total=   0.6s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.503, total=   0.6s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=6 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=6, score=0.504, total=   0.8s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=6 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=6, score=0.504, total=   0.9s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=6 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=6, score=0.503, total=   0.8s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=6 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=6, score=0.505, total=   0.8s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=6 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=6, score=0.504, total=   0.8s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1, score=0.503, total=  31.1s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1, score=0.503, total=  13.2s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1, score=0.502, total=  36.3s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1, score=0.506, total=  11.9s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1, score=0.503, total=  26.0s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2, score=0.503, total=   0.8s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2, score=0.503, total=   0.9s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2, score=0.502, total=   0.9s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2, score=0.506, total=   1.1s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2, score=0.503, total=   0.8s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50, score=0.504, total=   5.2s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50, score=0.504, total=   4.7s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50, score=0.502, total=   4.5s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50, score=0.507, total=   4.6s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50, score=0.503, total=   4.5s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100, score=0.503, total=   8.6s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100, score=0.503, total=   9.0s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100, score=0.502, total=   9.4s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100, score=0.507, total=   9.0s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100, score=0.503, total=   9.1s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50, score=0.504, total=   7.1s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50, score=0.505, total=   8.0s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50, score=0.503, total=   7.9s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50, score=0.507, total=   9.2s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50, score=0.503, total=  10.0s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100, score=0.505, total=  15.0s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100, score=0.505, total=  15.6s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100, score=0.503, total=  14.7s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100, score=0.507, total=  13.9s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100, score=0.503, total=  13.4s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50 \n"]},{"name":"stderr","output_type":"stream","text":["C:\\ProgramData\\Anaconda3\\envs\\dhdsblend2021\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"name":"stdout","output_type":"stream","text":["[12:53:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50, score=0.504, total=   2.3s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50 \n","[12:53:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50, score=0.502, total=   2.3s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50 \n","[12:53:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50, score=0.502, total=   2.2s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50 \n","[12:53:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50, score=0.506, total=   1.9s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50 \n","[12:53:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50, score=0.503, total=   2.0s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100 \n","[12:53:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100, score=0.503, total=   3.5s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100 \n","[12:53:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100, score=0.503, total=   4.5s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100 \n","[12:53:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100, score=0.503, total=   5.0s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100 \n","[12:53:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100, score=0.506, total=   7.1s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100 \n","[12:54:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100, score=0.505, total=   5.2s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50 \n","[12:54:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50, score=0.505, total=   4.4s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50 \n","[12:54:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50, score=0.505, total=   5.8s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50 \n","[12:54:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50, score=0.504, total=   3.4s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50 \n","[12:54:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50, score=0.508, total=   4.2s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50 \n","[12:54:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50, score=0.506, total=   5.7s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100 \n","[12:54:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100, score=0.506, total=   6.0s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100 \n","[12:54:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100, score=0.505, total=   9.1s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100 \n","[12:54:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100, score=0.506, total=   7.4s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100 \n","[12:54:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100, score=0.509, total=   6.6s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100 \n","[12:54:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100, score=0.507, total=   6.4s\n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Done  65 out of  65 | elapsed:  6.9min finished\n"]},{"name":"stdout","output_type":"stream","text":["[12:55:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","-----------------------------------\n","Mejores hiperparámetros encontrados\n","-----------------------------------\n","{'model': XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=2,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), 'model__max_depth': 2, 'model__n_estimators': 100} : 0.5065295382033919 None\n"]}],"source":["# Pipeline + Grid Search\n","pasos = [('scaler', None), ('model', LogisticRegression(random_state = 127,solver='liblinear'))]\n","pipe_grid = Pipeline(pasos)\n","param_grid = [{'model' : [tree.DecisionTreeClassifier(random_state=40)], 'model__max_depth':[2,4,6]},\n","              {'model' : [LogisticRegression(random_state = 127,solver='liblinear')], 'model__penalty':['l1','l2']},\n","              {'model' : [RandomForestClassifier(n_jobs=-1,bootstrap=True,random_state = 127)], 'model__n_estimators':[50,100], 'model__max_depth':[2,4]},\n","              {'model' : [xgb.XGBClassifier(n_jobs=-1)], 'model__n_estimators':[50,100], 'model__max_depth':[1,2]}]\n","cv = KFold(n_splits=5) #random_state=123)\n","gsearch = GridSearchCV(estimator=pipe_grid, cv=cv,\n","                        param_grid=param_grid, verbose=4)\n","gsearch.fit(X_train_6, y_train_6)\n","\n","print(\"-----------------------------------\")\n","print(\"Mejores hiperparámetros encontrados\")\n","print(\"-----------------------------------\")\n","print(gsearch.best_params_, \":\", gsearch.best_score_, gsearch.scoring)\n"]},{"cell_type":"markdown","id":"a1RXaas7hs-C","metadata":{"id":"a1RXaas7hs-C"},"source":["#### Ventana de 12 horas"]},{"cell_type":"code","execution_count":52,"id":"U8Z86-isTCRI","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":3967,"status":"ok","timestamp":1649998410619,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"U8Z86-isTCRI","outputId":"de3aa63f-43a7-457b-dbe9-46823d3632f9"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Fecha_hora</th>\n","      <th>user_followers</th>\n","      <th>text</th>\n","      <th>volume</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>301.0</td>\n","      <td>debunking myths by</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>301.0</td>\n","      <td>weekend read keen to learn about assets check...</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>301.0</td>\n","      <td>bloomberg lp with</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>301.0</td>\n","      <td>by</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>163.0</td>\n","      <td></td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            Fecha_hora  user_followers  \\\n","0  2021-02-05 10:00:00           301.0   \n","1  2021-02-05 10:00:00           301.0   \n","2  2021-02-05 10:00:00           301.0   \n","3  2021-02-05 10:00:00           301.0   \n","4  2021-02-05 10:00:00           163.0   \n","\n","                                                text    volume  target  \n","0                                debunking myths by   4.846474     0.0  \n","1   weekend read keen to learn about assets check...  4.846474     0.0  \n","2                                 bloomberg lp with   4.846474     0.0  \n","3                                                by   4.846474     0.0  \n","4                                                     4.846474     0.0  "]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["data_12 = pd.read_csv(root_path+'Data/data_12h_prep.csv')\n","columnas = ['Fecha_hora', 'user_followers', 'text', 'volume', 'target']\n","data_12.columns = columnas\n","data_12.head()"]},{"cell_type":"code","execution_count":53,"id":"P0zWJaikQF1f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":183537,"status":"ok","timestamp":1649998594154,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"P0zWJaikQF1f","outputId":"bec384f5-81f9-4374-f245-53785e7ddfa3"},"outputs":[{"data":{"text/plain":["[[0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.741, 0.259, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.323, 0.677, 0.6369],\n"," [0.0, 0.803, 0.197, 0.4019],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.756, 0.244, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.168, 0.16, 0.672, 0.743],\n"," [0.0, 0.615, 0.385, 0.3612],\n"," [0.0, 0.843, 0.157, 0.4215],\n"," [0.0, 0.82, 0.18, 0.0258],\n"," [0.0, 0.784, 0.216, 0.0258],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.859, 0.141, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.466, 0.534, 0.0, -0.7269],\n"," [0.0, 0.759, 0.241, 0.6597],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.0, 0.844, 0.156, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.091, 0.753, 0.156, 0.2196],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.286, 0.714, 0.0, -0.5574],\n"," [0.0, 0.683, 0.317, 0.6249],\n"," [0.0, 0.791, 0.209, 0.4404],\n"," [0.0, 0.504, 0.496, 0.7096],\n"," [0.0, 0.656, 0.344, 0.2732],\n"," [0.0, 0.876, 0.124, 0.34],\n"," [0.087, 0.913, 0.0, -0.2023],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.887, 0.113, 0.3182],\n"," [0.0, 0.843, 0.157, 0.3818],\n"," [0.0, 0.73, 0.27, 0.5719],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.203, 0.58, 0.217, 0.0258],\n"," [0.11, 0.756, 0.134, 0.1027],\n"," [0.0, 0.683, 0.317, 0.6249],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.749, 0.251, 0.5719],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.783, 0.217, 0.3818],\n"," [0.0, 0.8, 0.2, 0.3612],\n"," [0.107, 0.773, 0.12, 0.0772],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.203, 0.797, 0.0, -0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.809, 0.191, 0.5106],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.079, 0.785, 0.136, 0.2196],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.756, 0.244, 0.6697],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.815, 0.185, 0.5106],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.855, 0.145, 0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.855, 0.145, 0.296],\n"," [0.0, 0.769, 0.231, 0.5994],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.753, 0.247, 0.3818],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.824, 0.176, 0.296],\n"," [0.0, 0.792, 0.208, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.826, 0.174, 0.2263],\n"," [0.0, 0.529, 0.471, 0.7906],\n"," [0.0, 0.664, 0.336, 0.8225],\n"," [0.0, 0.78, 0.22, 0.4767],\n"," [0.0, 0.769, 0.231, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.866, 0.134, 0.1779],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.111, 0.758, 0.131, 0.1027],\n"," [0.0, 0.855, 0.145, 0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.852, 0.148, 0.3818],\n"," [0.0, 0.732, 0.268, 0.5106],\n"," [0.423, 0.577, 0.0, -0.6597],\n"," [0.0, 0.786, 0.214, 0.5994],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.425, 0.575, 0.0, -0.5719],\n"," [0.213, 0.787, 0.0, -0.2263],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.277, 0.723, 0.0, -0.5583],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.694, 0.306, 0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.662, 0.338, 0.5542],\n"," [0.0, 0.575, 0.425, 0.5719],\n"," [0.0, 0.345, 0.655, 0.2263],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.818, 0.182, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.123, 0.877, 0.0, -0.1027],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.577, 0.423, 0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.114, 0.702, 0.184, 0.3818],\n"," [0.0, 0.508, 0.492, 0.7003],\n"," [0.0, 0.508, 0.492, 0.7003],\n"," [0.0, 0.508, 0.492, 0.7003],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.273, 0.727, 0.0, -0.4588],\n"," [0.0, 0.806, 0.194, 0.34],\n"," [0.091, 0.579, 0.331, 0.7003],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.517, 0.483, 0.4215],\n"," [0.106, 0.894, 0.0, -0.2263],\n"," [0.0, 0.738, 0.262, 0.5994],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.84, 0.16, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.17, 0.721, 0.109, -0.2344],\n"," [0.0, 0.792, 0.208, 0.4939],\n"," [0.0, 0.75, 0.25, 0.7184],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.863, 0.137, 0.4019],\n"," [0.0, 0.813, 0.187, 0.3182],\n"," [0.079, 0.826, 0.095, 0.1027],\n"," [0.0, 0.435, 0.565, 0.5994],\n"," [0.0, 0.886, 0.114, 0.2648],\n"," [0.237, 0.763, 0.0, -0.4215],\n"," [0.0, 0.838, 0.162, 0.4404],\n"," [0.0, 0.791, 0.209, 0.4404],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.145, 0.855, 0.0, -0.296],\n"," [0.0, 0.508, 0.492, 0.7003],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.412, 0.588, 0.6908],\n"," [0.0, 0.508, 0.492, 0.7003],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.814, 0.186, 0.6249],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.585, 0.415, 0.7964],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.069, 0.931, 0.0, -0.1027],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.905, 0.095, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.769, 0.231, 0.4588],\n"," [0.0, 0.9, 0.1, 0.25],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.813, 0.187, 0.3182],\n"," [0.0, 0.884, 0.116, 0.3612],\n"," [0.0, 0.833, 0.167, 0.5574],\n"," [0.0, 0.274, 0.726, 0.6486],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.856, 0.144, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.821, 0.179, 0.34],\n"," [0.2, 0.8, 0.0, -0.4588],\n"," [0.0, 0.802, 0.198, 0.4939],\n"," [0.231, 0.769, 0.0, -0.5574],\n"," [0.0, 0.778, 0.222, 0.25],\n"," [0.0, 0.82, 0.18, 0.0258],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.119, 0.811, 0.07, -0.2263],\n"," [0.0, 0.66, 0.34, 0.5574],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.776, 0.224, 0.3818],\n"," [0.138, 0.566, 0.296, 0.3612],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.905, 0.095, 0.3182],\n"," [0.0, 0.822, 0.178, 0.3818],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.328, 0.672, 0.0, -0.5994],\n"," [0.0, 0.8, 0.2, 0.3612],\n"," [0.0, 0.795, 0.205, 0.2023],\n"," [0.0, 0.787, 0.213, 0.4019],\n"," [0.0, 0.746, 0.254, 0.7003],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.316, 0.684, 0.0, -0.5719],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.219, 0.781, 0.0, -0.2023],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.8, 0.2, 0.3612],\n"," [0.0, 0.588, 0.412, 0.8126],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.204, 0.796, 0.0, -0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.221, 0.779, 0.0, -0.6597],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.755, 0.245, 0.5994],\n"," [0.0, 0.769, 0.231, 0.2023],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.784, 0.216, 0.5106],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.604, 0.396, 0.7351],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.097, 0.903, 0.0, -0.128],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.09, 0.802, 0.108, 0.1027],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.341, 0.659, 0.0, -0.4767],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.408, 0.592, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.897, 0.103, 0.128],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.793, 0.207, 0.5267],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.82, 0.18, 0.0258],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.736, 0.264, 0.7269],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.909, 0.091, 0.1027],\n"," [0.314, 0.686, 0.0, -0.6705],\n"," [0.0, 0.508, 0.492, 0.5859],\n"," [0.0, 0.843, 0.157, 0.0772],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.821, 0.179, 0.34],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.882, 0.118, 0.34],\n"," [0.0, 0.787, 0.213, 0.5859],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.769, 0.231, 0.2023],\n"," [0.0, 0.802, 0.198, 0.6369],\n"," [0.0, 0.599, 0.401, 0.7717],\n"," [0.0, 0.773, 0.227, 0.6124],\n"," [0.268, 0.732, 0.0, -0.296],\n"," [0.0, 0.674, 0.326, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.882, 0.118, 0.2846],\n"," [0.0, 0.748, 0.252, 0.4019],\n"," [0.0, 0.8, 0.2, 0.4588],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.348, 0.652, 0.0, -0.1531],\n"," [0.0, 0.887, 0.113, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.8, 0.2, 0.4588],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.756, 0.244, 0.6369],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.694, 0.306, 0.296],\n"," [0.0, 0.694, 0.306, 0.296],\n"," [0.0, 0.884, 0.116, 0.3612],\n"," [0.0, 0.778, 0.222, 0.25],\n"," [0.0, 0.86, 0.14, 0.0772],\n"," [0.185, 0.815, 0.0, -0.3612],\n"," [0.0, 0.82, 0.18, 0.5106],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.204, 0.796, 0.0, -0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.694, 0.306, 0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.089, 0.691, 0.22, 0.4939],\n"," [0.0, 0.86, 0.14, 0.3818],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.734, 0.266, 0.4404],\n"," [0.286, 0.714, 0.0, -0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.849, 0.151, 0.4939],\n"," [0.133, 0.867, 0.0, -0.3818],\n"," [0.231, 0.769, 0.0, -0.34],\n"," [0.0, 0.64, 0.36, 0.5434],\n"," [0.075, 0.75, 0.175, 0.3818],\n"," [0.0, 0.827, 0.173, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.131, 0.763, 0.106, -0.1531],\n"," [0.0, 0.664, 0.336, 0.7248],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.776, 0.224, 0.6696],\n"," [0.0, 0.488, 0.512, 0.6369],\n"," [0.0, 0.911, 0.089, 0.1901],\n"," [0.0, 0.69, 0.31, 0.743],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.778, 0.222, 0.25],\n"," [0.0, 0.83, 0.17, 0.6249],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.816, 0.184, 0.4019],\n"," [0.316, 0.684, 0.0, -0.5719],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.588, 0.412, 0.5423],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.859, 0.141, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.341, 0.659, 0.0, -0.6367],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.765, 0.235, 0.4588],\n"," [0.167, 0.833, 0.0, -0.296],\n"," [0.0, 0.847, 0.153, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.728, 0.272, 0.6395],\n"," [0.0, 0.861, 0.139, 0.3089],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.3, 0.7, 0.0, -0.5945],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.821, 0.179, 0.34],\n"," [0.0, 0.673, 0.327, 0.743],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.398, 0.602, 0.0, -0.6486],\n"," [0.215, 0.785, 0.0, -0.6249],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.131, 0.765, 0.104, -0.1901],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.678, 0.322, 0.6908],\n"," [0.05, 0.561, 0.389, 0.8979],\n"," [0.0, 0.682, 0.318, 0.6369],\n"," [0.198, 0.802, 0.0, -0.5719],\n"," [0.0, 0.847, 0.153, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.535, 0.465, 0.7264],\n"," [0.0, 0.921, 0.079, 0.2263],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.751, 0.249, 0.5106],\n"," [0.0, 0.909, 0.091, 0.0258],\n"," [0.444, 0.556, 0.0, -0.9153],\n"," [0.0, 0.899, 0.101, 0.2023],\n"," [0.083, 0.632, 0.285, 0.7269],\n"," [0.109, 0.746, 0.144, 0.1779],\n"," [0.159, 0.841, 0.0, -0.5574],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.07, 0.873, 0.057, -0.0772],\n"," [0.112, 0.888, 0.0, -0.2263],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.115, 0.885, 0.0, -0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.809, 0.191, 0.3818],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.341, 0.659, 0.0, -0.4767],\n"," [0.0, 0.8, 0.2, 0.3612],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.739, 0.261, 0.6488],\n"," [0.225, 0.775, 0.0, -0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.702, 0.298, 0.6249],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.663, 0.337, 0.765],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.87, 0.13, 0.2023],\n"," [0.295, 0.705, 0.0, -0.7883],\n"," [0.1, 0.9, 0.0, -0.2732],\n"," [0.0, 0.698, 0.302, 0.4404],\n"," [0.202, 0.798, 0.0, -0.6486],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.8, 0.2, 0.4588],\n"," [0.057, 0.67, 0.273, 0.6705],\n"," [0.109, 0.891, 0.0, -0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.896, 0.104, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.904, 0.096, 0.177],\n"," [0.076, 0.811, 0.114, 0.1779],\n"," [0.0, 0.698, 0.302, 0.6369],\n"," [0.0, 0.802, 0.198, 0.6369],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.169, 0.756, 0.076, -0.3818],\n"," [0.405, 0.595, 0.0, -0.9225],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.371, 0.584, 0.045, -0.8885],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.864, 0.136, 0.296],\n"," [0.0, 0.769, 0.231, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.252, 0.748, 0.0, -0.5719],\n"," [0.323, 0.677, 0.0, -0.6486],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.161, 0.674, 0.166, 0.0258],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.899, 0.101, 0.2263],\n"," [0.0, 0.787, 0.213, 0.5574],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.714, 0.286, 0.6808],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.227, 0.773, 0.5267],\n"," [0.0, 0.588, 0.412, 0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.774, 0.226, 0.4215],\n"," [0.265, 0.735, 0.0, -0.6597],\n"," [0.121, 0.794, 0.084, -0.2023],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.504, 0.496, 0.7096],\n"," [0.0, 0.775, 0.225, 0.5859],\n"," [0.114, 0.761, 0.125, 0.0516],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.098, 0.813, 0.089, -0.0258],\n"," [0.0, 0.698, 0.302, 0.6369],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.72, 0.28, 0.5423],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.609, 0.391, 0.8828],\n"," [0.0, 0.544, 0.456, 0.7717],\n"," [0.0, 0.737, 0.263, 0.6908],\n"," [0.0, 0.852, 0.148, 0.3818],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.828, 0.172, 0.3612],\n"," [0.093, 0.814, 0.093, -0.0018],\n"," [0.11, 0.65, 0.24, 0.3818],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.316, 0.684, 0.0, -0.5588],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.72, 0.28, 0.765],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.753, 0.247, 0.3818],\n"," [0.0, 0.794, 0.206, 0.5994],\n"," [0.0, 0.865, 0.135, 0.3612],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.336, 0.49, 0.175, -0.3182],\n"," [0.73, 0.27, 0.0, -0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.133, 0.665, 0.202, 0.2228],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.498, 0.502, 0.9202],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.823, 0.177, 0.6249],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.266, 0.546, 0.188, -0.5106],\n"," [0.0, 0.69, 0.31, 0.6705],\n"," [0.22, 0.78, 0.0, -0.4767],\n"," [0.0, 0.713, 0.287, 0.7537],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.69, 0.31, 0.4019],\n"," [0.0, 0.637, 0.363, 0.6908],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.815, 0.185, 0.3612],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.605, 0.395, 0.5542],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.691, 0.309, 0.6682],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.596, 0.404, 0.8316],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.232, 0.768, 0.0, -0.6177],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.683, 0.317, 0.6705],\n"," [0.135, 0.71, 0.155, 0.0772],\n"," [0.0, 0.738, 0.262, 0.4927],\n"," [0.0, 0.758, 0.242, 0.3724],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.735, 0.265, 0.2023],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.818, 0.182, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.783, 0.217, 0.3612],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.418, 0.582, 0.0, -0.3804],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.821, 0.179, 0.34],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.8, 0.2, 0.3612],\n"," [0.076, 0.707, 0.217, 0.4215],\n"," [0.0, 0.682, 0.318, 0.6369],\n"," [0.072, 0.821, 0.108, 0.1779],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.072, 0.821, 0.108, 0.1779],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.0, 0.875, 0.125, 0.4588],\n"," [0.083, 0.784, 0.132, 0.25],\n"," [0.0, 0.508, 0.492, 0.7003],\n"," [0.132, 0.789, 0.079, -0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.305, 0.695, 0.8442],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.246, 0.629, 0.126, -0.4767],\n"," [0.0, 0.714, 0.286, 0.7003],\n"," [0.273, 0.727, 0.0, -0.4588],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.122, 0.612, 0.266, 0.4667],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.811, 0.189, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.797, 0.203, 0.552],\n"," [0.403, 0.597, 0.0, -0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.818, 0.182, 0.4404],\n"," [0.31, 0.69, 0.0, -0.5574],\n"," [0.0, 0.779, 0.221, 0.1779],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.833, 0.167, 0.2023],\n"," [0.0, 0.588, 0.412, 0.6369],\n"," [0.0, 0.213, 0.787, 0.5719],\n"," [0.126, 0.686, 0.189, 0.2732],\n"," [0.0, 0.633, 0.367, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.4, 0.6, 0.0, -0.25],\n"," [0.164, 0.672, 0.164, 0.0],\n"," [0.164, 0.672, 0.164, 0.0],\n"," [0.0, 0.522, 0.478, 0.6705],\n"," [0.0, 0.549, 0.451, 0.7506],\n"," [0.0, 0.659, 0.341, 0.7351],\n"," [0.0, 0.784, 0.216, 0.5106],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.56, 0.44, 0.6705],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.333, 0.667, 0.4588],\n"," [0.0, 0.863, 0.137, 0.2263],\n"," [0.097, 0.903, 0.0, -0.0191],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.672, 0.328, 0.4404],\n"," [0.167, 0.833, 0.0, -0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.741, 0.259, 0.4215],\n"," [0.0, 0.822, 0.178, 0.0772],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.787, 0.213, 0.4019],\n"," [0.132, 0.868, 0.0, -0.4404],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.128, 0.642, 0.229, 0.296],\n"," [0.172, 0.698, 0.13, 0.0258],\n"," [0.299, 0.597, 0.104, -0.4939],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.0, 0.823, 0.177, 0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.122, 0.732, 0.146, 0.0935],\n"," [0.0, 0.828, 0.172, 0.4404],\n"," [0.0, 0.844, 0.156, 0.5719],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.0, 0.842, 0.158, 0.128],\n"," [0.092, 0.908, 0.0, -0.2584],\n"," [0.0, 0.404, 0.596, 0.7096],\n"," [0.0, 0.469, 0.531, 0.5267],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.13, 0.87, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.694, 0.306, 0.296],\n"," [0.0, 0.829, 0.171, 0.4391],\n"," [0.18, 0.667, 0.153, -0.1027],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.147, 0.67, 0.184, -0.4299],\n"," [0.127, 0.597, 0.276, 0.4588],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.837, 0.163, 0.5994],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.553, 0.447, 0.836],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.872, 0.128, 0.3612],\n"," [0.0, 0.816, 0.184, 0.4019],\n"," [0.353, 0.321, 0.326, -0.0423],\n"," [0.0, 0.568, 0.432, 0.8225],\n"," [0.286, 0.714, 0.0, -0.3412],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.719, 0.281, 0.8316],\n"," [0.127, 0.769, 0.104, -0.1531],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.142, 0.645, 0.213, 0.2732],\n"," [0.0, 0.718, 0.282, 0.6705],\n"," [0.158, 0.842, 0.0, -0.4588],\n"," [0.0, 0.61, 0.39, 0.4939],\n"," [0.0, 0.691, 0.309, 0.7717],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.602, 0.398, 0.765],\n"," [0.417, 0.583, 0.0, -0.5106],\n"," [0.0, 0.427, 0.573, 0.9022],\n"," [0.0, 0.721, 0.279, 0.7351],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.115, 0.885, 0.0, -0.0772],\n"," [0.0, 0.714, 0.286, 0.5859],\n"," [0.0, 0.764, 0.236, 0.5719],\n"," [0.0, 0.796, 0.204, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.856, 0.144, 0.4019],\n"," [0.0, 0.742, 0.258, 0.7096],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.772, 0.228, 0.5477],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.258, 0.656, 0.086, -0.608],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.734, 0.266, 0.5719],\n"," [0.174, 0.826, 0.0, -0.2732],\n"," [0.187, 0.719, 0.094, -0.3182],\n"," [0.0, 0.815, 0.185, 0.3612],\n"," [0.643, 0.357, 0.0, -0.5574],\n"," [0.341, 0.659, 0.0, -0.4767],\n"," [0.0, 0.699, 0.301, 0.7096],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.106, 0.894, 0.0, -0.0772],\n"," [0.109, 0.891, 0.0, -0.296],\n"," [0.0, 0.68, 0.32, 0.5106],\n"," [0.0, 0.76, 0.24, 0.6249],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.86, 0.14, 0.5023],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.775, 0.225, 0.4404],\n"," [0.0, 0.414, 0.586, 0.795],\n"," [0.0, 0.708, 0.292, 0.4391],\n"," [0.0, 0.699, 0.301, 0.6808],\n"," [0.0, 0.714, 0.286, 0.6808],\n"," [0.0, 0.829, 0.171, 0.5106],\n"," [0.216, 0.784, 0.0, -0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.2, 0.8, 0.0, -0.5423],\n"," [0.0, 0.549, 0.451, 0.6249],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.732, 0.268, 0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.763, 0.237, 0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.823, 0.177, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.662, 0.338, 0.7321],\n"," [0.0, 0.8, 0.2, 0.3612],\n"," [0.245, 0.598, 0.158, -0.1531],\n"," [0.237, 0.763, 0.0, -0.4767],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.854, 0.146, 0.34],\n"," [0.145, 0.751, 0.104, -0.1779],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.199, 0.801, 0.0, -0.4973],\n"," [0.0, 0.763, 0.237, 0.6808],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.756, 0.244, 0.7003],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.256, 0.625, 0.119, -0.296],\n"," [0.0, 0.884, 0.116, 0.3612],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.783, 0.217, 0.3612],\n"," [0.0, 0.73, 0.27, 0.743],\n"," [0.0, 0.833, 0.167, 0.2023],\n"," [0.263, 0.737, 0.0, -0.5719],\n"," [0.0, 0.874, 0.126, 0.0772],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.727, 0.273, 0.7184],\n"," [0.0, 0.895, 0.105, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.551, 0.449, 0.6908],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.109, 0.891, 0.0, -0.296],\n"," [0.0, 0.328, 0.672, 0.6249],\n"," [0.193, 0.459, 0.349, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.858, 0.142, 0.5106],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.654, 0.346, 0.5719],\n"," [0.0, 0.828, 0.172, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.882, 0.118, 0.34],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.237, 0.678, 0.085, -0.6705],\n"," [0.062, 0.752, 0.186, 0.5859],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.178, 0.822, 0.0, -0.5709],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.145, 0.855, 0.0, -0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.429, 0.571, 0.0, -0.9001],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.098, 0.667, 0.235, 0.3612],\n"," [0.0, 0.741, 0.259, 0.4215],\n"," [0.161, 0.737, 0.101, -0.3182],\n"," [0.09, 0.66, 0.25, 0.5267],\n"," [0.196, 0.506, 0.297, 0.1531],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.541, 0.459, 0.8176],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.722, 0.278, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.784, 0.216, 0.5106],\n"," [0.101, 0.78, 0.119, 0.1027],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 1.0, 0.5994],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.078, 0.782, 0.14, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.756, 0.244, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.465, 0.535, 0.5574],\n"," [0.0, 0.741, 0.259, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.881, 0.119, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.792, 0.208, 0.2732],\n"," [0.191, 0.619, 0.191, 0.0],\n"," [0.0, 0.805, 0.195, 0.4404],\n"," [0.109, 0.891, 0.0, -0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.566, 0.434, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.847, 0.153, 0.4019],\n"," [0.0, 0.764, 0.236, 0.5719],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.157, 0.843, 0.0, -0.3818],\n"," [0.152, 0.848, 0.0, -0.5267],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.834, 0.166, 0.5849],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.773, 0.227, 0.6249],\n"," [0.188, 0.676, 0.136, -0.1744],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.513, 0.487, 0.6908],\n"," [0.0, 0.513, 0.487, 0.6908],\n"," [0.0, 0.513, 0.487, 0.6908],\n"," [0.0, 0.513, 0.487, 0.6908],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.597, 0.403, 0.0, -0.8126],\n"," [0.162, 0.838, 0.0, -0.4404],\n"," [0.0, 0.916, 0.084, 0.0258],\n"," [0.0, 0.828, 0.172, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.495, 0.434, 0.071, -0.868],\n"," [0.0, 1.0, 0.0, 0.0],\n"," ...]"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["sentiment=[senti_score_udf(x) for x in data_12['text']]\n","sentiment"]},{"cell_type":"code","execution_count":54,"id":"twfaFX2KypTw","metadata":{"executionInfo":{"elapsed":832,"status":"ok","timestamp":1649998594982,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"twfaFX2KypTw"},"outputs":[],"source":["df_sentimiento = pd.DataFrame(sentiment)\n","df_sentimiento.columns=['Negativo','Neutro','Positivo','Compound']\n","df_sentimiento.index=data_12.Fecha_hora"]},{"cell_type":"code","execution_count":55,"id":"FXLNJt_I2Of1","metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1649998594983,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"FXLNJt_I2Of1"},"outputs":[],"source":["data_12.set_index('Fecha_hora',drop=True,inplace=True)"]},{"cell_type":"code","execution_count":56,"id":"drtrggUt3F0H","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1649998594983,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"drtrggUt3F0H","outputId":"fa845ee8-5c97-4a80-88bb-d504fbc92181"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_followers</th>\n","      <th>text</th>\n","      <th>volume</th>\n","      <th>target</th>\n","    </tr>\n","    <tr>\n","      <th>Fecha_hora</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>debunking myths by</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>weekend read keen to learn about assets check...</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>bloomberg lp with</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>by</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>163.0</td>\n","      <td></td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     user_followers  \\\n","Fecha_hora                            \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           163.0   \n","\n","                                                                  text  \\\n","Fecha_hora                                                               \n","2021-02-05 10:00:00                                debunking myths by    \n","2021-02-05 10:00:00   weekend read keen to learn about assets check...   \n","2021-02-05 10:00:00                                 bloomberg lp with    \n","2021-02-05 10:00:00                                                by    \n","2021-02-05 10:00:00                                                      \n","\n","                       volume  target  \n","Fecha_hora                             \n","2021-02-05 10:00:00  4.846474     0.0  \n","2021-02-05 10:00:00  4.846474     0.0  \n","2021-02-05 10:00:00  4.846474     0.0  \n","2021-02-05 10:00:00  4.846474     0.0  \n","2021-02-05 10:00:00  4.846474     0.0  "]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["data_12.head()"]},{"cell_type":"code","execution_count":57,"id":"YXfMrLt823T9","metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1649998594984,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"YXfMrLt823T9"},"outputs":[],"source":["data_final_12= pd.concat([data_12,df_sentimiento],axis=1)\n","data_final_12.drop(['text','user_followers','volume'],inplace=True,axis=1)"]},{"cell_type":"code","execution_count":58,"id":"Vj33AJv43Q31","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1649998594985,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"Vj33AJv43Q31","outputId":"3ed10b45-990d-49f2-d5f8-8f638105ebca"},"outputs":[{"data":{"text/plain":["0.0    657639\n","1.0    632806\n","Name: target, dtype: int64"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["data_final_12.target.value_counts()"]},{"cell_type":"code","execution_count":59,"id":"VmYuxLJZ5UJ2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1649998594986,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"VmYuxLJZ5UJ2","outputId":"bfc59421-5462-453f-f497-583501459be4"},"outputs":[{"data":{"text/plain":["target      0\n","Negativo    0\n","Neutro      0\n","Positivo    0\n","Compound    0\n","dtype: int64"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["data_final_12.isna().sum()"]},{"cell_type":"code","execution_count":60,"id":"V4wPETAl6ntr","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":455},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1649998594987,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"V4wPETAl6ntr","outputId":"4af5cb99-7553-4f8a-9dc9-a310ac800db3"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>target</th>\n","      <th>Negativo</th>\n","      <th>Neutro</th>\n","      <th>Positivo</th>\n","      <th>Compound</th>\n","    </tr>\n","    <tr>\n","      <th>Fecha_hora</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.733375</td>\n","      <td>0.141625</td>\n","      <td>0.191587</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 11:00:00</th>\n","      <td>0.0</td>\n","      <td>0.036789</td>\n","      <td>0.858634</td>\n","      <td>0.104577</td>\n","      <td>0.136373</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 12:00:00</th>\n","      <td>0.0</td>\n","      <td>0.034255</td>\n","      <td>0.843436</td>\n","      <td>0.122319</td>\n","      <td>0.154889</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 13:00:00</th>\n","      <td>0.0</td>\n","      <td>0.029848</td>\n","      <td>0.847051</td>\n","      <td>0.092798</td>\n","      <td>0.116370</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 14:00:00</th>\n","      <td>0.0</td>\n","      <td>0.027440</td>\n","      <td>0.878612</td>\n","      <td>0.093948</td>\n","      <td>0.135504</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2022-02-18 14:00:00</th>\n","      <td>1.0</td>\n","      <td>0.043031</td>\n","      <td>0.840680</td>\n","      <td>0.116299</td>\n","      <td>0.162116</td>\n","    </tr>\n","    <tr>\n","      <th>2022-02-18 20:00:00</th>\n","      <td>1.0</td>\n","      <td>0.047657</td>\n","      <td>0.797960</td>\n","      <td>0.154389</td>\n","      <td>0.204873</td>\n","    </tr>\n","    <tr>\n","      <th>2022-02-18 21:00:00</th>\n","      <td>0.0</td>\n","      <td>0.047296</td>\n","      <td>0.836479</td>\n","      <td>0.116251</td>\n","      <td>0.163007</td>\n","    </tr>\n","    <tr>\n","      <th>2022-02-18 22:00:00</th>\n","      <td>1.0</td>\n","      <td>0.049515</td>\n","      <td>0.830021</td>\n","      <td>0.120461</td>\n","      <td>0.160952</td>\n","    </tr>\n","    <tr>\n","      <th>2022-02-18 23:00:00</th>\n","      <td>1.0</td>\n","      <td>0.072190</td>\n","      <td>0.820000</td>\n","      <td>0.107809</td>\n","      <td>0.085002</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2280 rows × 5 columns</p>\n","</div>"],"text/plain":["                     target  Negativo    Neutro  Positivo  Compound\n","Fecha_hora                                                         \n","2021-02-05 10:00:00     0.0  0.000000  0.733375  0.141625  0.191587\n","2021-02-05 11:00:00     0.0  0.036789  0.858634  0.104577  0.136373\n","2021-02-05 12:00:00     0.0  0.034255  0.843436  0.122319  0.154889\n","2021-02-05 13:00:00     0.0  0.029848  0.847051  0.092798  0.116370\n","2021-02-05 14:00:00     0.0  0.027440  0.878612  0.093948  0.135504\n","...                     ...       ...       ...       ...       ...\n","2022-02-18 14:00:00     1.0  0.043031  0.840680  0.116299  0.162116\n","2022-02-18 20:00:00     1.0  0.047657  0.797960  0.154389  0.204873\n","2022-02-18 21:00:00     0.0  0.047296  0.836479  0.116251  0.163007\n","2022-02-18 22:00:00     1.0  0.049515  0.830021  0.120461  0.160952\n","2022-02-18 23:00:00     1.0  0.072190  0.820000  0.107809  0.085002\n","\n","[2280 rows x 5 columns]"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["data_final_12.groupby(by=data_final_12.index,axis=0).mean()"]},{"cell_type":"code","execution_count":61,"id":"69A_bx5g3nPq","metadata":{"executionInfo":{"elapsed":15024,"status":"ok","timestamp":1649998610002,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"69A_bx5g3nPq"},"outputs":[],"source":["date=[dt.datetime.strptime(x,'%Y-%m-%d %H:%M:%S') for x in data_final_12.index]"]},{"cell_type":"code","execution_count":62,"id":"U1YdjErI4KNf","metadata":{"executionInfo":{"elapsed":2917,"status":"ok","timestamp":1649998612916,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"U1YdjErI4KNf"},"outputs":[],"source":["data_final_12.index=date"]},{"cell_type":"code","execution_count":63,"id":"MM4cyEwfX08n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1649998612917,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"MM4cyEwfX08n","outputId":"c190d24e-bd2a-4088-bdcf-7f36551e5fa2"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>target</th>\n","      <th>Negativo</th>\n","      <th>Neutro</th>\n","      <th>Positivo</th>\n","      <th>Compound</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.000</td>\n","      <td>0.000</td>\n","      <td>0.0000</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.741</td>\n","      <td>0.259</td>\n","      <td>0.4939</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.000</td>\n","      <td>0.000</td>\n","      <td>0.0000</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.000</td>\n","      <td>0.000</td>\n","      <td>0.0000</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     target  Negativo  Neutro  Positivo  Compound\n","2021-02-05 10:00:00     0.0       0.0   1.000     0.000    0.0000\n","2021-02-05 10:00:00     0.0       0.0   0.741     0.259    0.4939\n","2021-02-05 10:00:00     0.0       0.0   1.000     0.000    0.0000\n","2021-02-05 10:00:00     0.0       0.0   1.000     0.000    0.0000\n","2021-02-05 10:00:00     0.0       0.0   0.000     0.000    0.0000"]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["data_final_12.head()"]},{"cell_type":"code","execution_count":64,"id":"wND8tXVHYw3l","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1649998612917,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"wND8tXVHYw3l","outputId":"fb953c51-2250-4294-9a15-3126f0aaf1c6"},"outputs":[{"data":{"text/plain":["target      0.0000\n","Negativo    0.0000\n","Neutro      0.0000\n","Positivo    0.0000\n","Compound   -0.9918\n","dtype: float64"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["data_final_12.min()"]},{"cell_type":"code","execution_count":65,"id":"2LACwmonYhdJ","metadata":{"executionInfo":{"elapsed":3037,"status":"ok","timestamp":1649998656641,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"2LACwmonYhdJ"},"outputs":[],"source":["# Train Test Split\n","train,test=train_test_split(data_final_12,stratify=data_final_12['target'],random_state=3);\n","\n","#vectorizer=TfidfVectorizer();\n","X_train_12=train.drop(['target', 'Compound'], axis=1)\n","y_train_12=train['target'];\n","\n","X_test_12=test.drop(['target', 'Compound'], axis=1);\n","y_test_12=test['target'];"]},{"cell_type":"code","execution_count":67,"id":"6Jqv3TxjYhdK","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":708,"status":"ok","timestamp":1649998657344,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"6Jqv3TxjYhdK","outputId":"2db8cdaa-c0e2-47d8-b4b9-56cb2730658f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.509621464793622\n"]}],"source":["# Naive Bayes Multinomial\n","nbc=MultinomialNB();\n","\n","nbc.fit(X_train_12,y_train_12);\n","y_pred=nbc.predict(X_test_12);\n","\n","print('Accuracy:',accuracy_score(y_test_12,y_pred))"]},{"cell_type":"code","execution_count":68,"id":"f2niNdE_YhdK","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21169,"status":"ok","timestamp":1649996121640,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"f2niNdE_YhdK","outputId":"c9842213-3978-473d-e8ea-5d29850bc607"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n","[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    9.3s\n","[Parallel(n_jobs=3)]: Done  60 out of  60 | elapsed:   11.6s finished\n"]},{"name":"stdout","output_type":"stream","text":["best score: 0.5096218746252571\n","best params: {'alpha': 1e-05}\n"]}],"source":["X=data_final_12.drop(['target', 'Compound'], axis=1);\n","y=data_final_12['target'];\n","\n","skf=StratifiedKFold(n_splits=3,random_state=3,shuffle=True);\n","\n","params={'alpha':np.arange(0.00001,1,0.05)};\n","GS_CV=GridSearchCV(MultinomialNB(),params,cv=skf,verbose=1,n_jobs=3);\n","GS_CV.fit(X,y);\n","print('best score:',GS_CV.best_score_)\n","print('best params:',GS_CV.best_params_)"]},{"cell_type":"code","execution_count":69,"id":"CySQVTc8YhdK","metadata":{"id":"CySQVTc8YhdK"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 13 candidates, totalling 65 fits\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"]},{"name":"stdout","output_type":"stream","text":["[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.509, total=   0.4s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"]},{"name":"stdout","output_type":"stream","text":["[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.510, total=   0.4s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.6s remaining:    0.0s\n"]},{"name":"stdout","output_type":"stream","text":["[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.508, total=   0.4s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.0s remaining:    0.0s\n"]},{"name":"stdout","output_type":"stream","text":["[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.512, total=   0.4s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.509, total=   0.3s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.509, total=   0.6s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.511, total=   0.5s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.509, total=   0.5s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.512, total=   0.5s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.509, total=   0.7s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=6 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=6, score=0.510, total=   0.7s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=6 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=6, score=0.509, total=   0.7s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=6 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=6, score=0.509, total=   0.8s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=6 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=6, score=0.512, total=   0.7s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=6 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=6, score=0.509, total=   0.8s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1, score=0.509, total=  48.3s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1, score=0.510, total=  43.3s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1, score=0.508, total=  42.1s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1, score=0.512, total=  36.0s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1, score=0.509, total=  32.9s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2, score=0.509, total=   1.0s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2, score=0.510, total=   1.1s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2, score=0.508, total=   1.0s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2, score=0.512, total=   1.0s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2, score=0.509, total=   1.0s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50, score=0.509, total=   5.0s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50, score=0.510, total=   4.4s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50, score=0.508, total=   4.6s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50, score=0.512, total=   4.4s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50, score=0.509, total=   4.4s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100, score=0.509, total=   8.9s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100, score=0.510, total=   9.2s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100, score=0.508, total=   8.4s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100, score=0.512, total=   8.3s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100, score=0.509, total=   8.1s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50, score=0.510, total=   6.7s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50, score=0.511, total=   6.7s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50, score=0.509, total=   6.5s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50, score=0.513, total=   6.4s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50, score=0.510, total=   6.5s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100, score=0.509, total=  12.2s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100, score=0.511, total=  12.3s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100, score=0.509, total=  12.4s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100, score=0.513, total=  12.4s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100, score=0.510, total=  12.1s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50 \n"]},{"name":"stderr","output_type":"stream","text":["C:\\ProgramData\\Anaconda3\\envs\\dhdsblend2021\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"name":"stdout","output_type":"stream","text":["[14:22:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50, score=0.509, total=   1.9s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50 \n","[14:22:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50, score=0.510, total=   1.9s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50 \n","[14:22:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50, score=0.508, total=   1.8s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50 \n","[14:22:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50, score=0.512, total=   2.3s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50 \n","[14:22:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50, score=0.509, total=   1.7s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100 \n","[14:22:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100, score=0.509, total=   3.3s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100 \n","[14:22:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100, score=0.510, total=   3.2s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100 \n","[14:22:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100, score=0.508, total=   3.3s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100 \n","[14:22:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100, score=0.512, total=   3.3s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100 \n","[14:22:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100, score=0.509, total=   3.2s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50 \n","[14:22:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50, score=0.511, total=   3.0s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50 \n","[14:23:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50, score=0.511, total=   3.0s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50 \n","[14:23:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50, score=0.509, total=   2.9s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50 \n","[14:23:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50, score=0.513, total=   2.8s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50 \n","[14:23:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50, score=0.511, total=   3.1s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100 \n","[14:23:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100, score=0.512, total=   5.1s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100 \n","[14:23:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100, score=0.511, total=   5.2s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100 \n","[14:23:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100, score=0.510, total=   5.1s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100 \n","[14:23:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100, score=0.513, total=   5.3s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100 \n","[14:23:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100, score=0.512, total=   5.1s\n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Done  65 out of  65 | elapsed:  7.4min finished\n"]},{"name":"stdout","output_type":"stream","text":["[14:23:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","-----------------------------------\n","Mejores hiperparámetros encontrados\n","-----------------------------------\n","{'model': XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=2,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), 'model__max_depth': 2, 'model__n_estimators': 100} : 0.5116006609403081 None\n"]}],"source":["# Pipeline + Grid Search\n","pasos = [('scaler', None), ('model', LogisticRegression(random_state = 127,solver='liblinear'))]\n","pipe_grid = Pipeline(pasos)\n","param_grid = [{'model' : [tree.DecisionTreeClassifier(random_state=40)], 'model__max_depth':[2,4,6]},\n","              {'model' : [LogisticRegression(random_state = 127,solver='liblinear')], 'model__penalty':['l1','l2']},\n","              {'model' : [RandomForestClassifier(n_jobs=-1,bootstrap=True,random_state = 127)], 'model__n_estimators':[50,100], 'model__max_depth':[2,4]},\n","              {'model' : [xgb.XGBClassifier(n_jobs=-1)], 'model__n_estimators':[50,100], 'model__max_depth':[1,2]}]\n","cv = KFold(n_splits=5) #random_state=123)\n","gsearch = GridSearchCV(estimator=pipe_grid, cv=cv,\n","                        param_grid=param_grid, verbose=4)\n","gsearch.fit(X_train_12, y_train_12)\n","\n","print(\"-----------------------------------\")\n","print(\"Mejores hiperparámetros encontrados\")\n","print(\"-----------------------------------\")\n","print(gsearch.best_params_, \":\", gsearch.best_score_, gsearch.scoring)"]},{"cell_type":"markdown","id":"YqUnvqabhyFn","metadata":{"id":"YqUnvqabhyFn"},"source":["#### Ventana de 24 horas"]},{"cell_type":"code","execution_count":70,"id":"EWCIe9zWe_FW","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":3036,"status":"ok","timestamp":1649999054325,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"EWCIe9zWe_FW","outputId":"fe69740e-cd13-4ceb-9b59-caa3cd6652fc"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Fecha_hora</th>\n","      <th>user_followers</th>\n","      <th>text</th>\n","      <th>volume</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>301.0</td>\n","      <td>debunking myths by</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>301.0</td>\n","      <td>weekend read keen to learn about assets check...</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>301.0</td>\n","      <td>bloomberg lp with</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>301.0</td>\n","      <td>by</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2021-02-05 10:00:00</td>\n","      <td>163.0</td>\n","      <td></td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            Fecha_hora  user_followers  \\\n","0  2021-02-05 10:00:00           301.0   \n","1  2021-02-05 10:00:00           301.0   \n","2  2021-02-05 10:00:00           301.0   \n","3  2021-02-05 10:00:00           301.0   \n","4  2021-02-05 10:00:00           163.0   \n","\n","                                                text    volume  target  \n","0                                debunking myths by   4.846474     0.0  \n","1   weekend read keen to learn about assets check...  4.846474     0.0  \n","2                                 bloomberg lp with   4.846474     0.0  \n","3                                                by   4.846474     0.0  \n","4                                                     4.846474     0.0  "]},"execution_count":70,"metadata":{},"output_type":"execute_result"}],"source":["data_24 = pd.read_csv(root_path+'Data/data_24h_prep.csv')\n","columnas = ['Fecha_hora', 'user_followers', 'text', 'volume', 'target']\n","data_24.columns = columnas\n","data_24.head()"]},{"cell_type":"code","execution_count":71,"id":"GSD8FIPce_FW","metadata":{"id":"GSD8FIPce_FW"},"outputs":[{"data":{"text/plain":["[[0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.741, 0.259, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.323, 0.677, 0.6369],\n"," [0.0, 0.803, 0.197, 0.4019],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.756, 0.244, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.168, 0.16, 0.672, 0.743],\n"," [0.0, 0.615, 0.385, 0.3612],\n"," [0.0, 0.843, 0.157, 0.4215],\n"," [0.0, 0.82, 0.18, 0.0258],\n"," [0.0, 0.784, 0.216, 0.0258],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.859, 0.141, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.466, 0.534, 0.0, -0.7269],\n"," [0.0, 0.759, 0.241, 0.6597],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.0, 0.844, 0.156, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.091, 0.753, 0.156, 0.2196],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.286, 0.714, 0.0, -0.5574],\n"," [0.0, 0.683, 0.317, 0.6249],\n"," [0.0, 0.791, 0.209, 0.4404],\n"," [0.0, 0.504, 0.496, 0.7096],\n"," [0.0, 0.656, 0.344, 0.2732],\n"," [0.0, 0.876, 0.124, 0.34],\n"," [0.087, 0.913, 0.0, -0.2023],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.887, 0.113, 0.3182],\n"," [0.0, 0.843, 0.157, 0.3818],\n"," [0.0, 0.73, 0.27, 0.5719],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.203, 0.58, 0.217, 0.0258],\n"," [0.11, 0.756, 0.134, 0.1027],\n"," [0.0, 0.683, 0.317, 0.6249],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.749, 0.251, 0.5719],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.783, 0.217, 0.3818],\n"," [0.0, 0.8, 0.2, 0.3612],\n"," [0.107, 0.773, 0.12, 0.0772],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.203, 0.797, 0.0, -0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.809, 0.191, 0.5106],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.079, 0.785, 0.136, 0.2196],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.756, 0.244, 0.6697],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.815, 0.185, 0.5106],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.855, 0.145, 0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.855, 0.145, 0.296],\n"," [0.0, 0.769, 0.231, 0.5994],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.753, 0.247, 0.3818],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.824, 0.176, 0.296],\n"," [0.0, 0.792, 0.208, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.826, 0.174, 0.2263],\n"," [0.0, 0.529, 0.471, 0.7906],\n"," [0.0, 0.664, 0.336, 0.8225],\n"," [0.0, 0.78, 0.22, 0.4767],\n"," [0.0, 0.769, 0.231, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.866, 0.134, 0.1779],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.111, 0.758, 0.131, 0.1027],\n"," [0.0, 0.855, 0.145, 0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.852, 0.148, 0.3818],\n"," [0.0, 0.732, 0.268, 0.5106],\n"," [0.423, 0.577, 0.0, -0.6597],\n"," [0.0, 0.786, 0.214, 0.5994],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.425, 0.575, 0.0, -0.5719],\n"," [0.213, 0.787, 0.0, -0.2263],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.277, 0.723, 0.0, -0.5583],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.694, 0.306, 0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.662, 0.338, 0.5542],\n"," [0.0, 0.575, 0.425, 0.5719],\n"," [0.0, 0.345, 0.655, 0.2263],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.818, 0.182, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.123, 0.877, 0.0, -0.1027],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.577, 0.423, 0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.114, 0.702, 0.184, 0.3818],\n"," [0.0, 0.508, 0.492, 0.7003],\n"," [0.0, 0.508, 0.492, 0.7003],\n"," [0.0, 0.508, 0.492, 0.7003],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.273, 0.727, 0.0, -0.4588],\n"," [0.0, 0.806, 0.194, 0.34],\n"," [0.091, 0.579, 0.331, 0.7003],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.517, 0.483, 0.4215],\n"," [0.106, 0.894, 0.0, -0.2263],\n"," [0.0, 0.738, 0.262, 0.5994],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.84, 0.16, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.17, 0.721, 0.109, -0.2344],\n"," [0.0, 0.792, 0.208, 0.4939],\n"," [0.0, 0.75, 0.25, 0.7184],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.863, 0.137, 0.4019],\n"," [0.0, 0.813, 0.187, 0.3182],\n"," [0.079, 0.826, 0.095, 0.1027],\n"," [0.0, 0.435, 0.565, 0.5994],\n"," [0.0, 0.886, 0.114, 0.2648],\n"," [0.237, 0.763, 0.0, -0.4215],\n"," [0.0, 0.838, 0.162, 0.4404],\n"," [0.0, 0.791, 0.209, 0.4404],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.145, 0.855, 0.0, -0.296],\n"," [0.0, 0.508, 0.492, 0.7003],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.412, 0.588, 0.6908],\n"," [0.0, 0.508, 0.492, 0.7003],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.814, 0.186, 0.6249],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.585, 0.415, 0.7964],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.069, 0.931, 0.0, -0.1027],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.905, 0.095, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.769, 0.231, 0.4588],\n"," [0.0, 0.9, 0.1, 0.25],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.813, 0.187, 0.3182],\n"," [0.0, 0.884, 0.116, 0.3612],\n"," [0.0, 0.833, 0.167, 0.5574],\n"," [0.0, 0.274, 0.726, 0.6486],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.856, 0.144, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.821, 0.179, 0.34],\n"," [0.2, 0.8, 0.0, -0.4588],\n"," [0.0, 0.802, 0.198, 0.4939],\n"," [0.231, 0.769, 0.0, -0.5574],\n"," [0.0, 0.778, 0.222, 0.25],\n"," [0.0, 0.82, 0.18, 0.0258],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.119, 0.811, 0.07, -0.2263],\n"," [0.0, 0.66, 0.34, 0.5574],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.776, 0.224, 0.3818],\n"," [0.138, 0.566, 0.296, 0.3612],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.905, 0.095, 0.3182],\n"," [0.0, 0.822, 0.178, 0.3818],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.328, 0.672, 0.0, -0.5994],\n"," [0.0, 0.8, 0.2, 0.3612],\n"," [0.0, 0.795, 0.205, 0.2023],\n"," [0.0, 0.787, 0.213, 0.4019],\n"," [0.0, 0.746, 0.254, 0.7003],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.316, 0.684, 0.0, -0.5719],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.219, 0.781, 0.0, -0.2023],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.8, 0.2, 0.3612],\n"," [0.0, 0.588, 0.412, 0.8126],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.204, 0.796, 0.0, -0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.221, 0.779, 0.0, -0.6597],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.755, 0.245, 0.5994],\n"," [0.0, 0.769, 0.231, 0.2023],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.784, 0.216, 0.5106],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.604, 0.396, 0.7351],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.097, 0.903, 0.0, -0.128],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.09, 0.802, 0.108, 0.1027],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.341, 0.659, 0.0, -0.4767],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.408, 0.592, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.897, 0.103, 0.128],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.793, 0.207, 0.5267],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.82, 0.18, 0.0258],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.736, 0.264, 0.7269],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.909, 0.091, 0.1027],\n"," [0.314, 0.686, 0.0, -0.6705],\n"," [0.0, 0.508, 0.492, 0.5859],\n"," [0.0, 0.843, 0.157, 0.0772],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.821, 0.179, 0.34],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.882, 0.118, 0.34],\n"," [0.0, 0.787, 0.213, 0.5859],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.769, 0.231, 0.2023],\n"," [0.0, 0.802, 0.198, 0.6369],\n"," [0.0, 0.599, 0.401, 0.7717],\n"," [0.0, 0.773, 0.227, 0.6124],\n"," [0.268, 0.732, 0.0, -0.296],\n"," [0.0, 0.674, 0.326, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.882, 0.118, 0.2846],\n"," [0.0, 0.748, 0.252, 0.4019],\n"," [0.0, 0.8, 0.2, 0.4588],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.348, 0.652, 0.0, -0.1531],\n"," [0.0, 0.887, 0.113, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.8, 0.2, 0.4588],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.756, 0.244, 0.6369],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.694, 0.306, 0.296],\n"," [0.0, 0.694, 0.306, 0.296],\n"," [0.0, 0.884, 0.116, 0.3612],\n"," [0.0, 0.778, 0.222, 0.25],\n"," [0.0, 0.86, 0.14, 0.0772],\n"," [0.185, 0.815, 0.0, -0.3612],\n"," [0.0, 0.82, 0.18, 0.5106],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.204, 0.796, 0.0, -0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.694, 0.306, 0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.089, 0.691, 0.22, 0.4939],\n"," [0.0, 0.86, 0.14, 0.3818],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.734, 0.266, 0.4404],\n"," [0.286, 0.714, 0.0, -0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.849, 0.151, 0.4939],\n"," [0.133, 0.867, 0.0, -0.3818],\n"," [0.231, 0.769, 0.0, -0.34],\n"," [0.0, 0.64, 0.36, 0.5434],\n"," [0.075, 0.75, 0.175, 0.3818],\n"," [0.0, 0.827, 0.173, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.131, 0.763, 0.106, -0.1531],\n"," [0.0, 0.664, 0.336, 0.7248],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.776, 0.224, 0.6696],\n"," [0.0, 0.488, 0.512, 0.6369],\n"," [0.0, 0.911, 0.089, 0.1901],\n"," [0.0, 0.69, 0.31, 0.743],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.778, 0.222, 0.25],\n"," [0.0, 0.83, 0.17, 0.6249],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.816, 0.184, 0.4019],\n"," [0.316, 0.684, 0.0, -0.5719],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.588, 0.412, 0.5423],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.859, 0.141, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.341, 0.659, 0.0, -0.6367],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.765, 0.235, 0.4588],\n"," [0.167, 0.833, 0.0, -0.296],\n"," [0.0, 0.847, 0.153, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.728, 0.272, 0.6395],\n"," [0.0, 0.861, 0.139, 0.3089],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.3, 0.7, 0.0, -0.5945],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.821, 0.179, 0.34],\n"," [0.0, 0.673, 0.327, 0.743],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.398, 0.602, 0.0, -0.6486],\n"," [0.215, 0.785, 0.0, -0.6249],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.131, 0.765, 0.104, -0.1901],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.678, 0.322, 0.6908],\n"," [0.05, 0.561, 0.389, 0.8979],\n"," [0.0, 0.682, 0.318, 0.6369],\n"," [0.198, 0.802, 0.0, -0.5719],\n"," [0.0, 0.847, 0.153, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.535, 0.465, 0.7264],\n"," [0.0, 0.921, 0.079, 0.2263],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.751, 0.249, 0.5106],\n"," [0.0, 0.909, 0.091, 0.0258],\n"," [0.444, 0.556, 0.0, -0.9153],\n"," [0.0, 0.899, 0.101, 0.2023],\n"," [0.083, 0.632, 0.285, 0.7269],\n"," [0.109, 0.746, 0.144, 0.1779],\n"," [0.159, 0.841, 0.0, -0.5574],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.07, 0.873, 0.057, -0.0772],\n"," [0.112, 0.888, 0.0, -0.2263],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.115, 0.885, 0.0, -0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.809, 0.191, 0.3818],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.341, 0.659, 0.0, -0.4767],\n"," [0.0, 0.8, 0.2, 0.3612],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.739, 0.261, 0.6488],\n"," [0.225, 0.775, 0.0, -0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.702, 0.298, 0.6249],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.663, 0.337, 0.765],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.87, 0.13, 0.2023],\n"," [0.295, 0.705, 0.0, -0.7883],\n"," [0.1, 0.9, 0.0, -0.2732],\n"," [0.0, 0.698, 0.302, 0.4404],\n"," [0.202, 0.798, 0.0, -0.6486],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.8, 0.2, 0.4588],\n"," [0.057, 0.67, 0.273, 0.6705],\n"," [0.109, 0.891, 0.0, -0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.896, 0.104, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.904, 0.096, 0.177],\n"," [0.076, 0.811, 0.114, 0.1779],\n"," [0.0, 0.698, 0.302, 0.6369],\n"," [0.0, 0.802, 0.198, 0.6369],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.169, 0.756, 0.076, -0.3818],\n"," [0.405, 0.595, 0.0, -0.9225],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.371, 0.584, 0.045, -0.8885],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.864, 0.136, 0.296],\n"," [0.0, 0.769, 0.231, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.252, 0.748, 0.0, -0.5719],\n"," [0.323, 0.677, 0.0, -0.6486],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.161, 0.674, 0.166, 0.0258],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.899, 0.101, 0.2263],\n"," [0.0, 0.787, 0.213, 0.5574],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.714, 0.286, 0.6808],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.227, 0.773, 0.5267],\n"," [0.0, 0.588, 0.412, 0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.774, 0.226, 0.4215],\n"," [0.265, 0.735, 0.0, -0.6597],\n"," [0.121, 0.794, 0.084, -0.2023],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.504, 0.496, 0.7096],\n"," [0.0, 0.775, 0.225, 0.5859],\n"," [0.114, 0.761, 0.125, 0.0516],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.098, 0.813, 0.089, -0.0258],\n"," [0.0, 0.698, 0.302, 0.6369],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.72, 0.28, 0.5423],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.609, 0.391, 0.8828],\n"," [0.0, 0.544, 0.456, 0.7717],\n"," [0.0, 0.737, 0.263, 0.6908],\n"," [0.0, 0.852, 0.148, 0.3818],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.828, 0.172, 0.3612],\n"," [0.093, 0.814, 0.093, -0.0018],\n"," [0.11, 0.65, 0.24, 0.3818],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.316, 0.684, 0.0, -0.5588],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.72, 0.28, 0.765],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.753, 0.247, 0.3818],\n"," [0.0, 0.794, 0.206, 0.5994],\n"," [0.0, 0.865, 0.135, 0.3612],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.336, 0.49, 0.175, -0.3182],\n"," [0.73, 0.27, 0.0, -0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.133, 0.665, 0.202, 0.2228],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.498, 0.502, 0.9202],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.823, 0.177, 0.6249],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.266, 0.546, 0.188, -0.5106],\n"," [0.0, 0.69, 0.31, 0.6705],\n"," [0.22, 0.78, 0.0, -0.4767],\n"," [0.0, 0.713, 0.287, 0.7537],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.69, 0.31, 0.4019],\n"," [0.0, 0.637, 0.363, 0.6908],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.815, 0.185, 0.3612],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.605, 0.395, 0.5542],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.691, 0.309, 0.6682],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.596, 0.404, 0.8316],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.232, 0.768, 0.0, -0.6177],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.683, 0.317, 0.6705],\n"," [0.135, 0.71, 0.155, 0.0772],\n"," [0.0, 0.738, 0.262, 0.4927],\n"," [0.0, 0.758, 0.242, 0.3724],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.735, 0.265, 0.2023],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.818, 0.182, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.783, 0.217, 0.3612],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.418, 0.582, 0.0, -0.3804],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.821, 0.179, 0.34],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.8, 0.2, 0.3612],\n"," [0.076, 0.707, 0.217, 0.4215],\n"," [0.0, 0.682, 0.318, 0.6369],\n"," [0.072, 0.821, 0.108, 0.1779],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.072, 0.821, 0.108, 0.1779],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.824, 0.176, 0.4939],\n"," [0.0, 0.875, 0.125, 0.4588],\n"," [0.083, 0.784, 0.132, 0.25],\n"," [0.0, 0.508, 0.492, 0.7003],\n"," [0.132, 0.789, 0.079, -0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.305, 0.695, 0.8442],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.246, 0.629, 0.126, -0.4767],\n"," [0.0, 0.714, 0.286, 0.7003],\n"," [0.273, 0.727, 0.0, -0.4588],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.122, 0.612, 0.266, 0.4667],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.811, 0.189, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.797, 0.203, 0.552],\n"," [0.403, 0.597, 0.0, -0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.818, 0.182, 0.4404],\n"," [0.31, 0.69, 0.0, -0.5574],\n"," [0.0, 0.779, 0.221, 0.1779],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.833, 0.167, 0.2023],\n"," [0.0, 0.588, 0.412, 0.6369],\n"," [0.0, 0.213, 0.787, 0.5719],\n"," [0.126, 0.686, 0.189, 0.2732],\n"," [0.0, 0.633, 0.367, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.4, 0.6, 0.0, -0.25],\n"," [0.164, 0.672, 0.164, 0.0],\n"," [0.164, 0.672, 0.164, 0.0],\n"," [0.0, 0.522, 0.478, 0.6705],\n"," [0.0, 0.549, 0.451, 0.7506],\n"," [0.0, 0.659, 0.341, 0.7351],\n"," [0.0, 0.784, 0.216, 0.5106],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.56, 0.44, 0.6705],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.333, 0.667, 0.4588],\n"," [0.0, 0.863, 0.137, 0.2263],\n"," [0.097, 0.903, 0.0, -0.0191],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.672, 0.328, 0.4404],\n"," [0.167, 0.833, 0.0, -0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.741, 0.259, 0.4215],\n"," [0.0, 0.822, 0.178, 0.0772],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.787, 0.213, 0.4019],\n"," [0.132, 0.868, 0.0, -0.4404],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.128, 0.642, 0.229, 0.296],\n"," [0.172, 0.698, 0.13, 0.0258],\n"," [0.299, 0.597, 0.104, -0.4939],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.0, 0.823, 0.177, 0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.122, 0.732, 0.146, 0.0935],\n"," [0.0, 0.828, 0.172, 0.4404],\n"," [0.0, 0.844, 0.156, 0.5719],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.0, 0.842, 0.158, 0.128],\n"," [0.092, 0.908, 0.0, -0.2584],\n"," [0.0, 0.404, 0.596, 0.7096],\n"," [0.0, 0.469, 0.531, 0.5267],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.13, 0.87, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.694, 0.306, 0.296],\n"," [0.0, 0.829, 0.171, 0.4391],\n"," [0.18, 0.667, 0.153, -0.1027],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.147, 0.67, 0.184, -0.4299],\n"," [0.127, 0.597, 0.276, 0.4588],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.837, 0.163, 0.5994],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.553, 0.447, 0.836],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.872, 0.128, 0.3612],\n"," [0.0, 0.816, 0.184, 0.4019],\n"," [0.353, 0.321, 0.326, -0.0423],\n"," [0.0, 0.568, 0.432, 0.8225],\n"," [0.286, 0.714, 0.0, -0.3412],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.719, 0.281, 0.8316],\n"," [0.127, 0.769, 0.104, -0.1531],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.142, 0.645, 0.213, 0.2732],\n"," [0.0, 0.718, 0.282, 0.6705],\n"," [0.158, 0.842, 0.0, -0.4588],\n"," [0.0, 0.61, 0.39, 0.4939],\n"," [0.0, 0.691, 0.309, 0.7717],\n"," [0.0, 0.682, 0.318, 0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.602, 0.398, 0.765],\n"," [0.417, 0.583, 0.0, -0.5106],\n"," [0.0, 0.427, 0.573, 0.9022],\n"," [0.0, 0.721, 0.279, 0.7351],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.115, 0.885, 0.0, -0.0772],\n"," [0.0, 0.714, 0.286, 0.5859],\n"," [0.0, 0.764, 0.236, 0.5719],\n"," [0.0, 0.796, 0.204, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.856, 0.144, 0.4019],\n"," [0.0, 0.742, 0.258, 0.7096],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.772, 0.228, 0.5477],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.258, 0.656, 0.086, -0.608],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.734, 0.266, 0.5719],\n"," [0.174, 0.826, 0.0, -0.2732],\n"," [0.187, 0.719, 0.094, -0.3182],\n"," [0.0, 0.815, 0.185, 0.3612],\n"," [0.643, 0.357, 0.0, -0.5574],\n"," [0.341, 0.659, 0.0, -0.4767],\n"," [0.0, 0.699, 0.301, 0.7096],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.106, 0.894, 0.0, -0.0772],\n"," [0.109, 0.891, 0.0, -0.296],\n"," [0.0, 0.68, 0.32, 0.5106],\n"," [0.0, 0.76, 0.24, 0.6249],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.86, 0.14, 0.5023],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.775, 0.225, 0.4404],\n"," [0.0, 0.414, 0.586, 0.795],\n"," [0.0, 0.708, 0.292, 0.4391],\n"," [0.0, 0.699, 0.301, 0.6808],\n"," [0.0, 0.714, 0.286, 0.6808],\n"," [0.0, 0.829, 0.171, 0.5106],\n"," [0.216, 0.784, 0.0, -0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.2, 0.8, 0.0, -0.5423],\n"," [0.0, 0.549, 0.451, 0.6249],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.732, 0.268, 0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.763, 0.237, 0.4215],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.823, 0.177, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.662, 0.338, 0.7321],\n"," [0.0, 0.8, 0.2, 0.3612],\n"," [0.245, 0.598, 0.158, -0.1531],\n"," [0.237, 0.763, 0.0, -0.4767],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.854, 0.146, 0.34],\n"," [0.145, 0.751, 0.104, -0.1779],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.199, 0.801, 0.0, -0.4973],\n"," [0.0, 0.763, 0.237, 0.6808],\n"," [0.0, 0.0, 0.0, 0.0],\n"," [0.0, 0.756, 0.244, 0.7003],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.256, 0.625, 0.119, -0.296],\n"," [0.0, 0.884, 0.116, 0.3612],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.783, 0.217, 0.3612],\n"," [0.0, 0.73, 0.27, 0.743],\n"," [0.0, 0.833, 0.167, 0.2023],\n"," [0.263, 0.737, 0.0, -0.5719],\n"," [0.0, 0.874, 0.126, 0.0772],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.727, 0.273, 0.7184],\n"," [0.0, 0.895, 0.105, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.551, 0.449, 0.6908],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.109, 0.891, 0.0, -0.296],\n"," [0.0, 0.328, 0.672, 0.6249],\n"," [0.193, 0.459, 0.349, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.858, 0.142, 0.5106],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.654, 0.346, 0.5719],\n"," [0.0, 0.828, 0.172, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.882, 0.118, 0.34],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.237, 0.678, 0.085, -0.6705],\n"," [0.062, 0.752, 0.186, 0.5859],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.178, 0.822, 0.0, -0.5709],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.145, 0.855, 0.0, -0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.429, 0.571, 0.0, -0.9001],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.098, 0.667, 0.235, 0.3612],\n"," [0.0, 0.741, 0.259, 0.4215],\n"," [0.161, 0.737, 0.101, -0.3182],\n"," [0.09, 0.66, 0.25, 0.5267],\n"," [0.196, 0.506, 0.297, 0.1531],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.541, 0.459, 0.8176],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.722, 0.278, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.784, 0.216, 0.5106],\n"," [0.101, 0.78, 0.119, 0.1027],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.0, 1.0, 0.5994],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.078, 0.782, 0.14, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.756, 0.244, 0.4404],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.465, 0.535, 0.5574],\n"," [0.0, 0.741, 0.259, 0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.881, 0.119, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.792, 0.208, 0.2732],\n"," [0.191, 0.619, 0.191, 0.0],\n"," [0.0, 0.805, 0.195, 0.4404],\n"," [0.109, 0.891, 0.0, -0.296],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.566, 0.434, 0.3182],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.847, 0.153, 0.4019],\n"," [0.0, 0.764, 0.236, 0.5719],\n"," [0.344, 0.656, 0.0, -0.2732],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.157, 0.843, 0.0, -0.3818],\n"," [0.152, 0.848, 0.0, -0.5267],\n"," [0.234, 0.532, 0.234, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.834, 0.166, 0.5849],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.773, 0.227, 0.6249],\n"," [0.188, 0.676, 0.136, -0.1744],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 0.513, 0.487, 0.6908],\n"," [0.0, 0.513, 0.487, 0.6908],\n"," [0.0, 0.513, 0.487, 0.6908],\n"," [0.0, 0.513, 0.487, 0.6908],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.597, 0.403, 0.0, -0.8126],\n"," [0.162, 0.838, 0.0, -0.4404],\n"," [0.0, 0.916, 0.084, 0.0258],\n"," [0.0, 0.828, 0.172, 0.4019],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.0, 1.0, 0.0, 0.0],\n"," [0.495, 0.434, 0.071, -0.868],\n"," [0.0, 1.0, 0.0, 0.0],\n"," ...]"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["sentiment=[senti_score_udf(x) for x in data_24['text']]\n","sentiment"]},{"cell_type":"code","execution_count":72,"id":"nI6TqHyLe_FX","metadata":{"id":"nI6TqHyLe_FX"},"outputs":[],"source":["df_sentimiento = pd.DataFrame(sentiment)\n","df_sentimiento.columns=['Negativo','Neutro','Positivo','Compound']\n","df_sentimiento.index=data_24.Fecha_hora"]},{"cell_type":"code","execution_count":73,"id":"5qsQt7qte_FX","metadata":{"id":"5qsQt7qte_FX"},"outputs":[],"source":["data_24.set_index('Fecha_hora',drop=True,inplace=True)"]},{"cell_type":"code","execution_count":74,"id":"3ABEU6Y0e_FX","metadata":{"id":"3ABEU6Y0e_FX"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_followers</th>\n","      <th>text</th>\n","      <th>volume</th>\n","      <th>target</th>\n","    </tr>\n","    <tr>\n","      <th>Fecha_hora</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>debunking myths by</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>weekend read keen to learn about assets check...</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>bloomberg lp with</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>301.0</td>\n","      <td>by</td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>163.0</td>\n","      <td></td>\n","      <td>4.846474</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     user_followers  \\\n","Fecha_hora                            \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           301.0   \n","2021-02-05 10:00:00           163.0   \n","\n","                                                                  text  \\\n","Fecha_hora                                                               \n","2021-02-05 10:00:00                                debunking myths by    \n","2021-02-05 10:00:00   weekend read keen to learn about assets check...   \n","2021-02-05 10:00:00                                 bloomberg lp with    \n","2021-02-05 10:00:00                                                by    \n","2021-02-05 10:00:00                                                      \n","\n","                       volume  target  \n","Fecha_hora                             \n","2021-02-05 10:00:00  4.846474     0.0  \n","2021-02-05 10:00:00  4.846474     0.0  \n","2021-02-05 10:00:00  4.846474     0.0  \n","2021-02-05 10:00:00  4.846474     0.0  \n","2021-02-05 10:00:00  4.846474     0.0  "]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["data_24.head()"]},{"cell_type":"code","execution_count":75,"id":"VXd78Qgwe_FX","metadata":{"id":"VXd78Qgwe_FX"},"outputs":[],"source":["data_final_24= pd.concat([data_24,df_sentimiento],axis=1)\n","data_final_24.drop(['text','user_followers','volume'],inplace=True,axis=1)"]},{"cell_type":"code","execution_count":76,"id":"LRrnNOcle_FX","metadata":{"id":"LRrnNOcle_FX"},"outputs":[{"data":{"text/plain":["0.0    664187\n","1.0    626258\n","Name: target, dtype: int64"]},"execution_count":76,"metadata":{},"output_type":"execute_result"}],"source":["data_final_24.target.value_counts()"]},{"cell_type":"code","execution_count":77,"id":"Sx9TWk0Je_FX","metadata":{"id":"Sx9TWk0Je_FX"},"outputs":[{"data":{"text/plain":["target      0\n","Negativo    0\n","Neutro      0\n","Positivo    0\n","Compound    0\n","dtype: int64"]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"source":["data_final_24.isna().sum()"]},{"cell_type":"code","execution_count":78,"id":"MIH7V0r5e_FX","metadata":{"id":"MIH7V0r5e_FX"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>target</th>\n","      <th>Negativo</th>\n","      <th>Neutro</th>\n","      <th>Positivo</th>\n","      <th>Compound</th>\n","    </tr>\n","    <tr>\n","      <th>Fecha_hora</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.733375</td>\n","      <td>0.141625</td>\n","      <td>0.191587</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 11:00:00</th>\n","      <td>1.0</td>\n","      <td>0.036789</td>\n","      <td>0.858634</td>\n","      <td>0.104577</td>\n","      <td>0.136373</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 12:00:00</th>\n","      <td>0.0</td>\n","      <td>0.034255</td>\n","      <td>0.843436</td>\n","      <td>0.122319</td>\n","      <td>0.154889</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 13:00:00</th>\n","      <td>0.0</td>\n","      <td>0.029848</td>\n","      <td>0.847051</td>\n","      <td>0.092798</td>\n","      <td>0.116370</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 14:00:00</th>\n","      <td>0.0</td>\n","      <td>0.027440</td>\n","      <td>0.878612</td>\n","      <td>0.093948</td>\n","      <td>0.135504</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2022-02-18 14:00:00</th>\n","      <td>0.0</td>\n","      <td>0.043031</td>\n","      <td>0.840680</td>\n","      <td>0.116299</td>\n","      <td>0.162116</td>\n","    </tr>\n","    <tr>\n","      <th>2022-02-18 20:00:00</th>\n","      <td>1.0</td>\n","      <td>0.047657</td>\n","      <td>0.797960</td>\n","      <td>0.154389</td>\n","      <td>0.204873</td>\n","    </tr>\n","    <tr>\n","      <th>2022-02-18 21:00:00</th>\n","      <td>0.0</td>\n","      <td>0.047296</td>\n","      <td>0.836479</td>\n","      <td>0.116251</td>\n","      <td>0.163007</td>\n","    </tr>\n","    <tr>\n","      <th>2022-02-18 22:00:00</th>\n","      <td>0.0</td>\n","      <td>0.049515</td>\n","      <td>0.830021</td>\n","      <td>0.120461</td>\n","      <td>0.160952</td>\n","    </tr>\n","    <tr>\n","      <th>2022-02-18 23:00:00</th>\n","      <td>1.0</td>\n","      <td>0.072190</td>\n","      <td>0.820000</td>\n","      <td>0.107809</td>\n","      <td>0.085002</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2280 rows × 5 columns</p>\n","</div>"],"text/plain":["                     target  Negativo    Neutro  Positivo  Compound\n","Fecha_hora                                                         \n","2021-02-05 10:00:00     0.0  0.000000  0.733375  0.141625  0.191587\n","2021-02-05 11:00:00     1.0  0.036789  0.858634  0.104577  0.136373\n","2021-02-05 12:00:00     0.0  0.034255  0.843436  0.122319  0.154889\n","2021-02-05 13:00:00     0.0  0.029848  0.847051  0.092798  0.116370\n","2021-02-05 14:00:00     0.0  0.027440  0.878612  0.093948  0.135504\n","...                     ...       ...       ...       ...       ...\n","2022-02-18 14:00:00     0.0  0.043031  0.840680  0.116299  0.162116\n","2022-02-18 20:00:00     1.0  0.047657  0.797960  0.154389  0.204873\n","2022-02-18 21:00:00     0.0  0.047296  0.836479  0.116251  0.163007\n","2022-02-18 22:00:00     0.0  0.049515  0.830021  0.120461  0.160952\n","2022-02-18 23:00:00     1.0  0.072190  0.820000  0.107809  0.085002\n","\n","[2280 rows x 5 columns]"]},"execution_count":78,"metadata":{},"output_type":"execute_result"}],"source":["data_final_24.groupby(by=data_final_24.index,axis=0).mean()"]},{"cell_type":"code","execution_count":79,"id":"hXxspoX9e_FX","metadata":{"id":"hXxspoX9e_FX"},"outputs":[],"source":["date=[dt.datetime.strptime(x,'%Y-%m-%d %H:%M:%S') for x in data_final_24.index]"]},{"cell_type":"code","execution_count":80,"id":"dHF6a08Se_FX","metadata":{"id":"dHF6a08Se_FX"},"outputs":[],"source":["data_final_24.index=date"]},{"cell_type":"code","execution_count":81,"id":"AUvbM7Ixe_FX","metadata":{"id":"AUvbM7Ixe_FX"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>target</th>\n","      <th>Negativo</th>\n","      <th>Neutro</th>\n","      <th>Positivo</th>\n","      <th>Compound</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.000</td>\n","      <td>0.000</td>\n","      <td>0.0000</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.741</td>\n","      <td>0.259</td>\n","      <td>0.4939</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.000</td>\n","      <td>0.000</td>\n","      <td>0.0000</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.000</td>\n","      <td>0.000</td>\n","      <td>0.0000</td>\n","    </tr>\n","    <tr>\n","      <th>2021-02-05 10:00:00</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000</td>\n","      <td>0.000</td>\n","      <td>0.0000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     target  Negativo  Neutro  Positivo  Compound\n","2021-02-05 10:00:00     0.0       0.0   1.000     0.000    0.0000\n","2021-02-05 10:00:00     0.0       0.0   0.741     0.259    0.4939\n","2021-02-05 10:00:00     0.0       0.0   1.000     0.000    0.0000\n","2021-02-05 10:00:00     0.0       0.0   1.000     0.000    0.0000\n","2021-02-05 10:00:00     0.0       0.0   0.000     0.000    0.0000"]},"execution_count":81,"metadata":{},"output_type":"execute_result"}],"source":["data_final_24.head()"]},{"cell_type":"code","execution_count":82,"id":"ozgp4SEne_FX","metadata":{"id":"ozgp4SEne_FX"},"outputs":[{"data":{"text/plain":["target      0.0000\n","Negativo    0.0000\n","Neutro      0.0000\n","Positivo    0.0000\n","Compound   -0.9918\n","dtype: float64"]},"execution_count":82,"metadata":{},"output_type":"execute_result"}],"source":["data_final_24.min()"]},{"cell_type":"code","execution_count":83,"id":"kZo8lpCDe_FY","metadata":{"id":"kZo8lpCDe_FY"},"outputs":[],"source":["# Train Test Split\n","train,test=train_test_split(data_final_24,stratify=data_final_24['target'],random_state=3);\n","\n","#vectorizer=TfidfVectorizer();\n","X_train_24=train.drop(['target', 'Compound'], axis=1)\n","y_train_24=train['target'];\n","\n","X_test_24=test.drop(['target', 'Compound'], axis=1);\n","y_test_24=test['target'];"]},{"cell_type":"code","execution_count":85,"id":"JAe_0sYme_FY","metadata":{"id":"JAe_0sYme_FY"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.5146956715807224\n"]}],"source":["# Naive Bayes Multinomial\n","nbc=MultinomialNB();\n","\n","nbc.fit(X_train_24,y_train_24);\n","y_pred=nbc.predict(X_test_24);\n","\n","print('Accuracy:',accuracy_score(y_test_24,y_pred))"]},{"cell_type":"code","execution_count":86,"id":"YP72JXTUe_FY","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21169,"status":"ok","timestamp":1649996121640,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"YP72JXTUe_FY","outputId":"c9842213-3978-473d-e8ea-5d29850bc607"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n","[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    8.4s\n","[Parallel(n_jobs=3)]: Done  60 out of  60 | elapsed:   10.9s finished\n"]},{"name":"stdout","output_type":"stream","text":["best score: 0.5096218746252571\n","best params: {'alpha': 1e-05}\n"]}],"source":["X_24=data_final_2.drop(['target', 'Compound'], axis=1);\n","y_24=data_final_2['target'];\n","\n","skf=StratifiedKFold(n_splits=3,random_state=3,shuffle=True);\n","\n","params={'alpha':np.arange(0.00001,1,0.05)};\n","GS_CV=GridSearchCV(MultinomialNB(),params,cv=skf,verbose=1,n_jobs=3);\n","GS_CV.fit(X,y);\n","print('best score:',GS_CV.best_score_)\n","print('best params:',GS_CV.best_params_)"]},{"cell_type":"code","execution_count":87,"id":"4etITLzQe_FY","metadata":{"id":"4etITLzQe_FY"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 13 candidates, totalling 65 fits\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"]},{"name":"stdout","output_type":"stream","text":["[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.514, total=   0.4s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"]},{"name":"stdout","output_type":"stream","text":["[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.515, total=   0.3s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.6s remaining:    0.0s\n"]},{"name":"stdout","output_type":"stream","text":["[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.514, total=   0.3s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.0s remaining:    0.0s\n"]},{"name":"stdout","output_type":"stream","text":["[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.517, total=   0.3s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.514, total=   0.3s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.513, total=   0.5s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.515, total=   0.5s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.514, total=   0.5s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.517, total=   0.5s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.514, total=   0.5s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=6 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=6, score=0.513, total=   0.7s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=6 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=6, score=0.516, total=   0.8s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=6 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=6, score=0.515, total=   0.7s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=6 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=6, score=0.518, total=   0.8s\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=6 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=6, score=0.515, total=   0.7s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1, score=0.514, total=  36.2s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1, score=0.515, total=  37.2s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1, score=0.514, total=  33.2s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1, score=0.517, total=  38.1s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l1, score=0.514, total=  28.3s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2, score=0.514, total=   0.9s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2, score=0.515, total=   1.0s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2, score=0.514, total=   1.0s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2, score=0.517, total=   1.0s\n","[CV] model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2 \n","[CV]  model=LogisticRegression(random_state=127, solver='liblinear'), model__penalty=l2, score=0.514, total=   0.9s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50, score=0.513, total=   5.4s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50, score=0.515, total=   4.6s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50, score=0.514, total=   4.4s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50, score=0.517, total=   4.9s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=50, score=0.514, total=   4.5s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100, score=0.513, total=   8.8s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100, score=0.515, total=   8.4s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100, score=0.514, total=   8.7s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100, score=0.517, total=   8.9s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100, score=0.514, total=   8.6s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50, score=0.514, total=   6.5s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50, score=0.516, total=   6.5s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50, score=0.515, total=   6.7s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50, score=0.518, total=   6.4s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=50, score=0.514, total=   6.4s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100, score=0.514, total=  12.7s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100, score=0.516, total=  12.6s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100, score=0.514, total=  12.5s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100, score=0.518, total=  13.1s\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=4, model__n_estimators=100, score=0.515, total=  12.5s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50 \n"]},{"name":"stderr","output_type":"stream","text":["C:\\ProgramData\\Anaconda3\\envs\\dhdsblend2021\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n","  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"]},{"name":"stdout","output_type":"stream","text":["[14:37:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50, score=0.513, total=   1.9s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50 \n","[14:37:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50, score=0.515, total=   2.5s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50 \n","[14:37:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50, score=0.514, total=   1.9s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50 \n","[14:37:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50, score=0.517, total=   2.0s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50 \n","[14:37:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=50, score=0.514, total=   1.9s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100 \n","[14:37:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100, score=0.514, total=   3.6s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100 \n","[14:37:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100, score=0.515, total=   3.5s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100 \n","[14:37:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100, score=0.514, total=   3.6s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100 \n","[14:37:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100, score=0.517, total=   3.6s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100 \n","[14:37:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=1, model__n_estimators=100, score=0.514, total=   3.5s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50 \n","[14:37:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50, score=0.514, total=   2.9s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50 \n","[14:37:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50, score=0.516, total=   3.0s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50 \n","[14:37:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50, score=0.515, total=   2.9s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50 \n","[14:37:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50, score=0.518, total=   3.0s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50 \n","[14:37:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=50, score=0.514, total=   3.2s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100 \n","[14:38:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100, score=0.515, total=   5.7s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100 \n","[14:38:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100, score=0.517, total=   5.9s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100 \n","[14:38:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100, score=0.516, total=   5.7s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100 \n","[14:38:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100, score=0.518, total=   5.7s\n","[CV] model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100 \n","[14:38:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","[CV]  model=XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), model__max_depth=2, model__n_estimators=100, score=0.516, total=   5.9s\n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Done  65 out of  65 | elapsed:  7.0min finished\n"]},{"name":"stdout","output_type":"stream","text":["[14:38:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","-----------------------------------\n","Mejores hiperparámetros encontrados\n","-----------------------------------\n","{'model': XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n","              colsample_bynode=None, colsample_bytree=None,\n","              enable_categorical=False, gamma=None, gpu_id=None,\n","              importance_type=None, interaction_constraints=None,\n","              learning_rate=None, max_delta_step=None, max_depth=2,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n","              predictor=None, random_state=None, reg_alpha=None,\n","              reg_lambda=None, scale_pos_weight=None, subsample=None,\n","              tree_method=None, validate_parameters=None, verbosity=None), 'model__max_depth': 2, 'model__n_estimators': 100} : 0.5163380469375156 None\n"]}],"source":["# Pipeline + Grid Search\n","pasos = [('scaler', None), ('model', LogisticRegression(random_state = 127,solver='liblinear'))]\n","pipe_grid = Pipeline(pasos)\n","param_grid = [{'model' : [tree.DecisionTreeClassifier(random_state=40)], 'model__max_depth':[2,4,6]},\n","              {'model' : [LogisticRegression(random_state = 127,solver='liblinear')], 'model__penalty':['l1','l2']},\n","              {'model' : [RandomForestClassifier(n_jobs=-1,bootstrap=True,random_state = 127)], 'model__n_estimators':[50,100], 'model__max_depth':[2,4]},\n","              {'model' : [xgb.XGBClassifier(n_jobs=-1)], 'model__n_estimators':[50,100], 'model__max_depth':[1,2]}]\n","cv = KFold(n_splits=5) #random_state=123)\n","gsearch = GridSearchCV(estimator=pipe_grid, cv=cv,\n","                        param_grid=param_grid, verbose=4)\n","gsearch.fit(X_train_24, y_train_24)\n","\n","print(\"-----------------------------------\")\n","print(\"Mejores hiperparámetros encontrados\")\n","print(\"-----------------------------------\")\n","print(gsearch.best_params_, \":\", gsearch.best_score_, gsearch.scoring)\n"]},{"cell_type":"markdown","id":"rHDmODCBnWvl","metadata":{"id":"rHDmODCBnWvl"},"source":["### Pipeline"]},{"cell_type":"code","execution_count":89,"id":"dlsUphBCnbm6","metadata":{"id":"dlsUphBCnbm6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: vaderSentiment in c:\\programdata\\anaconda3\\envs\\dhdsblend2021\\lib\\site-packages (3.3.2)\n","Requirement already satisfied: requests in c:\\programdata\\anaconda3\\envs\\dhdsblend2021\\lib\\site-packages (from vaderSentiment) (2.27.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\dhdsblend2021\\lib\\site-packages (from requests->vaderSentiment) (1.26.6)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\dhdsblend2021\\lib\\site-packages (from requests->vaderSentiment) (2021.10.8)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\dhdsblend2021\\lib\\site-packages (from requests->vaderSentiment) (3.2)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\envs\\dhdsblend2021\\lib\\site-packages (from requests->vaderSentiment) (2.0.4)\n"]}],"source":["!pip install vaderSentiment\n","#from google.colab import drive\n","#drive.mount('/content/gdrive/')\n","#root_path = 'gdrive/MyDrive/Colab Notebooks/'  "]},{"cell_type":"code","execution_count":90,"id":"hQZEe4mtn9Fu","metadata":{"id":"hQZEe4mtn9Fu"},"outputs":[],"source":["from sklearn.base import BaseEstimator, TransformerMixin\n","import re\n","import string\n","from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n","\n","import pandas as pd\n","import datetime as dt\n","import numpy as np\n","\n","from sklearn.metrics import confusion_matrix, recall_score, precision_score, precision_recall_curve,auc,mean_squared_error\n","from sklearn.model_selection import TimeSeriesSplit\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import RepeatedKFold\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.model_selection import GridSearchCV,StratifiedKFold,train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","from sklearn import tree\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.pipeline import Pipeline\n","import xgboost as xgb\n","\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import GridSearchCV\n","\n","class FeatureSelection(BaseEstimator, TransformerMixin):\n","\n","    def __init__(self,selected_features):\n","        self.selected_features=selected_features\n","\n","    def fit(self,X,y=None):\n","        return self\n","\n","    def transform(self, X, y=None):\n","        return X[self.selected_features]\n","\n","\n","class TextMining(BaseEstimator, TransformerMixin):\n","    \n","    def __init__(self,selected_features):\n","        self.selected_features=selected_features\n","        \n","    def fit(self,X,y=None):\n","        return self\n","    \n","    def transform(self, X, y=None):\n","        mencion = re.compile(\"@\\S+\")\n","        links = re.compile(\"https*\\S+\")\n","        hashtags = re.compile(\"#\\S+\")\n","        apostrofes = re.compile(\"\\'\\w+\")\n","        puntuaciones = re.compile('[%s]' % re.escape(string.punctuation))\n","        numeros = re.compile(r'\\w*\\d+\\w*')\n","        espacios = re.compile('\\s{2,}')#(' +')\n","        html = re.compile('<.*?>') \n","        alfanumericos = re.compile(\"[^a-z0-9]\")\n","        aa = re.compile(\"aa\\S+\")\n","        def eliminar(x):\n","            clean_mencion = re.sub(mencion, \" \", x)\n","            clean_links = re.sub(links, \" \", clean_mencion)\n","            clean_hashtags = re.sub(hashtags, \" \", clean_links)\n","            clean_apostrofes = re.sub(apostrofes, '', clean_hashtags)\n","            clean_puntuaciones = re.sub(puntuaciones, '', clean_apostrofes)\n","            clean_numeros = re.sub(numeros, '', clean_puntuaciones)\n","            clean_text = re.sub(html, '', clean_numeros)\n","            clean_alfanumericos = re.sub(alfanumericos,\" \", clean_text)\n","            clean_aa = re.sub(aa,\" \", clean_alfanumericos)\n","            clean_espacios = re.sub(espacios,' ', clean_aa)\n","            return clean_espacios\n","        texto=[x.lower() for x in X[self.selected_features]]\n","        texto=[eliminar(x) for x in texto]\n","        return pd.DataFrame(texto,index=X.index,columns=['text'])\n","\n","class Vader(BaseEstimator, TransformerMixin):\n","    def __init__(self,selected_features):\n","        self.selected_features=selected_features\n","    \n","    def fit(self,X,y=None):\n","        return self\n","\n","    def transform(self, X, y=None):\n","        def senti_score_udf(sentence):\n","            analyser = SentimentIntensityAnalyzer()\n","            snt = analyser.polarity_scores(sentence)\n","            return ([snt['neg'], snt['neu'], snt['pos'], snt['compound']])\n","        texto=[senti_score_udf(x) for x in X[self.selected_features]]\n","        #X[self.text]=texto\n","        df_sentimiento = pd.DataFrame(texto)\n","        df_sentimiento.columns=['Negativo','Neutro','Positivo','Compound']\n","        df_sentimiento.groupby(by=df_sentimiento.index,axis=0).mean()\n","        return df_sentimiento"]},{"cell_type":"code","execution_count":91,"id":"Pihqo9axoFma","metadata":{"id":"Pihqo9axoFma"},"outputs":[],"source":["from math import remainder\n","from sklearn.pipeline import FeatureUnion\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.pipeline import Pipeline\n","\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.compose import ColumnTransformer\n","\n","\n","numeric_cols = ['volume','user_followers']\n","\n","remainder_transformer = Pipeline(\n","                            steps=[('scaler', StandardScaler())]\n","                          )\n","text_features=['text']\n","text_transformer = Pipeline(\n","                            steps=[('TextMining',TextMining(selected_features=text_features[0])),\n","                                  ('Vader',Vader(selected_features=text_features[0])),]\n","                          )\n","\n","preprocessor = ColumnTransformer(\n","                    transformers=[('text',text_transformer,text_features),\n","                                  ('Scaler',StandardScaler(),numeric_cols)],\n","                    remainder='passthrough'\n","                )\n","\n","pasos = [('prep',preprocessor),\n","         ('model',LogisticRegression(random_state = 127,solver='liblinear'))]\n","\n","pipe=Pipeline(pasos)"]},{"cell_type":"code","execution_count":92,"id":"xidIALrporTJ","metadata":{"id":"xidIALrporTJ"},"outputs":[],"source":["param_grid = [{'model' : [tree.DecisionTreeClassifier(random_state=40)], 'model__max_depth':[2,4]},#,\n","              {'model' : [RandomForestClassifier(n_jobs=-1,bootstrap=True,random_state = 127)], 'model__n_estimators':[100,200], 'model__max_depth':[2,4,6]},#,\n","              {'model' : [xgb.XGBClassifier(n_jobs=-1)], 'model__n_estimators':[100,200], 'model__max_depth':[1,2,4,6]}]\n","#cv = RepeatedKFold(n_splits=5) #random_state=123)\n","cv = KFold(n_splits=5) #random_state=123)\n","\n","\n","grid=GridSearchCV(estimator=pipe, param_grid=param_grid, cv=cv,verbose=4)"]},{"cell_type":"code","execution_count":93,"id":"Q4JZFg9opL5v","metadata":{"id":"Q4JZFg9opL5v"},"outputs":[],"source":["data_clean_2 = pd.read_csv(root_path+'Data/data_6h.csv')\n","columnas = ['Indice','Fecha_hora', 'user_followers', 'text', 'volume', 'target']\n","#data_clean_2.columns = columnas\n","\n","X=data_clean_2.sample(n=200000,random_state=123).drop(['Unnamed: 0','target'],axis=1)#'Indice','volume','user_followers'\n","y=data_clean_2.sample(n=200000,random_state=123)['target']\n","X.index=data_clean_2.sample(n=200000,random_state=123)['Unnamed: 0']\n","y.index=data_clean_2.sample(n=200000,random_state=123)['Unnamed: 0']\n","#print(X,y)"]},{"cell_type":"code","execution_count":94,"id":"cWfXpGPkpQ3J","metadata":{"id":"cWfXpGPkpQ3J"},"outputs":[{"data":{"text/html":["<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"cd7bf1c1-ab8f-4a24-96f2-3036e141fd42\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"cd7bf1c1-ab8f-4a24-96f2-3036e141fd42\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('prep',\n","                 ColumnTransformer(remainder='passthrough',\n","                                   transformers=[('text',\n","                                                  Pipeline(steps=[('TextMining',\n","                                                                   TextMining(selected_features='text')),\n","                                                                  ('Vader',\n","                                                                   Vader(selected_features='text'))]),\n","                                                  ['text']),\n","                                                 ('Scaler', StandardScaler(),\n","                                                  ['volume',\n","                                                   'user_followers'])])),\n","                ('model',\n","                 LogisticRegression(random_state=127, solver='liblinear'))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"402be9cd-b460-4312-bff2-212dde5761d7\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"402be9cd-b460-4312-bff2-212dde5761d7\">prep: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder='passthrough',\n","                  transformers=[('text',\n","                                 Pipeline(steps=[('TextMining',\n","                                                  TextMining(selected_features='text')),\n","                                                 ('Vader',\n","                                                  Vader(selected_features='text'))]),\n","                                 ['text']),\n","                                ('Scaler', StandardScaler(),\n","                                 ['volume', 'user_followers'])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a1e3f4f9-fdbd-461f-9e4a-199a7aa61e7f\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"a1e3f4f9-fdbd-461f-9e4a-199a7aa61e7f\">text</label><div class=\"sk-toggleable__content\"><pre>['text']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"0c2b916b-00fb-4da4-bb5a-3886cc703d81\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"0c2b916b-00fb-4da4-bb5a-3886cc703d81\">TextMining</label><div class=\"sk-toggleable__content\"><pre>TextMining(selected_features='text')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"8e7bcef4-7057-4973-8e4b-23e8dd59dfe0\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"8e7bcef4-7057-4973-8e4b-23e8dd59dfe0\">Vader</label><div class=\"sk-toggleable__content\"><pre>Vader(selected_features='text')</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"2f9ac7e3-c998-48cb-a6da-79208b72c246\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"2f9ac7e3-c998-48cb-a6da-79208b72c246\">Scaler</label><div class=\"sk-toggleable__content\"><pre>['volume', 'user_followers']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"177f3a80-0556-4f89-9193-4b5cab2dec24\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"177f3a80-0556-4f89-9193-4b5cab2dec24\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"4743bd48-33e1-448e-84a9-93b6fad74502\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"4743bd48-33e1-448e-84a9-93b6fad74502\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=127, solver='liblinear')</pre></div></div></div></div></div></div></div>"],"text/plain":["Pipeline(steps=[('prep',\n","                 ColumnTransformer(remainder='passthrough',\n","                                   transformers=[('text',\n","                                                  Pipeline(steps=[('TextMining',\n","                                                                   TextMining(selected_features='text')),\n","                                                                  ('Vader',\n","                                                                   Vader(selected_features='text'))]),\n","                                                  ['text']),\n","                                                 ('Scaler', StandardScaler(),\n","                                                  ['volume',\n","                                                   'user_followers'])])),\n","                ('model',\n","                 LogisticRegression(random_state=127, solver='liblinear'))])"]},"execution_count":94,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn import set_config\n","set_config(display=\"diagram\")\n","pipe  # click on the diagram below to see the details of each step"]},{"cell_type":"code","execution_count":95,"id":"bMMZMsSNn3ZZ","metadata":{"id":"bMMZMsSNn3ZZ"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 16 candidates, totalling 80 fits\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"]},{"name":"stdout","output_type":"stream","text":["[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.535, total=29.7min\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 29.7min remaining:    0.0s\n"]},{"name":"stdout","output_type":"stream","text":["[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.527, total=31.0min\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 60.8min remaining:    0.0s\n"]},{"name":"stdout","output_type":"stream","text":["[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.519, total=30.8min\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 91.6min remaining:    0.0s\n"]},{"name":"stdout","output_type":"stream","text":["[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.532, total=32.7min\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=2 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=2, score=0.534, total=29.8min\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.556, total=28.4min\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.553, total=28.6min\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.551, total=28.8min\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.552, total=28.8min\n","[CV] model=DecisionTreeClassifier(random_state=40), model__max_depth=4 \n","[CV]  model=DecisionTreeClassifier(random_state=40), model__max_depth=4, score=0.555, total=28.7min\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100 \n","[CV]  model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100, score=0.534, total=28.9min\n","[CV] model=RandomForestClassifier(n_jobs=-1, random_state=127), model__max_depth=2, model__n_estimators=100 \n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3, random_state=30)\n","\n","grid.fit(X_train,y_train)"]},{"cell_type":"markdown","id":"EaupAj_qngF0","metadata":{"id":"EaupAj_qngF0"},"source":["### Testing"]},{"cell_type":"code","execution_count":null,"id":"USoLNBPppga7","metadata":{"id":"USoLNBPppga7"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from sklearn.metrics import auc\n","\n","prediction = grid.predict(X_test)\n","performance = mean_squared_error(y_test, prediction)\n","print(performance)\n","\n","from sklearn.metrics import confusion_matrix\n","confusion = confusion_matrix(y_test, prediction)\n","print(confusion)\n","\n","from sklearn.metrics import roc_curve\n","fpr_log,tpr_log,thr_log = roc_curve(y_test, prediction)\n","\n","df = pd.DataFrame(dict(fpr=fpr_log, tpr=tpr_log, thr = thr_log))\n","\n","plt.axis([0, 1.01, 0, 1.01])\n","plt.xlabel('1 - Specificty'); plt.ylabel('TPR / Sensitivity'); plt.title('ROC Curve')\n","plt.plot(df['fpr'],df['tpr'])\n","plt.plot(np.arange(0,1, step =0.01), np.arange(0,1, step =0.01))\n","plt.show()\n","\n","print('AUC=', auc(fpr_log, tpr_log))"]},{"cell_type":"code","execution_count":null,"id":"SIAYtgjxpsaW","metadata":{"id":"SIAYtgjxpsaW"},"outputs":[],"source":["# Resultados del grid\n","# ==============================================================================\n","resultados = pd.DataFrame(grid.cv_results_)\n","resultados.filter(regex = '(param.*|mean_t|std_t)')\\\n","    .drop(columns = 'params')\\\n","    .sort_values('mean_test_score', ascending = False)"]},{"cell_type":"code","execution_count":null,"id":"YHBFyx_4pxHO","metadata":{"id":"YHBFyx_4pxHO"},"outputs":[],"source":["# Mejores hiperparámetros\n","# ==============================================================================\n","print(\"-----------------------------------\")\n","print(\"Mejores hiperparámetros encontrados\")\n","print(\"-----------------------------------\")\n","print(grid.best_params_, \":\", grid.best_score_, grid.scoring)"]},{"cell_type":"markdown","id":"gnlpS3hXsS1_","metadata":{"id":"gnlpS3hXsS1_"},"source":["### No usado"]},{"cell_type":"code","execution_count":null,"id":"uhbrxLYL7tno","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":687},"executionInfo":{"elapsed":13817,"status":"error","timestamp":1649994712349,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"uhbrxLYL7tno","outputId":"3e8b0d97-19fb-485f-f104-24f734296005"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-241-d175902529df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mscatter_kws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"alpha\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mline_kws\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"color\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"alpha\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0max\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     21\u001b[0m     \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"precio vs {column}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bold\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             )\n\u001b[1;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/seaborn/regression.py\u001b[0m in \u001b[0;36mregplot\u001b[0;34m(x, y, data, x_estimator, x_bins, x_ci, scatter, fit_reg, ci, n_boot, units, seed, order, logistic, lowess, robust, logx, x_partial, y_partial, truncate, dropna, x_jitter, y_jitter, label, color, marker, scatter_kws, line_kws, ax)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0mscatter_kws\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"marker\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[0mline_kws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mline_kws\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_kws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m     \u001b[0mplotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscatter_kws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_kws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/seaborn/regression.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, ax, scatter_kws, line_kws)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_reg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_kws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;31m# Label the axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/seaborn/regression.py\u001b[0m in \u001b[0;36mlineplot\u001b[0;34m(self, ax, kws)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;34m\"\"\"Draw the model.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;31m# Fit the regression model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_bands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m         \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/seaborn/regression.py\u001b[0m in \u001b[0;36mfit_regression\u001b[0;34m(self, ax, x_range, grid)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat_boots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_logx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat_boots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;31m# Compute the confidence interval at each grid point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/seaborn/regression.py\u001b[0m in \u001b[0;36mfit_fast\u001b[0;34m(self, grid)\u001b[0m\n\u001b[1;32m    244\u001b[0m                                     \u001b[0mn_boot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_boot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                                     \u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                                     seed=self.seed).T\n\u001b[0m\u001b[1;32m    247\u001b[0m         \u001b[0myhat_boots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta_boots\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat_boots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/seaborn/algorithms.py\u001b[0m in \u001b[0;36mbootstrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_boot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mresampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintegers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# intp is indexing dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mboot_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboot_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/seaborn/algorithms.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_boot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mresampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintegers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# intp is indexing dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mboot_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboot_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]},{"data":{"image/png":"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","text/plain":["<Figure size 648x360 with 9 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# Gráfico de distribución para cada variable numérica\n","# ==============================================================================\n","# Ajustar número de subplots en función del número de columnas\n","from matplotlib import ticker\n","\n","fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(9, 5))\n","axes = axes.flat\n","columnas_numeric = data_final_12.select_dtypes(include=['float64', 'int']).columns\n","columnas_numeric = columnas_numeric.drop('target')\n","\n","for i, column in enumerate(columnas_numeric):\n","    sns.regplot(\n","        x           = data_final_12[column],\n","        y           = data_final_12['target'],\n","        color       = \"gray\",\n","        marker      = '.',\n","        scatter_kws = {\"alpha\":0.4},\n","        line_kws    = {\"color\":\"r\",\"alpha\":0.7},\n","        ax          = axes[i]\n","    )\n","    axes[i].set_title(f\"precio vs {column}\", fontsize = 7, fontweight = \"bold\")\n","    #axes[i].ticklabel_format(style='sci', scilimits=(-4,4), axis='both')\n","    axes[i].yaxis.set_major_formatter(ticker.EngFormatter())\n","    axes[i].xaxis.set_major_formatter(ticker.EngFormatter())\n","    axes[i].tick_params(labelsize = 6)\n","    axes[i].set_xlabel(\"\")\n","    axes[i].set_ylabel(\"\")\n","\n","# Se eliminan los axes vacíos\n","for i in [8]:\n","    fig.delaxes(axes[i])\n","    \n","fig.tight_layout()\n","plt.subplots_adjust(top=0.9)\n","fig.suptitle('Correlación con precio', fontsize = 10, fontweight = \"bold\");"]},{"cell_type":"code","execution_count":null,"id":"49d14e9f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":419,"status":"ok","timestamp":1649992364521,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"49d14e9f","outputId":"ab73213e-2ded-42b0-a4e1-b7154f3df6c1"},"outputs":[{"data":{"text/plain":["['Fecha_hora', 'user_followers', 'text', 'volume', 'target']"]},"execution_count":199,"metadata":{},"output_type":"execute_result"}],"source":["columnas = ['Fecha_hora', 'user_followers', 'text', 'volume', 'target']\n","columnas"]},{"cell_type":"code","execution_count":null,"id":"4f0f4cf3","metadata":{"id":"4f0f4cf3"},"outputs":[],"source":["#data.to_csv(root_path+'Data/data_clean.csv')"]},{"cell_type":"code","execution_count":null,"id":"e2f80f1e","metadata":{"id":"e2f80f1e"},"outputs":[],"source":["englishStemmer=SnowballStemmer(\"english\")\n","\n","stopwords_en = stopwords.words('english');\n","\n","# si no hacemos esto y usamos directo stopwords_sp, CountVectorizer devuelve un warning\n","stopwords_en_stem = [englishStemmer.stem(x) for x in stopwords_en]\n","\n","vectorizer = CountVectorizer(stop_words = stopwords_en_stem, lowercase = True, strip_accents = 'unicode');"]},{"cell_type":"code","execution_count":null,"id":"e3d4ce9f","metadata":{"id":"e3d4ce9f"},"outputs":[],"source":["#clean_words = [x for x in stemmer if x not in stopwords]"]},{"cell_type":"code","execution_count":null,"id":"4a20d57e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":94943,"status":"ok","timestamp":1649992461736,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"4a20d57e","outputId":"de70d01a-a798-453c-dc89-b58f38076040"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["0 of 1290445\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["50000 of 1290445\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["100000 of 1290445\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["150000 of 1290445\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["200000 of 1290445\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["250000 of 1290445\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["300000 of 1290445\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["350000 of 1290445\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["400000 of 1290445\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["450000 of 1290445\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["500000 of 1290445\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["550000 of 1290445\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["600000 of 1290445\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["650000 of 1290445\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["700000 of 1290445\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["750000 of 1290445\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["800000 of 1290445\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["850000 of 1290445\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["900000 of 1290445\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["950000 of 1290445\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["1000000 of 1290445\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["1050000 of 1290445\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["1100000 of 1290445\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["1150000 of 1290445\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["1200000 of 1290445\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"name":"stdout","output_type":"stream","text":["1250000 of 1290445\n"]}],"source":["palabras = []\n","for i in range(0,largo,50000):\n","    data = pd.read_csv(root_path+'Data/data_12h_prep.csv', header = 0, skiprows=i, nrows=20000)\n","    data.columns = columnas\n","    #tokenizacion = [word_tokenize(x) for x in data.text]\n","    stemmer = [englishStemmer.stem(x) for x in data.text]\n","    vectorizer.fit(stemmer);\n","    countvectorizer_encoding = vectorizer.transform(stemmer);\n","    data_text = pd.DataFrame(countvectorizer_encoding.todense(), \n","             columns = vectorizer.get_feature_names())\n","    cantidad_apariciones = data_text.sum()\n","    mask = cantidad_apariciones < 3\n","    palabras.extend(cantidad_apariciones[mask].index)\n","    del data, countvectorizer_encoding, data_text, cantidad_apariciones, mask\n","    print(f'{i} of {largo}')"]},{"cell_type":"code","execution_count":null,"id":"581068ac","metadata":{"id":"581068ac"},"outputs":[],"source":["palabras_a_sacar = ['btc', 'bitcoin', 'crypto', 'price', 'amp', 'get', 'market', 'time', 'one', 'see', 'us', 'eth', 'project', 'new', 'usd']\n","stopwords_en.extend(palabras_a_sacar)"]},{"cell_type":"code","execution_count":null,"id":"53bca7e0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":496,"status":"ok","timestamp":1649992474686,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"53bca7e0","outputId":"90113610-a60f-4274-9983-86bce48de114"},"outputs":[{"data":{"text/plain":["['i',\n"," 'me',\n"," 'my',\n"," 'myself',\n"," 'we',\n"," 'our',\n"," 'ours',\n"," 'ourselves',\n"," 'you',\n"," \"you're\",\n"," \"you've\",\n"," \"you'll\",\n"," \"you'd\",\n"," 'your',\n"," 'yours',\n"," 'yourself',\n"," 'yourselves',\n"," 'he',\n"," 'him',\n"," 'his',\n"," 'himself',\n"," 'she',\n"," \"she's\",\n"," 'her',\n"," 'hers',\n"," 'herself',\n"," 'it',\n"," \"it's\",\n"," 'its',\n"," 'itself',\n"," 'they',\n"," 'them',\n"," 'their',\n"," 'theirs',\n"," 'themselves',\n"," 'what',\n"," 'which',\n"," 'who',\n"," 'whom',\n"," 'this',\n"," 'that',\n"," \"that'll\",\n"," 'these',\n"," 'those',\n"," 'am',\n"," 'is',\n"," 'are',\n"," 'was',\n"," 'were',\n"," 'be',\n"," 'been',\n"," 'being',\n"," 'have',\n"," 'has',\n"," 'had',\n"," 'having',\n"," 'do',\n"," 'does',\n"," 'did',\n"," 'doing',\n"," 'a',\n"," 'an',\n"," 'the',\n"," 'and',\n"," 'but',\n"," 'if',\n"," 'or',\n"," 'because',\n"," 'as',\n"," 'until',\n"," 'while',\n"," 'of',\n"," 'at',\n"," 'by',\n"," 'for',\n"," 'with',\n"," 'about',\n"," 'against',\n"," 'between',\n"," 'into',\n"," 'through',\n"," 'during',\n"," 'before',\n"," 'after',\n"," 'above',\n"," 'below',\n"," 'to',\n"," 'from',\n"," 'up',\n"," 'down',\n"," 'in',\n"," 'out',\n"," 'on',\n"," 'off',\n"," 'over',\n"," 'under',\n"," 'again',\n"," 'further',\n"," 'then',\n"," 'once',\n"," 'here',\n"," 'there',\n"," 'when',\n"," 'where',\n"," 'why',\n"," 'how',\n"," 'all',\n"," 'any',\n"," 'both',\n"," 'each',\n"," 'few',\n"," 'more',\n"," 'most',\n"," 'other',\n"," 'some',\n"," 'such',\n"," 'no',\n"," 'nor',\n"," 'not',\n"," 'only',\n"," 'own',\n"," 'same',\n"," 'so',\n"," 'than',\n"," 'too',\n"," 'very',\n"," 's',\n"," 't',\n"," 'can',\n"," 'will',\n"," 'just',\n"," 'don',\n"," \"don't\",\n"," 'should',\n"," \"should've\",\n"," 'now',\n"," 'd',\n"," 'll',\n"," 'm',\n"," 'o',\n"," 're',\n"," 've',\n"," 'y',\n"," 'ain',\n"," 'aren',\n"," \"aren't\",\n"," 'couldn',\n"," \"couldn't\",\n"," 'didn',\n"," \"didn't\",\n"," 'doesn',\n"," \"doesn't\",\n"," 'hadn',\n"," \"hadn't\",\n"," 'hasn',\n"," \"hasn't\",\n"," 'haven',\n"," \"haven't\",\n"," 'isn',\n"," \"isn't\",\n"," 'ma',\n"," 'mightn',\n"," \"mightn't\",\n"," 'mustn',\n"," \"mustn't\",\n"," 'needn',\n"," \"needn't\",\n"," 'shan',\n"," \"shan't\",\n"," 'shouldn',\n"," \"shouldn't\",\n"," 'wasn',\n"," \"wasn't\",\n"," 'weren',\n"," \"weren't\",\n"," 'won',\n"," \"won't\",\n"," 'wouldn',\n"," \"wouldn't\",\n"," 'abandon',\n"," 'abandoned',\n"," 'abandons',\n"," 'abcde',\n"," 'abi',\n"," 'ability',\n"," 'abit',\n"," 'aboard',\n"," 'abroad',\n"," 'abrubt',\n"," 'absence',\n"," 'absent',\n"," 'absorb',\n"," 'absoulute',\n"," 'abstracts',\n"," 'abt',\n"," 'abund',\n"," 'abz',\n"," 'acb',\n"," 'acc',\n"," 'accelerated',\n"," 'accelerates',\n"," 'acceleratin',\n"," 'accelerating',\n"," 'acceleration',\n"," 'accep',\n"," 'acceptable',\n"," 'accepteert',\n"," 'accepti',\n"," 'acceptiing',\n"," 'acceptin',\n"," 'accessing',\n"," 'accessories',\n"," 'acco',\n"," 'accomplish',\n"," 'accomplishment',\n"," 'accor',\n"," 'accordin',\n"," 'accordingly',\n"," 'accout',\n"," 'accross',\n"," 'accumulat',\n"," 'accuracy',\n"," 'accurately',\n"," 'ace',\n"," 'achievable',\n"," 'achievement',\n"," 'achieves',\n"," 'achieving',\n"," 'achilles',\n"," 'acid',\n"," 'acknowledge',\n"," 'acknowledged',\n"," 'acqui',\n"," 'acquihires',\n"," 'acquisitio',\n"," 'acquisition',\n"," 'acquistato',\n"," 'acres',\n"," 'acros',\n"," 'acst',\n"," 'acting',\n"," 'actions',\n"," 'actionsupporting',\n"," 'activating',\n"," 'activist',\n"," 'actress',\n"," 'acumulation',\n"," 'adabtc',\n"," 'adadown',\n"," 'adadownusdt',\n"," 'adaeth',\n"," 'adam',\n"," 'adapting',\n"," 'adaption',\n"," 'adax',\n"," 'addressable',\n"," 'adigitalcurrency',\n"," 'adlytick',\n"," 'administer',\n"," 'administration',\n"," 'admins',\n"," 'admiration',\n"," 'admire',\n"," 'admission',\n"," 'admit',\n"," 'admits',\n"," 'admitted',\n"," 'adolescence',\n"," 'adopted',\n"," 'adopters',\n"," 'adress',\n"," 'adult',\n"," 'adva',\n"," 'advanta',\n"," 'advisable',\n"," 'advised',\n"," 'advises',\n"," 'advisory',\n"," 'advocate',\n"," 'adx',\n"," 'adxbtc',\n"," 'ae',\n"," 'aerosol',\n"," 'aezs',\n"," 'aff',\n"," 'affected',\n"," 'affecting',\n"," 'affects',\n"," 'affirm',\n"," 'affo',\n"," 'affordable',\n"," 'afraid',\n"," 'aft',\n"," 'afte',\n"," 'afterhours',\n"," 'afternoon',\n"," 'afterwards',\n"," 'afuera',\n"," 'ag',\n"," 'agai',\n"," 'agains',\n"," 'againunprecedented',\n"," 'agan',\n"," 'ageing',\n"," 'agenda',\n"," 'agent',\n"," 'ages',\n"," 'aggregately',\n"," 'aggregator',\n"," 'aggressive',\n"," 'aggressively',\n"," 'aging',\n"," 'aginst',\n"," 'agothanks',\n"," 'agr',\n"," 'agreeing',\n"," 'agrees',\n"," 'agso',\n"," 'aha',\n"," 'ahha',\n"," 'ahhh',\n"," 'ahmed',\n"," 'ahpm',\n"," 'aht',\n"," 'aid',\n"," 'aiding',\n"," 'aimed',\n"," 'aint',\n"," 'airdropped',\n"," 'airdropping',\n"," 'aired',\n"," 'airing',\n"," 'airlines',\n"," 'aisshwarya',\n"," 'akt',\n"," 'alameda',\n"," 'alarm',\n"," 'alarmi',\n"," 'alerted',\n"," 'alesso',\n"," 'alex',\n"," 'algobtc',\n"," 'algorithms',\n"," 'algos',\n"," 'algotrading',\n"," 'alia',\n"," 'alien',\n"," 'aligned',\n"," 'alittle',\n"," 'allah',\n"," 'allegations',\n"," 'alleviate',\n"," 'alliance',\n"," 'allie',\n"," 'allin',\n"," 'allinclusive',\n"," 'allnew',\n"," 'allocated',\n"," 'allocations',\n"," 'allone',\n"," 'allowin',\n"," 'alloys',\n"," 'allt',\n"," 'alltimehighs',\n"," 'alltimethesame',\n"," 'allways',\n"," 'almighty',\n"," 'almos',\n"," 'alottamoney',\n"," 'aloud',\n"," 'alphabit',\n"," 'alphausdt',\n"," 'alr',\n"," 'alrea',\n"," 'altbtc',\n"," 'altc',\n"," 'alte',\n"," 'alterna',\n"," 'alternativ',\n"," 'alternatively',\n"," 'altogether',\n"," 'altrank',\n"," 'altruistic',\n"," 'aluminum',\n"," 'alvarium',\n"," 'alw',\n"," 'alysystem',\n"," 'amanda',\n"," 'amas',\n"," 'amass',\n"," 'amaz',\n"," 'amazoncoin',\n"," 'ambcrypto',\n"," 'ambiguity',\n"," 'ambitions',\n"," 'ambitious',\n"," 'amd',\n"," 'amer',\n"," 'amidst',\n"," 'amigo',\n"," 'amirite',\n"," 'amm',\n"," 'ammous',\n"," 'amoeba',\n"," 'amoun',\n"," 'ampamp',\n"," 'ampere',\n"," 'amusement',\n"," 'ana',\n"," 'analog',\n"," 'analys',\n"," 'analysi',\n"," 'analysys',\n"," 'analytic',\n"," 'analyzed',\n"," 'analyzing',\n"," 'anarchocapitalism',\n"," 'anarchy',\n"," 'anchor',\n"," 'anchored',\n"," 'ancient',\n"," 'andor',\n"," 'andro',\n"," 'androm',\n"," 'andwell',\n"," 'andy',\n"," 'ang',\n"," 'angel',\n"," 'angeles',\n"," 'angle',\n"," 'angpao',\n"," 'angry',\n"," 'animated',\n"," 'animation',\n"," 'anime',\n"," 'anita',\n"," 'ankrbtc',\n"," 'ankrusdt',\n"," 'annihilate',\n"," 'anniversary',\n"," 'annnd',\n"," 'annnnd',\n"," 'annnnnd',\n"," 'announ',\n"," 'announcements',\n"," 'annoying',\n"," 'annoyingly',\n"," 'annually',\n"," 'ano',\n"," 'anointed',\n"," 'anon',\n"," 'anonpowered',\n"," 'anot',\n"," 'anothe',\n"," 'anotherone',\n"," 'ans',\n"," 'answered',\n"," 'answers',\n"," 'ant',\n"," 'ante',\n"," 'anthonia',\n"," 'antibitcoin',\n"," 'antibitcoiners',\n"," 'anticipati',\n"," 'anticrypto',\n"," 'antigold',\n"," 'antimonopoly',\n"," 'antminer',\n"," 'antusdt',\n"," 'anxiety',\n"," 'anyo',\n"," 'anyon',\n"," 'anyones',\n"," 'anystake',\n"," 'anyth',\n"," 'anytim',\n"," 'anyways',\n"," 'anywher',\n"," 'ap',\n"," 'apartment',\n"," 'aped',\n"," 'apes',\n"," 'apha',\n"," 'apifiny',\n"," 'apl',\n"," 'apologizes',\n"," 'apparent',\n"," 'appc',\n"," 'appcbtc',\n"," 'appear',\n"," 'appearing',\n"," 'apper',\n"," 'appl',\n"," 'applaud',\n"," 'apples',\n"," 'applicable',\n"," 'applies',\n"," 'apply',\n"," 'appr',\n"," 'apprecia',\n"," 'appreciat',\n"," 'appreciatio',\n"," 'appreciation',\n"," 'approached',\n"," 'appropriate',\n"," 'approve',\n"," 'approves',\n"," 'approxima',\n"," 'apr',\n"," 'aprender',\n"," 'apt',\n"," 'aqms',\n"," 'aquire',\n"," 'araligi',\n"," 'arbez',\n"," 'architect',\n"," 'architecture',\n"," 'areaa',\n"," 'arent',\n"," 'argenti',\n"," 'argentina',\n"," 'arguably',\n"," 'arguments',\n"," 'arhwoooooooooo',\n"," 'arifinnkri',\n"," 'aristabank',\n"," 'aristotle',\n"," 'arizona',\n"," 'armani',\n"," 'armorfi',\n"," 'arms',\n"," 'aro',\n"," 'aromatherapy',\n"," 'arou',\n"," 'aroun',\n"," 'arpa',\n"," 'arpausdt',\n"," 'arrano',\n"," 'arrested',\n"," 'arrests',\n"," 'arrivals',\n"," 'arrive',\n"," 'arrogantly',\n"," 'arrowed',\n"," 'arrows',\n"," 'arte',\n"," 'arth',\n"," 'artifical',\n"," 'artificial',\n"," 'artificially',\n"," 'artisans',\n"," 'artist',\n"," 'artworks',\n"," 'ascendi',\n"," 'ascendin',\n"," 'ascent',\n"," 'ascentrainvest',\n"," 'asf',\n"," 'ashi',\n"," 'asian',\n"," 'asicresistant',\n"," 'asko',\n"," 'asks',\n"," 'aso',\n"," 'aspects',\n"," 'asse',\n"," 'asserts',\n"," 'assett',\n"," 'assigne',\n"," 'assigned',\n"," 'assignment',\n"," 'assistant',\n"," 'assisting',\n"," 'associate',\n"," 'association',\n"," 'asss',\n"," 'assss',\n"," 'assuming',\n"," 'assumption',\n"," 'assure',\n"," 'ast',\n"," 'astbtc',\n"," 'astonishing',\n"," 'astrological',\n"," 'astronaut',\n"," 'astronom',\n"," 'asus',\n"," 'ate',\n"," 'athome',\n"," 'atlcoins',\n"," 'atleas',\n"," 'atleats',\n"," 'atmusdt',\n"," 'atombtc',\n"," 'atop',\n"," 'atr',\n"," 'atrocious',\n"," 'attac',\n"," 'attacker',\n"," 'attacks',\n"," 'attain',\n"," 'attax',\n"," 'attempted',\n"," 'atten',\n"," 'attend',\n"," 'attendees',\n"," 'attending',\n"," 'attitude',\n"," 'attorney',\n"," 'attract',\n"," 'attracts',\n"," 'atusd',\n"," 'au',\n"," 'auct',\n"," 'auctioning',\n"," 'aud',\n"," 'audi',\n"," 'audible',\n"," 'audiences',\n"," 'audiobtc',\n"," 'audiousdt',\n"," 'audit',\n"," 'audited',\n"," 'aug',\n"," 'aus',\n"," 'aussie',\n"," 'australian',\n"," 'austrian',\n"," 'authoritative',\n"," 'authoritatively',\n"," 'authorities',\n"," 'authority',\n"," 'autist',\n"," 'auto',\n"," 'automaker',\n"," 'automakers',\n"," 'automatically',\n"," 'automine',\n"," 'automobil',\n"," 'autonomicaly',\n"," 'autopilot',\n"," 'av',\n"," 'avai',\n"," 'availab',\n"," 'availability',\n"," 'availabl',\n"," 'avatarlogo',\n"," 'avaxusdt',\n"," 'aventador',\n"," 'averages',\n"," 'averaging',\n"," 'avert',\n"," 'avl',\n"," 'avoi',\n"," 'avoiding',\n"," 'avs',\n"," 'aw',\n"," 'awa',\n"," 'await',\n"," 'awar',\n"," 'award',\n"," 'awarded',\n"," 'awards',\n"," 'aware',\n"," 'awful',\n"," 'awfully',\n"," 'awhile',\n"," 'awkward',\n"," 'awoken',\n"," 'awon',\n"," 'aws',\n"," 'aww',\n"," 'axie',\n"," 'axium',\n"," 'axsusdt',\n"," 'axtrader',\n"," 'ayi',\n"," 'aztec',\n"," 'aztek',\n"," 'babbby',\n"," 'babe',\n"," 'babooooo',\n"," 'babyyy',\n"," 'bac',\n"," 'background',\n"," 'backhe',\n"," 'backing',\n"," 'backseat',\n"," 'backstopped',\n"," 'backtest',\n"," 'backtesting',\n"," 'backtowork',\n"," 'backups',\n"," 'backw',\n"," 'backward',\n"," 'backwards',\n"," 'bada',\n"," 'badgerdao',\n"," 'badgering',\n"," 'baggin',\n"," 'bahahahahhahahaa',\n"," 'bailout',\n"," 'bailouts',\n"," 'bain',\n"," 'bait',\n"," 'bake',\n"," 'bakers',\n"," 'balanced',\n"," 'balchunas',\n"," 'balcon',\n"," 'baller',\n"," 'ballistic',\n"," 'balloon',\n"," 'bam',\n"," 'banco',\n"," 'bandbtc',\n"," 'bands',\n"," 'bandwagon',\n"," 'bane',\n"," 'bangers',\n"," 'banked',\n"," 'bankless',\n"," 'bankroller',\n"," 'bankrupted',\n"," 'banktobank',\n"," 'bann',\n"," 'barga',\n"," 'baring',\n"," 'barking',\n"," 'barriers',\n"," 'barrow',\n"," 'bart',\n"," 'basket',\n"," 'bastards',\n"," 'bastion',\n"," 'bath',\n"," 'bathtub',\n"," 'batman',\n"," 'batteries',\n"," 'battery',\n"," 'battles',\n"," 'battling',\n"," 'bawoo',\n"," 'bayi',\n"," 'bbc',\n"," 'bbkcf',\n"," 'bbt',\n"," 'bcc',\n"," 'bcha',\n"," 'bchusdt',\n"," 'bcn',\n"," 'beacon',\n"," 'beads',\n"," 'beako',\n"," 'beanies',\n"," 'bearer',\n"," 'beastmode',\n"," 'beating',\n"," 'beauties',\n"," 'beautifulmorning',\n"," 'beautifuly',\n"," 'beavis',\n"," 'becareful',\n"," 'becom',\n"," 'beeeeer',\n"," 'beer',\n"," 'beers',\n"," 'befo',\n"," 'beforeamp',\n"," 'beg',\n"," 'beginn',\n"," 'beginner',\n"," 'begun',\n"," 'behalf',\n"," 'behaving',\n"," 'behavior',\n"," 'behaviour',\n"," 'behavioural',\n"," 'bei',\n"," 'beijing',\n"," 'bein',\n"," 'bekend',\n"," 'beli',\n"," 'belief',\n"," 'believed',\n"," 'believer',\n"," 'believing',\n"," 'bellow',\n"," 'belo',\n"," 'beloved',\n"," 'benchmarks',\n"," 'bending',\n"," 'beneficial',\n"," 'benefited',\n"," 'benefiting',\n"," 'benjamin',\n"," 'benny',\n"," 'bentley',\n"," 'benzinga',\n"," 'beras',\n"," 'berhad',\n"," 'besieged',\n"," 'bestcheapest',\n"," 'bestever',\n"," 'betalingen',\n"," 'betray',\n"," 'bett',\n"," 'betterlooking',\n"," 'bettinggambling',\n"," 'beyondit',\n"," 'bezos',\n"," 'bfch',\n"," 'bfg',\n"," 'bhatia',\n"," 'biasdoubts',\n"," 'bidytron',\n"," 'bigbang',\n"," 'bigboi',\n"," 'bigbreast',\n"," 'bilion',\n"," 'biller',\n"," 'billing',\n"," 'billionares',\n"," 'billiondollar',\n"," 'billon',\n"," 'bills',\n"," 'bina',\n"," 'binace',\n"," 'binan',\n"," 'binancebacked',\n"," 'binancebtcusdtperp',\n"," 'binancelisted',\n"," 'bingo',\n"," 'bioivt',\n"," 'biotch',\n"," 'biothen',\n"," 'birdy',\n"," 'birth',\n"," 'bitball',\n"," 'bitblockboom',\n"," 'bitches',\n"," 'bitcion',\n"," 'bitcoi',\n"," 'bitcoincash',\n"," 'bitcoincrypto',\n"," 'bitcoinergy',\n"," 'bitcoing',\n"," 'bitcoinhow',\n"," 'bitcoining',\n"," 'bitcoinladen',\n"," 'bitcoinmarket',\n"," 'bitcoinnative',\n"," 'bitcoinpowered',\n"," 'bitcoinsymbol',\n"," 'bitcointalk',\n"," 'bitcoiny',\n"," 'bitcone',\n"," 'bitcorn',\n"," 'bitdarn',\n"," 'bite',\n"," 'bitfarms',\n"," 'bitfields',\n"," 'bitfinexbtcusd',\n"," 'bitfink',\n"," 'biting',\n"," 'bitkv',\n"," 'bitmain',\n"," 'bitmart',\n"," 'bits',\n"," 'bitshield',\n"," 'bitstil',\n"," 'bitte',\n"," 'bittorrent',\n"," 'bittrexpartbtc',\n"," 'bitvolt',\n"," 'bityard',\n"," 'bizarre',\n"," 'bk',\n"," 'bla',\n"," 'blac',\n"," 'blackcab',\n"," 'blackhole',\n"," 'blackrock',\n"," 'blatant',\n"," 'blaze',\n"," 'bleach',\n"," 'bleeds',\n"," 'blessed',\n"," 'blessing',\n"," 'blindly',\n"," 'blindspot',\n"," 'bling',\n"," 'blink',\n"," 'blinkerd',\n"," 'blo',\n"," 'blockcasino',\n"," 'blockchainbased',\n"," 'blockchainera',\n"," 'blockchainfriendly',\n"," 'blocked',\n"," 'blockone',\n"," 'blockparty',\n"," 'blockstack',\n"," 'blogger',\n"," 'blond',\n"," 'bloodbath',\n"," 'bloody',\n"," 'blower',\n"," 'blown',\n"," 'bluechip',\n"," 'blues',\n"," 'bluesky',\n"," 'blunder',\n"," 'bmock',\n"," 'bnbdown',\n"," 'bnbdownusdt',\n"," 'bnbusdt',\n"," 'bntbtc',\n"," 'bntusdt',\n"," 'boarding',\n"," 'boardroom',\n"," 'boards',\n"," 'boats',\n"," 'bofa',\n"," 'boi',\n"," 'boko',\n"," 'bollas',\n"," 'bollinger',\n"," 'bollocks',\n"," 'bolt',\n"," 'bomb',\n"," 'bomboclat',\n"," 'bombs',\n"," 'bondly',\n"," 'bonkas',\n"," 'bonkers',\n"," 'bonu',\n"," 'boo',\n"," 'booked',\n"," 'bookie',\n"," 'booking',\n"," 'bookings',\n"," 'booongo',\n"," 'boooom',\n"," 'booooooooo',\n"," 'booster',\n"," 'boosters',\n"," 'boots',\n"," 'borderless',\n"," 'boring',\n"," 'borro',\n"," 'borrow',\n"," 'borrowing',\n"," 'botb',\n"," 'botox',\n"," 'bottle',\n"," 'botto',\n"," 'bottomline',\n"," 'boug',\n"," 'bough',\n"," 'bougjt',\n"," 'bounceback',\n"," 'bouncer',\n"," 'bounces',\n"," 'bouncing',\n"," 'bound',\n"," 'boundaries',\n"," 'boundary',\n"," 'bounds',\n"," 'bountybvb',\n"," 'bourtange',\n"," 'bout',\n"," 'bow',\n"," 'boxed',\n"," 'boxer',\n"," 'boyzzz',\n"," 'bp',\n"," 'bpp',\n"," 'bqx',\n"," 'bqxbtc',\n"," 'brace',\n"," 'braces',\n"," 'bracey',\n"," 'brad',\n"," 'brady',\n"," 'brag',\n"," 'brainer',\n"," 'braininv',\n"," 'brains',\n"," 'brainwashed',\n"," 'brakes',\n"," 'braking',\n"," 'branching',\n"," 'brande',\n"," 'brav',\n"," 'brave',\n"," 'bravo',\n"," 'brazing',\n"," 'brc',\n"," 'brd',\n"," ...]"]},"execution_count":202,"metadata":{},"output_type":"execute_result"}],"source":["stopwords_en.extend(palabras)\n","stopwords_en\n","\n","stopwords_en.extend(palabras_a_sacar)\n","stopwords_en\n","\n","with open(root_path+'Data/stopwords_custom.txt', 'w') as f:\n","  for word in stopwords_en: \n","    f.write(word+'\\n')"]},{"cell_type":"code","execution_count":null,"id":"6ec75e24","metadata":{"id":"6ec75e24"},"outputs":[],"source":["# 5 - Pipeline  Desicion Tree (PRUEBA)\n","pasos = [('scaler', StandardScaler()), ('dt', tree.DecisionTreeClassifier(random_state=40))]\n","pipe_grid = Pipeline(pasos)\n","param_grid = {'dt__max_depth':[4,8,12]}\n","tscv = TimeSeriesSplit(n_splits=5)\n","gsearch = GridSearchCV(estimator=pipe_grid, cv=tscv,\n","                        param_grid=param_grid)\n","gsearch.fit(X_train, y_train)\n"]},{"cell_type":"code","execution_count":null,"id":"FmaG709Mhkec","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":262,"status":"ok","timestamp":1649544737413,"user":{"displayName":"Agustín Barrandeguy","userId":"14557342631068393890"},"user_tz":180},"id":"FmaG709Mhkec","outputId":"76d9e7ee-cbbb-4ad8-e023-12f9c9c85de8"},"outputs":[{"data":{"text/plain":["5"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["2+1+2"]},{"cell_type":"code","execution_count":null,"id":"fc4f069d","metadata":{"id":"fc4f069d"},"outputs":[],"source":["prediction = gsearch.predict(X_test)\n","\n","performance = mean_squared_error(y_test, prediction)\n","\n","performance\n"]},{"cell_type":"code","execution_count":null,"id":"ba86738d","metadata":{"id":"ba86738d"},"outputs":[],"source":["cv = KFold(n_splits=5, random_state=123)\n","cv_scores = cross_val_score(\n","                estimator = pipe,\n","                X         = X_train,\n","                y         = y_train,\n","                scoring   = 'neg_root_mean_squared_error',\n","                cv        = cv\n","             )\n"]},{"cell_type":"code","execution_count":null,"id":"b00b334c","metadata":{"id":"b00b334c"},"outputs":[],"source":["#stemmer = [englishStemmer.stem(x) for x in data_clean_2.text]"]},{"cell_type":"code","execution_count":null,"id":"04627c1f","metadata":{"id":"04627c1f"},"outputs":[],"source":["#clean_words = [x for x in stemmer if x not in stopwords_en]"]},{"cell_type":"code","execution_count":null,"id":"d504cc17","metadata":{"id":"d504cc17"},"outputs":[],"source":["stopwords_en"]},{"cell_type":"code","execution_count":null,"id":"ebeb06a4","metadata":{"id":"ebeb06a4"},"outputs":[],"source":["data_clean_2.text = clean_words\n","data_clean_2"]},{"cell_type":"code","execution_count":null,"id":"34d63963","metadata":{"id":"34d63963"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"89969382","metadata":{"id":"89969382"},"outputs":[],"source":["##########################################################"]},{"cell_type":"code","execution_count":null,"id":"1abe5399","metadata":{"id":"1abe5399"},"outputs":[],"source":["tokenizacion = [word_tokenize(x) for x in data.text]\n","tokenizacion"]},{"cell_type":"code","execution_count":null,"id":"86fddc33","metadata":{"id":"86fddc33"},"outputs":[],"source":["englishStemmer=SnowballStemmer(\"english\")"]},{"cell_type":"code","execution_count":null,"id":"12ae3f1f","metadata":{"id":"12ae3f1f"},"outputs":[],"source":["stopwords_en = stopwords.words('english');\n","\n","# si no hacemos esto y usamos directo stopwords_sp, CountVectorizer devuelve un warning\n","stopwords_en_stem = [englishStemmer.stem(x) for x in stopwords_en]\n","\n","vectorizer = CountVectorizer(stop_words = stopwords_en_stem, lowercase = True, strip_accents = 'unicode');\n","\n","vectorizer.fit(data.text);\n","print('Vocabulario:\\n',vectorizer.vocabulary_) # vocabulario del corpus con la frecuencia de cada término"]},{"cell_type":"code","execution_count":null,"id":"8684e8c0","metadata":{"id":"8684e8c0"},"outputs":[],"source":["countvectorizer_encoding = vectorizer.transform(data.text);\n","print('\\n Transformamos los textos a una matriz esparsa:',type(countvectorizer_encoding))\n","\n","data_text = pd.DataFrame(countvectorizer_encoding.todense(), \n","             columns = vectorizer.get_feature_names())\n"]},{"cell_type":"code","execution_count":null,"id":"86400c7a","metadata":{"id":"86400c7a"},"outputs":[],"source":["cantidad_apariciones = data_text.sum()"]},{"cell_type":"code","execution_count":null,"id":"a0e4ccd4","metadata":{"id":"a0e4ccd4"},"outputs":[],"source":["mask = cantidad_apariciones < 3\n","mask.sum()"]},{"cell_type":"code","execution_count":null,"id":"8eb3dff8","metadata":{"id":"8eb3dff8"},"outputs":[],"source":["cantidad_apariciones[mask].index"]},{"cell_type":"code","execution_count":null,"id":"5094c18a","metadata":{"id":"5094c18a"},"outputs":[],"source":["data_clean = data_text.drop(cantidad_apariciones[mask].index, axis=1)\n","data_clean"]},{"cell_type":"code","execution_count":null,"id":"f5f9f8c4","metadata":{"id":"f5f9f8c4"},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfTransformer\n","\n","Tfidf_encoding=TfidfTransformer().fit_transform(data_clean);\n","\n","pd.DataFrame(Tfidf_encoding.todense(),columns=data_clean.columns)\n"]},{"cell_type":"code","execution_count":null,"id":"068520a3","metadata":{"id":"068520a3"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","from sklearn.decomposition import TruncatedSVD\n","\n","svd = TruncatedSVD(n_components=2);\n","P = svd.fit_transform(Tfidf_encoding)\n","\n","#grafico\n","color = ['m', 'g', 'r', 'c', 'b','k']\n","plt.figure()\n","patches = []\n","\n","for i,texto in enumerate(data.text):\n","    plt.plot(P[i,0], P[i,1], color[i]+\"o\")\n","    patches.append(mpatches.Patch(color=color[i], label='t'+str(i)))\n","\n","plt.legend(handles=patches)\n","plt.xlabel('dimension 1')\n","plt.ylabel('dimension 2')\n","#plt.axis([-4, 4, -4, 4])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"f649e12f","metadata":{"id":"f649e12f"},"outputs":[],"source":["# coeficientes (pesos) de los términos en cada una de las dos dimensiones\n","comp1,comp2 = svd.components_ \n","\n","# los ordenamos de menor a mayor y nos quedamos con los índices de sus posiciones en el array\n","indices=np.argsort(comp1); \n","\n","# invertimos para que queden ordenados de mayor a menor\n","indices=indices[::-1] \n","\n","# Evaluamos los términos en estas posiciones\n","print('Dimension 1:')\n","print(np.array(data_clean.columns)[indices]) \n","\n","print('\\n')\n","\n","indices=np.argsort(comp2);\n","indices=indices[::-1]\n","print('Dimension 2:')\n","print(np.array(data_clean.columns)[indices])\n","\n"]},{"cell_type":"code","execution_count":null,"id":"58c28ceb","metadata":{"id":"58c28ceb"},"outputs":[],"source":["data_clean['date_clean'] = data['Unnamed: 0'].values\n","data_clean['user_followers'] = data['user_followers'].values\n","data_clean['volume_clean'] = data['volume'].values\n","data_clean['target_clean'] = data['target'].values\n","data_clean.head(3)"]},{"cell_type":"code","execution_count":null,"id":"ed1d81ea","metadata":{"id":"ed1d81ea"},"outputs":[],"source":["data['user_followers'].values"]},{"cell_type":"code","execution_count":null,"id":"0119f744","metadata":{"id":"0119f744"},"outputs":[],"source":["data_clean['date_clean']"]},{"cell_type":"code","execution_count":null,"id":"4d9f02e4","metadata":{"id":"4d9f02e4"},"outputs":[],"source":["data_clean['target_clean'].value_counts()"]},{"cell_type":"code","execution_count":null,"id":"d66c26d1","metadata":{"id":"d66c26d1"},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.model_selection import GridSearchCV,StratifiedKFold,train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","X_train, X_test, y_train, y_test=train_test_split(data_clean.drop(['target_clean', 'date_clean'], axis=1), data_clean['target_clean'],\n","                            stratify=data_clean['target_clean'],random_state=3);\n","\n","nbc=MultinomialNB();\n","\n","nbc.fit(X_train,y_train);\n","y_pred=nbc.predict(X_test);\n","\n","print('Accuracy:',accuracy_score(y_test,y_pred))"]},{"cell_type":"code","execution_count":null,"id":"a94c4dc4","metadata":{"id":"a94c4dc4"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"48f232f0","metadata":{"id":"48f232f0"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":["39cda734","jp20vyppAO1d","8V34BYJFC3iu","vE45VSRePdpl","Y7pdPRNpDD8Z","gnlpS3hXsS1_"],"name":"Desafio_Final - Entregable.ipynb","provenance":[{"file_id":"1JQvn8ltybLFdEDhITENjN3HoR7ZpcEOq","timestamp":1649894995061},{"file_id":"1PZ8IMKjmRG7l8PuIaXbKh2QPXr6TLcYb","timestamp":1649603991525}],"toc_visible":true},"interpreter":{"hash":"cdc1364ae9eb5fc5b9b1f7b6542ac30e499f69d9924178b76153a50c6f9b6eb9"},"kernelspec":{"display_name":"Python [conda env:.conda-dhdsblend2021] *","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.11"}},"nbformat":4,"nbformat_minor":5}
